[{"categories":["微服务"],"content":"微服务和业务中台设计思考","date":"2023-09-16","objectID":"/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%92%8C%E4%B8%9A%E5%8A%A1%E4%B8%AD%E5%8F%B0%E8%AE%BE%E8%AE%A1%E6%80%9D%E8%80%83/","tags":["微服务"],"title":"微服务和业务中台设计思考","uri":"/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%92%8C%E4%B8%9A%E5%8A%A1%E4%B8%AD%E5%8F%B0%E8%AE%BE%E8%AE%A1%E6%80%9D%E8%80%83/"},{"categories":["微服务"],"content":"微服务和业务中台设计思考 微服务和业务中台设计思考 微服务和业务中台设计思考 ","date":"2023-09-16","objectID":"/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%92%8C%E4%B8%9A%E5%8A%A1%E4%B8%AD%E5%8F%B0%E8%AE%BE%E8%AE%A1%E6%80%9D%E8%80%83/:0:0","tags":["微服务"],"title":"微服务和业务中台设计思考","uri":"/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%92%8C%E4%B8%9A%E5%8A%A1%E4%B8%AD%E5%8F%B0%E8%AE%BE%E8%AE%A1%E6%80%9D%E8%80%83/"},{"categories":["微服务"],"content":"一、业务中台 ","date":"2023-09-16","objectID":"/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%92%8C%E4%B8%9A%E5%8A%A1%E4%B8%AD%E5%8F%B0%E8%AE%BE%E8%AE%A1%E6%80%9D%E8%80%83/:1:0","tags":["微服务"],"title":"微服务和业务中台设计思考","uri":"/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%92%8C%E4%B8%9A%E5%8A%A1%E4%B8%AD%E5%8F%B0%E8%AE%BE%E8%AE%A1%E6%80%9D%E8%80%83/"},{"categories":["微服务"],"content":"通用特征 业务中台是一种集约化的建设方式 业务中台是一种面向领域的架构体系 业务中台是一种按需使用的产品形态，必要时也可以变成按量计费的商业模式 ","date":"2023-09-16","objectID":"/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%92%8C%E4%B8%9A%E5%8A%A1%E4%B8%AD%E5%8F%B0%E8%AE%BE%E8%AE%A1%E6%80%9D%E8%80%83/:1:1","tags":["微服务"],"title":"微服务和业务中台设计思考","uri":"/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%92%8C%E4%B8%9A%E5%8A%A1%E4%B8%AD%E5%8F%B0%E8%AE%BE%E8%AE%A1%E6%80%9D%E8%80%83/"},{"categories":["微服务"],"content":"独有特征 业务中台在技术上是微服务的架构 业务中台在业务上是面向创新的架构 业务中台应该具备一种接受业务驱动，而又能支撑业务发展的正向反馈机制 ","date":"2023-09-16","objectID":"/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%92%8C%E4%B8%9A%E5%8A%A1%E4%B8%AD%E5%8F%B0%E8%AE%BE%E8%AE%A1%E6%80%9D%E8%80%83/:1:2","tags":["微服务"],"title":"微服务和业务中台设计思考","uri":"/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%92%8C%E4%B8%9A%E5%8A%A1%E4%B8%AD%E5%8F%B0%E8%AE%BE%E8%AE%A1%E6%80%9D%E8%80%83/"},{"categories":["微服务"],"content":"核心竞争力 快速的业务响应能力 规模化的创新能力 更低的试错成本 ","date":"2023-09-16","objectID":"/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%92%8C%E4%B8%9A%E5%8A%A1%E4%B8%AD%E5%8F%B0%E8%AE%BE%E8%AE%A1%E6%80%9D%E8%80%83/:1:3","tags":["微服务"],"title":"微服务和业务中台设计思考","uri":"/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%92%8C%E4%B8%9A%E5%8A%A1%E4%B8%AD%E5%8F%B0%E8%AE%BE%E8%AE%A1%E6%80%9D%E8%80%83/"},{"categories":["微服务"],"content":"如何做 领域驱动设计 (DDD) 通过分析问题空间和业务逻辑，将应用程序定义为域 域由多个子域组成，每个子域对应于业务的不同部分 设计与子域相对应的服务 子域分类 核心类 - 业务的关键差异化因素和应用程序中最有价值的部分。 (业务中台服务的候选) 支持类 - 与业务有关，但与差异化无关。 (业务前台服务的候选) 通用类 - 与业务无关，理想情况下可以使用现成的软件实现。 哪些不是业务中台 业务中台所提供的能力无法被共享，不是业务中台 如果出现新的业务需求或者需求变更，就要修改业务中台，不是严格的业务中台 如果出现前台调用中台，中台又调用前台的调用链路，不是合理的业务中台 ","date":"2023-09-16","objectID":"/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%92%8C%E4%B8%9A%E5%8A%A1%E4%B8%AD%E5%8F%B0%E8%AE%BE%E8%AE%A1%E6%80%9D%E8%80%83/:1:4","tags":["微服务"],"title":"微服务和业务中台设计思考","uri":"/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%92%8C%E4%B8%9A%E5%8A%A1%E4%B8%AD%E5%8F%B0%E8%AE%BE%E8%AE%A1%E6%80%9D%E8%80%83/"},{"categories":["微服务"],"content":"二、微服务 ","date":"2023-09-16","objectID":"/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%92%8C%E4%B8%9A%E5%8A%A1%E4%B8%AD%E5%8F%B0%E8%AE%BE%E8%AE%A1%E6%80%9D%E8%80%83/:2:0","tags":["微服务"],"title":"微服务和业务中台设计思考","uri":"/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%92%8C%E4%B8%9A%E5%8A%A1%E4%B8%AD%E5%8F%B0%E8%AE%BE%E8%AE%A1%E6%80%9D%E8%80%83/"},{"categories":["微服务"],"content":"微服务拆分方法 (1)按业务边界将业务域划分为多个业务子域(对应多个微服务) (2)将业务子域分解为多个领域对象 (对应某个微服务下的多个Service) (3)识别出领域对象的多个领域活动，覆盖到该领域对象所涉及的业务活动(一个领域活动对应Service下的一个方法 (4)识别出领域活动所涉及的聚合、实体和值对象(对应微服务的实体对象和数据对象) (5)比较不同子域。分析类似的领域对象，领域活动，聚合、实体和值对象，根据一定相似度闽值，合并去重 (6)分析同一个子域，如果不同Service之间没有任何交互，可进一步拆分成不同微服务 (7)迭代执行1-6步骤，持续提高拆分合理度 举例分析 所有业务用例，从应用和技术架构视角，都可以分为人机交互，逻辑处理，数据存储3个层面; 前台和中台的划分，重点在于“远辑处理和数据存储”的细分 故： (1)在微服务纵向拆分的成果基础上，做进一步的横向划分 (2)人机交互的，属于业务应用 (3)多变的、交易类的逻辑处理和数据存储，属于业务应用 (4)稳定的、基础的逻辑处理和数据存储，属于业务支撑 哪些不是微服务 仅仅为了不同团队并行开发而拆分的，不是微服务 没有拆分数据库的不是微服务 ","date":"2023-09-16","objectID":"/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%92%8C%E4%B8%9A%E5%8A%A1%E4%B8%AD%E5%8F%B0%E8%AE%BE%E8%AE%A1%E6%80%9D%E8%80%83/:2:1","tags":["微服务"],"title":"微服务和业务中台设计思考","uri":"/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%92%8C%E4%B8%9A%E5%8A%A1%E4%B8%AD%E5%8F%B0%E8%AE%BE%E8%AE%A1%E6%80%9D%E8%80%83/"},{"categories":["微服务"],"content":"经验反馈 每个微服务对应一个数据库，但如果存在关联查询需求的，尽可能保存在同一个实例中 业务中台服务不是越多越好，关键是能洞察到业务本质，始终保持面向资源的设计，而不是面向过程的设计 业务中台服务提供的功能颗粒度通常都是比前台服务的功能颗粒度更细 业务中台，是适用于业务逻辑比较复杂，业务变化和创新比较频繁的业务场景 业务中台一定要提前开发调试，不能和业务前台并行。业务前台开始开发时，业务中台API必须要是稳定的 业务前台和业务中台通过API网关来交互，很多非业务功能，例如路由，限流，认证，监控都由API网关来提供 不要把业务管控当作业务中台来建设，管控意味着处理逻辑和处理过程，这应该是业务前台利用业务中台的能力，组合/编排来实现 ","date":"2023-09-16","objectID":"/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%92%8C%E4%B8%9A%E5%8A%A1%E4%B8%AD%E5%8F%B0%E8%AE%BE%E8%AE%A1%E6%80%9D%E8%80%83/:2:2","tags":["微服务"],"title":"微服务和业务中台设计思考","uri":"/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%92%8C%E4%B8%9A%E5%8A%A1%E4%B8%AD%E5%8F%B0%E8%AE%BE%E8%AE%A1%E6%80%9D%E8%80%83/"},{"categories":["微服务"],"content":"三、总结 一定要前端和后端分离 后端做微服务拆分，形成一组微服务 通过划分原则，识别出中人台服务和前台服务 前端和前台服务共同组成了“业务前台” 中台服务共同组成“业务中台” 持续迭代步骤3~5 ","date":"2023-09-16","objectID":"/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%92%8C%E4%B8%9A%E5%8A%A1%E4%B8%AD%E5%8F%B0%E8%AE%BE%E8%AE%A1%E6%80%9D%E8%80%83/:3:0","tags":["微服务"],"title":"微服务和业务中台设计思考","uri":"/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%92%8C%E4%B8%9A%E5%8A%A1%E4%B8%AD%E5%8F%B0%E8%AE%BE%E8%AE%A1%E6%80%9D%E8%80%83/"},{"categories":["管理"],"content":"技术总监需要会些什么","date":"2023-08-23","objectID":"/%E6%8A%80%E6%9C%AF%E6%80%BB%E7%9B%91%E9%9C%80%E8%A6%81%E4%BC%9A%E4%BA%9B%E4%BB%80%E4%B9%88/","tags":["管理"],"title":"技术总监需要会些什么","uri":"/%E6%8A%80%E6%9C%AF%E6%80%BB%E7%9B%91%E9%9C%80%E8%A6%81%E4%BC%9A%E4%BA%9B%E4%BB%80%E4%B9%88/"},{"categories":["管理"],"content":"技术总监需要会些什么 技术总监需要会些什么 研发管理体系构建思考 道: 在于文化，思维，准则，价值观，领导力的构建，是思维和思想，它需要我们落到实处。 法：在于流程化，标准化，制度化的构建，是通过管理制度（法治）方式管理组织。 术：在于通过招，用，养，留，去五个维度打造人员管理体系。 器：在于通过系统化，工具化体系整体提升工程效能，精细化管理。 势：在于建立或者迎合公司和行业的形势，懂战略，明方向。 ","date":"2023-08-23","objectID":"/%E6%8A%80%E6%9C%AF%E6%80%BB%E7%9B%91%E9%9C%80%E8%A6%81%E4%BC%9A%E4%BA%9B%E4%BB%80%E4%B9%88/:0:0","tags":["管理"],"title":"技术总监需要会些什么","uri":"/%E6%8A%80%E6%9C%AF%E6%80%BB%E7%9B%91%E9%9C%80%E8%A6%81%E4%BC%9A%E4%BA%9B%E4%BB%80%E4%B9%88/"},{"categories":["管理"],"content":"背景 技术管理者(技术总监/经理/CTO)期望通过体系化的管理方式建设，能够在百人，千人以上的团队中有效的构建聚焦目标，自我成长，高效能的研发作战团队，快速拿出成果，支撑业务的快速发展。 ","date":"2023-08-23","objectID":"/%E6%8A%80%E6%9C%AF%E6%80%BB%E7%9B%91%E9%9C%80%E8%A6%81%E4%BC%9A%E4%BA%9B%E4%BB%80%E4%B9%88/:1:0","tags":["管理"],"title":"技术总监需要会些什么","uri":"/%E6%8A%80%E6%9C%AF%E6%80%BB%E7%9B%91%E9%9C%80%E8%A6%81%E4%BC%9A%E4%BA%9B%E4%BB%80%E4%B9%88/"},{"categories":["管理"],"content":"痛点 从小团队人员快速扩张，团队文化稀释，人员效能下降，目标逐渐弱化。 各自团队管理方式及标准不统一，人员管理及协同逐渐混乱。 组织扩大后，难以有效关注个人，无法准确评判个人的成长，贡献等。 ","date":"2023-08-23","objectID":"/%E6%8A%80%E6%9C%AF%E6%80%BB%E7%9B%91%E9%9C%80%E8%A6%81%E4%BC%9A%E4%BA%9B%E4%BB%80%E4%B9%88/:2:0","tags":["管理"],"title":"技术总监需要会些什么","uri":"/%E6%8A%80%E6%9C%AF%E6%80%BB%E7%9B%91%E9%9C%80%E8%A6%81%E4%BC%9A%E4%BA%9B%E4%BB%80%E4%B9%88/"},{"categories":["管理"],"content":"目标 通过构建完整研发管理体系，建立管理机制，让技术组织聚焦目标，高效运转，同时激励团队不断优化提升。 ","date":"2023-08-23","objectID":"/%E6%8A%80%E6%9C%AF%E6%80%BB%E7%9B%91%E9%9C%80%E8%A6%81%E4%BC%9A%E4%BA%9B%E4%BB%80%E4%B9%88/:3:0","tags":["管理"],"title":"技术总监需要会些什么","uri":"/%E6%8A%80%E6%9C%AF%E6%80%BB%E7%9B%91%E9%9C%80%E8%A6%81%E4%BC%9A%E4%BA%9B%E4%BB%80%E4%B9%88/"},{"categories":["管理"],"content":"研发管理体系构建思考 通过道，法，术，器，势五个维度去思考整个管理体系的构建。 ","date":"2023-08-23","objectID":"/%E6%8A%80%E6%9C%AF%E6%80%BB%E7%9B%91%E9%9C%80%E8%A6%81%E4%BC%9A%E4%BA%9B%E4%BB%80%E4%B9%88/:4:0","tags":["管理"],"title":"技术总监需要会些什么","uri":"/%E6%8A%80%E6%9C%AF%E6%80%BB%E7%9B%91%E9%9C%80%E8%A6%81%E4%BC%9A%E4%BA%9B%E4%BB%80%E4%B9%88/"},{"categories":["管理"],"content":"道: 在于文化，思维，准则，价值观，领导力的构建，是思维和思想，它需要我们落到实处。 通常团队小的时候，leader 可以深入到日常的管理事务中，管理者的智慧和想法可以体现在明处并落到做事上。 而当团队规模过百人的时候，组织架构一般已拆分层级，各项目和人员已经聚焦于各自产线上，甚至人员都已经分布在各个角落，新人的面孔逐渐陌生，此时我们也许需要构建文化，思维，基本准则，团队的价值观和管理者的领导力。 关注团队文化 文化在于使命，愿景，价值观的思考，这个也是企业需要思考并给与组织明确的目标。 而技术管理者需要深刻理解组织的使命和未来需要解决的一些社会问题；也需要了解客户的真正的痛点，努力达成美好又有价值的结果，以及在组织达成客户目标过程中，需要遵守以及秉承基本准则和宗旨。 管理者最基本的工作就是要亲身践行这些内容，并有意识的传达给一起奋斗的员工，而不是挂在墙上或写在纸上；同时我们也会考虑将企业文化加入绩效考核和入职考试中，以强化团队文化。 建立工作准则 准则在于明确组织达成目标过程中最基本的工作原则。一些职能部门或者特定职业群体会有自身工作的特殊原则和特性，比如技术部的一些工程师文化和思维方式，我们会将这些做为基本的工作原则和独有的组织文化。 工程师文化可以包含有高效，守信，激情，创新，分享等工作原则，它来源于公司的文化，又包含技术组织的文化特性，技术管理者应该迎合这样的群体，建设这样的团队和氛围。 高效: 更好更快速的拿出结果。 守信: 愿意为承诺的结果负责。 激情: 全身心的投入并感染别人。 创新: 敢于颠覆现有的模式并拿出结果。 分享: 将经验赋能给团队，与团队一起成长。 做事的工作思维 思维在于制定目标，完成目标过程中的做事思维方式。这个在建立和制定团队或者项目的工作目标及关键性事务决策时非常有用，比如在制定 ocr,kpi,技术选型决策,人员安排等场景。以下几种思维方式是我们可以参考的：用户第一，奋斗者优先，价值导向，财务思维。 用户第一: 找到组织或者团队服务面向的客户对象,能够对他们的痛点和爽点感同身受，并通过技术或者产品手段赋能并服务好用户，最终体现产品或者解决方案的价值。 奋斗者优先: 需要管理者识别并区分出团队成员中不同类型的人（庸人，人手，人才，奋斗者），要把机会和激励留给敢于承担，并和团队一起成长的人，这样的人成长会很快，潜力也往往很惊人。 价值导向: 定目标，做事要明确目标和事情本身的技术价值，产品价值和最终用户可感知的业务价值，我们只做最有价值的工作目标，筛选掉找不到价值的工作内容；这是技术管理决策需要考虑的关键维度。 财务思维: 本质是成本思维; 定目标，做事要明确目标和事情本身的资源（人员，时间等）投入产出比。我们允许战略性的投入，长远性的收益，但是做事时我们需要预估，明确和关注；这也是技术管理决策需要考虑的关键维度。 关键岗位的领导力 领导力是一种影响力，是成事的能力；管理者不仅仅局限于管理事务本身，更要关注人，关注团队，要以人为本；技术管理者需要掌握领导力，指引团队，去达成组织目标；可以从“找准目标”，“激励团队”，“影响他人”，“感同身受”这几个维度培养自身的领导力。 找准目标： 需要技术管理者一定的专业能力，帮助团队梳理一个愿景，制定一系列目标；也可以通过一定的感召力，帮助团队成员发现自我成长的动力，制定个人发展的目标；而本质上是需要领导者能够帮助团队找到方向。 激励团队： 管理者要激励团队，使众人行，而激励本身也是很大的话题；我们可以通过物质上的激励，荣誉上的激励，职位上的激励，成长上的激励等多种激励方式，让团队不断地小步成功→正向反馈→继续成功→正向反馈…如此循环，打造不断打胜仗的氛围和团队。 影响他人： 领导者需要有一定的前瞻力，去指引团队（它并不一定要体现在专业知识方面）。此时需要管理者拥有一定的学习力，给与团队指导，输出自身的观点，影响他人，提升他人的认知。 感同身受： 同理心不一定是领导者必备的素质，但这是管理者基本的能力素养。管理者要能够感知他人的情感，团队的氛围，做到有效沟通；能够为团队的成功而喝彩，为团队的失败、自身的决策及相关的结果负责。 小结 “有道无术术尚可求,有术无道止于术”，足以让人明白管理之“道”的重要性。管理是“以人为本”，核心在于目标和激励，本质还是管理者对“人性”的透彻理解，管理的“法”，“术”，“器”的细节和实施最终都源于对管理之“道”的理解和落地。所以有些技术管理者空有方法论，最终实施结果并不理想，这时需要反思落地的管理手段是否真正对齐初心。 ","date":"2023-08-23","objectID":"/%E6%8A%80%E6%9C%AF%E6%80%BB%E7%9B%91%E9%9C%80%E8%A6%81%E4%BC%9A%E4%BA%9B%E4%BB%80%E4%B9%88/:4:1","tags":["管理"],"title":"技术总监需要会些什么","uri":"/%E6%8A%80%E6%9C%AF%E6%80%BB%E7%9B%91%E9%9C%80%E8%A6%81%E4%BC%9A%E4%BA%9B%E4%BB%80%E4%B9%88/"},{"categories":["管理"],"content":"法：在于流程化，标准化，制度化的构建，是通过管理制度（法治）方式管理组织。 一般来说小团队人员在 50 人左右的时候，建立基本的研发项目流程就足够满足日常研发管理。而当团队规模超过百人，千人的时候，研发组织也许已经拆分成很多小团队，协作同时也会面临远程沟通的问题等，此时我们会考虑运用常见的流程，标准化的技术，规范化的制度去应对大型技术团队管理的挑战。 将研发协作流程化 研发管理中通常会涉及项目管理和人事管理，所以管理流程一般会围绕项目流程和人事流程去构建，而所有的流程化构建的目的是提升研发效率的效能，降低协作成本，这个也是判别一件事是否符合流程化的初心的重要标准。 流程化的构建工具: 考虑采用钉钉,飞书，OA 系统，TAPD 等等一些协同工具来定制流程解决。 项目流程构建: 由研发 PMO 等类似角色牵头，在协助组长解决日常项目中遇到的沟通，协作等问题后进行复盘，统筹抽象分析，梳理构建标准化的流程建设；比如项目立项流程,项目迭代流程,项目发布流程,紧急事故处理流程,研发资产申请流程等类似流程都会在这个过程中沉淀下来。 人事流程构建: 由研发 hrbp 牵头，在协助组长解决日常项目中遇到的人员效率，状态，成长，考核，晋升，淘汰这类问题过程中，进行复盘，统筹归纳分析，梳理构建标准化的流程建设；比如试用期转正流程，请假流程，人员晋升流程，招聘流程，面试流程等等。 将研发规范制度化 研发管理会涉及项目管理和人事管理，同样管理制度也会围绕项目流程和人事流程去构建，同理所有规范制度化构建的目的是标准化操作，有法可依，减少或避免犯错。 制度化的查询工具: 考虑采用 wiki,confluence 等知识库相关的工具。 项目制度构建: 由研发 PMO 等类似角色牵头，在协助组长解决和复盘日常项目问题的过程中，进行体系化解决方案的梳理，考虑从管理维度建立规范，制度等标准化的操作流程机制，避免重复犯错；比如数据库设计规范，分支管理规范，项目发布规范，线上故障处理规范，网络安全规范，项目流程规范，测试用例管理规范，项目性能标准规范等。 人事制度构建: 由研发 hrbp 牵头，在协助组长解决人员相关问题的过程中，进行全局性体系化思考，协同 PMO 等类似角色共建研发相关人力制度。比如绩效考核评分规范，研发晋升制度，研发招聘制度，研发激励体系等。 将研发技术标准化 在构建整个研发体系的过程中，我们期望通过五个维度(技术一体化，业务一体化，监控一体化，运维一体化，管理一体化)进行体系化构建，其中技术一体化的核心是打造标准化的技术体系。 技术标准化（技术一体化）包含技术/框架选型标准化，技术使用标准化，技术协议/工具标准化，技术结构标准化等。其中开源的bsf框架（基础框架）解决选型和使用标准化的问题，business（业务框架）解决协议和工具标准化及技术选型兼容问题，demo 脚手架项目解决快速构建新项目和技术结构标准化问题。 基于技术标准化的原则，我们也会关注运维标准化，监控标准化，测试标准化等涉及整个 devops 相关的标准化技术建设。 运维标准化（devops）: 通过构建 CICD 标准自动化流程, 通过 ops 自动化发布，让日常发布交还开发，彻底解放运维工作量；通过构建运维标准化体系实现自动化运维。 监控标准化: 通过标准化的监控体系构建全维度性能监控和质量分析,通过 oms 自动化监控，让日常问题排查更智能，秒级报警，秒级服务自愈，秒级报告项目质量。 测试标准化: 通过标准化的测试管理体系，主流程自动化测试体系，自动化全链路压测体系，解放测试部分工作量，保障线上性能和稳定性。 小结 管理之法本质是从流程化，标准化，制度化等维度建立整个“管理机制”，最终的核心目标是通过管理的法治建立标准化的操作规范，再通过标准化的规范提升人员的协作效率、监督机制、系统稳定性/安全性等；技术管理者在实施时勿忘初心，切忌为了管理而管理，一切尽可能从简化人力管理，提升效率为目标而设置管理机制。 ","date":"2023-08-23","objectID":"/%E6%8A%80%E6%9C%AF%E6%80%BB%E7%9B%91%E9%9C%80%E8%A6%81%E4%BC%9A%E4%BA%9B%E4%BB%80%E4%B9%88/:4:2","tags":["管理"],"title":"技术总监需要会些什么","uri":"/%E6%8A%80%E6%9C%AF%E6%80%BB%E7%9B%91%E9%9C%80%E8%A6%81%E4%BC%9A%E4%BA%9B%E4%BB%80%E4%B9%88/"},{"categories":["管理"],"content":"术：在于通过招，用，养，留，去五个维度打造人员管理体系。 通常团队小的时候，人员的管理可以由核心管理者亲自安排，所以总体可控。而组织规模稍微大一些，权责必然会下放，组织也拆分成多个业务线或者团队。 为了保证组织规模成长过程中，人员基本管理方式一致，我们需要打造标准的人员管理体系辅助各级管理者，确保合适人员可以识别，引入，培养，不合适的人员可以淘汰；这个过程中技术管理者要和 hrbp，共同协作打造整个人员管理体系。 打造招聘体系（招） 招聘体系是人事构建管理过程中非常专业的内容，而技术管理者可能关注工程师文化所带来的不同特点，可以从招聘渠道，人员组织规划和预算，面试流程标准化，试用期考核制度等维度协助完善体系构建。 招聘渠道:可以从专业招聘渠道补充和人才引进激励制度建设来完善。 专业招聘渠道补充: 技术工程师常见的招聘渠道有 boss，猎聘，拉钩等,招聘渠道选择的过程中，垂直行业的招聘渠道特性会更明显。高端或者一些合适的岗位，可以通过猎头推荐，也可以通过熟人推荐，在实操过程中成功率和匹配率上会更高一些。 人才引进激励制度的建设: 需要公司内部建立完善内推渠道，相应的岗位激励政策，显式的成功案例，打动人心的招聘文案宣传几个方向努力才能略显成效。 当然曾经也见过一些公司的激励政策很好，但是内部宣传和成功案例，对内部员工的吸引和感知不够。也见过一些公司将内部人员推荐面试人数指标纳入技术部门各组绩效考核中，具体效果不得而知，也可以作为参考。 招聘计划: 可以从人员组织规划和预算来确定年度招聘计划和财务预算。 人员组织规划：技术管理者需要明确和对齐更高管理层年度的业务方向和期望，盘点自身组织最终需要达成技术目标，产品目标，业务目标，从而根据目标盘点现有技术人员，确定组织岗位规划和相应的招聘计划，协同相关的 hr 达成招聘目标。 预算: 技术管理者要有一定的财务成本思维，做好人员的组织规划后，确定相应研发组织的年度预算和部门预算，同时也要协同 hrbp 了解组织的投出产出比情况；如果中途有人员变动和额外新增人员，可以申请额外预算。 面试流程标准化:可以从梳理岗位模型，标准化面试，岗位胜任力模型 ，面试反馈，入职流程，试用期考核制度等多个维度推进优化。 岗位模型: 技术管理者需要协助招聘 hr，明确目标招聘岗位的人员画像，包括相应的年龄要求，能力模型（技术能力要求），级别，岗位职责，薪酬范围之外，也要特别关注技术岗位的能力，所需要的行业业务经验和业务知识的掌握程度。 标准化面试: 通过一定的标准化面试过程+标准化面试题库+经验交流，可以解决部分面试官的面试风格不一致导致面试结果不同的问题。但探其本质是应聘者能力是多维的，答案是多解的，需要规范性面试和面试官主观判断给予相对准确岗位匹配度评价。所以技术标准题库往往用于验证通用性的基础能力掌握是否全面，经验交流用于突显实战解决能力和全方位问题解决思路评估。 岗位胜任力模型：通过标准化多维度较为精准的判定该应聘者是否符合当前岗位，一般会考虑从价值观，年龄，稳定性，能力模型，薪酬等岗位匹配度模型建立岗位胜任力模型，这个对于招聘复盘，转正考核都会有参考意义，这个需要招聘 hr 统筹体系化梳理，建立标准。比如一些技术工作，若非管理岗，会对年龄会有所要求和限制；若非相同工种，技术能力要求和评估都有所不同，这些都是需要在建立模型时需要考虑的。 面试反馈：建立统一的面试反馈，让面试参与者（特别是通过者）填写反馈，关注面试过程和面试感受，同时也是反向筛选面试官，改善面试质量的方法。因为技术面试是专业性较强的面试过程，比如有些时候面试官的状态不佳和经验不足，在沟通过程的措辞和回答都要谨慎，否则容易引起应聘者反感，导致人才流失。 入职流程：根据不同岗位职级，建立快速的入职流程审批和背调过程，是技术管理者和相关 hr 特别需要关注的。毕竟求职是一种双向选择，很多优秀的候选人的错失，是因为漫长等待 offer 流程过程中，有了其他的机会；特别是技术工作者，求职的行业范围和机会也特别多。 试用期考核制度：可以从新人入职文档标准化，导师制度，试用期考核标准等方向建立入职后考核转正体系。 新人入职文档标准化: 除基础人事制度外，标准化运维环境，软件基础架构，项目流程规范，相关服务环境等软件环境，梳理必备基础信息文档和开发文档，最终整理新人入职文档，可以快速帮助新人上手，进入业务开发支撑状态；有效避免大部分重复性的一对一非业务基础信息指导，减轻技术管理者的工作量。 导师制度：为入职新人指定转正期间工作导师，协助入职工作环境熟悉，初期业务熟悉计划及答疑，中后期转正考核目标制定与达成及期间团队协作困难解决等；很多优秀技术人才在试用期后的离开，有些是因为新环境的不适应，关注度不够，目标不清晰导致，值得管理者反思。 试用期考核标准：帮助入职新人经历初期熟悉和适应后，一般在 2 周左右协助新人指定试用期工作和考核目标，导师需要协助指导期间遇到的难点和风险感知，帮助新人达成目标并对之进行考核评估，最终考核评估结果将直接关系试用期转正。 打造组织体系（用） 20~30 人左右的团队，其实不必关注太多团队组织问题，一个 leader 带着几个干活的（可能是全栈），直接非常高效率的拿出结果。 而当团队成员达到 50 人左右的时候，技术管理者应该要关注和思考组织构建的问题了，我们可以从矩阵组织架构建设，人员梯队建设两个维度建立组织体系。 矩阵组织架构建设：从职能型组织，产品型组织，创新性组织三个维度构建混合型组织架构 矩阵型组织架构图 职能型组织： 按照前端，后端，测试，产品，架构，技术委员会等职能维度拆分组织，在 30 人以下的团队中，人员的效能和复用性比较好，也非常适用。但是对于人员和产品的专业性深度及成长都会受限，适合业务探索初期。 产品型组织： 按照业务领域维度拆分多个业务项目团队，在团队人员超过 30 人以上，就可以考虑专业化分工，业务边界明确，更聚焦本身业务价值和产品深度打磨，也更有利于绩效考核管理。 创新型组织： 在业务成熟后期，尝试聚焦新业务创新，在探索初期召集 10 人左右小团队进行快速业务验证，快速迭代，快速体现价值，进行额外绩效激励。 在技术组织实际发展过程中，团队会根据本身的业务特性，团队规模大小，不断演进改变组织架构模式，以应对不同形态的挑战。一般情况下在超过 100 人左右时，组织会呈现职能型，产品型，创新型等多组织共存的混合架构模式。 人员梯队建设：从人员类型及梯队，职责及职级划分，AB 角色建设几个维度考量 人员类型及梯队: 组织内技术管理者要识别庸人，人手，人才，奋斗者不同人员类型，要区分普通员工，核心骨干，管理干部，储备人才几种人员类别，从而打造技术人员结构化梯队；一般来说技术负责人，产品负责人，架构师及高级开发往往时团队内最核心，最骨干的人，同样最终所有的激励制度会集中优先考虑，贡献最大，能力最大，承担核心岗位的头部员工。技术管理者要定期对骨干成员要一对一形式沟通激励，并形成机制规范。 职责及职级划分: 所有的员工都将归属到组织，归属到相应的岗位，明确相应的职责，权利和能力的边界，这是管理者用人的基本。所以一般技术成员都会有明确的归属产品线，明确的技术职级/管理职级，明确的岗位类型和岗位职责，这也是我们常说的“一个萝卜一个坑”；然而公司规模较小或创新组织时，人员复用性较强，跨边界和职责的工作会较多，职责和职级界限会相对模糊（比如说全栈工程师），这需要技术管理者权衡和区别。 AB 角色建设: 作为管理者最担心的是人员离职或者其他变动，直接影响组织目标达成。特别是行业业务场景特殊，专业性较强的技术工程师市场流动性不强，合适的人员需要长期培养。在公司达到一定规模或有足够预算时，应考虑全部核心岗位搭建明确 AB 角色制度，互相培养储备人才；在实际场景中 AB 角色的实施，确实会大量减少人员流动带来的业务风险；但是一些行业变动，管理能力问题，重大业务问题等导致的大范围的人员流动，还是需要技术管理者更智慧的管理思考。 打造成长体系（养） 30 人以下的团队，成员的专业能力的成长才是最有价值的，所以一般考虑从实战项目中提升能力。100 人以上的团队，应该考虑体系化的建设，建立学习成长氛围，培养出最符合公司价值观的“腰部”和“头部”力量。 我们可以从技术能力模型构建，对内分享体系构建，对外交流体系构建，人员成长预算几个维度打造成长体系。 技术能力模型构建：梳理明确的技术职级评级和能力要求。 技术组织一般会分 P 偏技术路线，和 M 偏管理路线两个维度构建整体的能力模型，再从专业能力，管理能力，业务能力等维度梳理公司级职级要求，从而打造专业技术能力模型。 对招聘而言应用能力模型，对标技术人员应聘者能力评级；对员工个人成长而言，打造能力模型，帮助个人明确个人能力成长路径和目标，激励前行。 对技术管理者而言，通过日常沟通接触，对标能力模型，准确了解并给予管理成员明确的技术能力评估。 一般来说，百人左右的技术组织就可以协同 hrbp 制定明确的能力职级划分，小规模的技术团队更多凭借管理者的从业经验主观判断，反而不太必要。 对内技术分享体系构建（走进来）：考虑内部建立分享激励制度，建立虚拟技术组织等形式。 核心目标是引导团队学习文化和氛围的建立，逐步形成学习型技术组织。 可以从内部技术分享维度，建立技术内部分享制度和相关的激励制度，比如有些公司会有量化技术分享指标落到各个技术团队 kpi 考核或转正考核期，也有公司会将分享次数均摊到个人分享考评或绩效考核中，用于年终晋升参考指标或现场的现金激励，都是不错的方式。 在公司内部建立专业性的虚拟技术（偏职能更细化）","date":"2023-08-23","objectID":"/%E6%8A%80%E6%9C%AF%E6%80%BB%E7%9B%91%E9%9C%80%E8%A6%81%E4%BC%9A%E4%BA%9B%E4%BB%80%E4%B9%88/:4:3","tags":["管理"],"title":"技术总监需要会些什么","uri":"/%E6%8A%80%E6%9C%AF%E6%80%BB%E7%9B%91%E9%9C%80%E8%A6%81%E4%BC%9A%E4%BA%9B%E4%BB%80%E4%B9%88/"},{"categories":["管理"],"content":"器：在于通过系统化，工具化体系整体提升工程效能，精细化管理。 社会（农业，工业，现代化）发展至今，产能的提升本质上来源于工具的提升。无论团队大小，工具对于研发效能的提升是显而易见的，一些场景下也许可以带来 5 倍，10 倍的提升。 因此技术管理者必须关注技术行业内最新及最佳的一些实践，及评估尝试这些实践所沉淀的一些平台或者工具赋能整个技术团队。 我们在实践从五个维度(技术一体化，业务一体化，监控一体化，运维一体化，管理一体化)构建研发体系，不断在其中引入一些第三方的工具/平台/开源/理念，和自研一些工具或者框架来提升整体研发体验和效率。 云平台 云平台的好处是按需使用，简单方便。对于创业型的小公司，可以快速开发上线验证商业模式，减少 IT 运维的很大工作量。 当然云平台从原则上来说规模化会带来成本的降低，实际情况并非如此，上一定规模以后可以适当考虑场景和成本自建服务器或搭建混合云方式。国内考虑腾讯云，阿里云；国外考虑 aws 和 google 云。与第三方云厂商合作的时候，折扣可以谈一谈，争取 2 折，5 折优惠。 云原生 Kubernetes 是最佳的实践云原生工具；在实践过程中，云原生带来的服务器资源的减少约有 30%左右，特别是针对开发，测试，预发环境，使用人员不多不频繁，云原生带来的资源复用，利用率还是很高的，成本降低也会很明显。 云原生不仅仅是在服务上面的改造，也在基础设施上考虑全部云原生化，可以有效提升运维的效率和标准化的实践。 Devops 市面上有很多 devops 商业解决方案，有一些都会和云原生和各自云平台兼容或者结合。但是可惜的是解决方案做的比较深入，跟自身的一些方案结合比较紧密，反而通用性降低一些，而我们需要的更多是可插拔的定制化方式。 自研 ops 自动化运维平台，配合自定义的标准化 cicd 方式其实更适合自身场景（另外配套其他的解决方案），但是这个不是银弹方案，究其本质目的是简化运维，简化发布。 企业协同办公沟通工具 市面上企业协同办公的工具有很多，而且很大部分都是免费的。比如企业微信，钉钉，飞书，从所有协同软件使用的经历来说，个人还是比较喜欢钉钉，当然飞书也还可以，企微最不喜欢。企业协同办公工具，决定了分布式远程办公，异地办公的沟通效率问题，效能提升好几倍；但是小团队成员同办公区域，一般感觉不出来，差异不明显。 自研标准化框架 技术选型基本上会考虑热门的语言，主流的技术，毕竟这样的人才会更多，比如 java。开源社区的活跃度，解决方案的成熟度和活跃度也都是考虑的范围，比如 spring 框架体系。特有的一些技术标准的整合和技术工具的整合，比如自研 bsf 框架，business 业务框架，脚手架，可以帮助开发人员一分钟快速上手进入开发，能效提升非常明显。 自研效能平台 阿里，腾讯，百度等一些公司都在研发效能平台，期望在研发整个链路上提升人员的投入产出比。 同样，我们也期望能够有一个简单有效的平台，能够将公司的文化，管理理念，制度，研发管理流程等沉淀到这样的平台中，能够实时反馈发现人员，项目，组织的效能问题并及时根据问题思考并改进它；效能平台本质的意义在于科学化，指标化，精细化的管理，将管理过程可量化，可追溯，可对比。 这个也是研发体系管理一体化要做的，将管理的事情标准化，流程化；标准化，流程化的事情自动化，系统化；当然过程真正实操，其实挺难，但是团队上规模后必须要做。 自研监控平台 pms 监控平台是整个技术平台和业务平台稳定性的最后防线，而最快速度发现问题，解决问题，靠的是体系化的监控平台建设。 很多第三方也提供了商业化或者免费的，开源的监控解决方案，比如听云，skywalking，cat 等。大多数的解决方案其实并不能满足需求，比如一些自定义的中间件，组件，标准化的技术方案，我们需要植入自有的监控，也有一些业务监控和埋点可能需要动态的配置，同时也有一些特有的报警和相关的监控策略及代码质量情况都需要纳入监控体系建设，最终需要公司基于业务场景和管理规范等梳理一套监控标准和经验去帮助定级问题，及时发现问题，指导解决问题，甚至自愈服务。 自研全链路压测平台 如果对公司的业务有性能要求并将性能指标作为日常的技术标准及上线标准，我们可能需要全链路的压测平台，定时自动化的生成日常的性能报告及性能预测。其中会涉及流量的录制和精准回放及生成压测报告，最终让压测全自动化，解放测试人员的这块精力和重复工作。 第三方工具 业内最佳项目管理实践有很多，而且很多管理者都有相关的新的和工具沉淀，这就给其他技术管理者很大的借鉴。比如 tapd,worktile 等都可以使用一下，但是要结合自身公司的实际情况和管理的侧重点。 小结 管理之器引入的是工具和自动化实践所给予我们的效能提升，从而引爆整个技术生产力。然而管理者须知工具终究为工具，真正能带来改变的依然是人。 不同人对同一个工具尚且能带来不同的结果，那么不同的管理方式带领不同的人使用同一个工具最终的结果和效能也许也完全不同。所以技术管理者需要需要警醒，人和管理才是需要长期关注的核心，最终工具才能带来爆发式的提升。 ","date":"2023-08-23","objectID":"/%E6%8A%80%E6%9C%AF%E6%80%BB%E7%9B%91%E9%9C%80%E8%A6%81%E4%BC%9A%E4%BA%9B%E4%BB%80%E4%B9%88/:4:4","tags":["管理"],"title":"技术总监需要会些什么","uri":"/%E6%8A%80%E6%9C%AF%E6%80%BB%E7%9B%91%E9%9C%80%E8%A6%81%E4%BC%9A%E4%BA%9B%E4%BB%80%E4%B9%88/"},{"categories":["管理"],"content":"势：在于建立或者迎合公司和行业的形势，懂战略，明方向。 这个时代有很多机会，整体的商业形势及技术形势都在不断地变化着，单纯的闭门造车去打造一个产品的时代已经过去了。 这就要求技术管理者能够对自身的行业商业形势足够敏感，对技术的更新迭代形势足够敏感，并做好提前的规划，所以技术管理者需要掌握或建立内势与外势的变化。 外势是外部行业的形势和商业的形势 几年之前互联网高速发展，很多行业都处于行业的风口，雷军说过一句话：“站在风口上，猪都能飞起来”，这句话是为了说明创业成功的本质是找到风口，顺势而为；源自于《孙子兵法·兵势篇》，“故善战人之势，如转圆石于千仞之山者，势也”，意思是善于指挥打仗的人所造就的“势”，就象让圆石从极高极陡的山上滚下来一样，来势凶猛。 而技术管理者需要去感知了解整体行业形势的，及早的配合公司的战略及时做业务的调整。特别是技术领域的变化，比如自然语言处理，人工智能，深度学习等一些新技术领域能够给予业务的赋能和创新，也都是非常有价值和值得去尝试的。一些业内的最佳实践和第三方成熟的商业解决方案（比如蓝鲸，听云，极光等），可以深入去接触及评估，考量这些技术带给业务的复用性，从而降低自研的成本。 内势是建立内部的成事的基础和必要条件（造势） 推进一些目标的执行和落地，要考虑天时，地利，人和等多方面的因素，天时指做事的时机是否合适，地利是指成事的资源条件是否具备，人和是指团队的凝聚力和心态。 优秀的技术管理者核心的工作内容是根据目标，建立内部这样的成事条件（造势），帮助团队成员在一堆事务中，找准真正高价值痛点，集结优势资源创造条件，推进并解决它。 比如一些技术的变革和标准化的实施，可以根据当前已经发生的故障（某些重大服务不可用故障）和问题进行复盘（找准痛点单点突破），梳理体系化的解决方案，找技术高 P 进行逐步规划落地。 小结 管理之势是需要让管理者跳出事务执行本身，从整个大局看清楚事情成败的主因，无论大到公司战略，还是小到内部事务的推进，都需要管理者能够深度思考本质，因势利导。 然后管理者依然需要警醒，形势虽然能够带来振幅和机遇，但是优秀脱颖而出的产品和成果才是带领公司和组织走下去的真正实力，所以成事的关键依然来源于本身组织的优秀人才和团队的执行力，才能最终拿出产品和成果。 ","date":"2023-08-23","objectID":"/%E6%8A%80%E6%9C%AF%E6%80%BB%E7%9B%91%E9%9C%80%E8%A6%81%E4%BC%9A%E4%BA%9B%E4%BB%80%E4%B9%88/:4:5","tags":["管理"],"title":"技术总监需要会些什么","uri":"/%E6%8A%80%E6%9C%AF%E6%80%BB%E7%9B%91%E9%9C%80%E8%A6%81%E4%BC%9A%E4%BA%9B%E4%BB%80%E4%B9%88/"},{"categories":["管理"],"content":"总结 研发管理体系的构建并没有完整的最佳实践可以直接复用，就如同世上没有一样的组织，一样的心路经历，所以需要技术管理者在不断地感悟中沉淀自身的一些框架性方法论，去应对未来公司发展所面对的挑战。我们依然需要学习，刷新，沉淀，分享，交流，与同路者砥砺前行！ ","date":"2023-08-23","objectID":"/%E6%8A%80%E6%9C%AF%E6%80%BB%E7%9B%91%E9%9C%80%E8%A6%81%E4%BC%9A%E4%BA%9B%E4%BB%80%E4%B9%88/:4:6","tags":["管理"],"title":"技术总监需要会些什么","uri":"/%E6%8A%80%E6%9C%AF%E6%80%BB%E7%9B%91%E9%9C%80%E8%A6%81%E4%BC%9A%E4%BA%9B%E4%BB%80%E4%B9%88/"},{"categories":["管理"],"content":"项目各阶段流程图","date":"2023-08-23","objectID":"/%E9%A1%B9%E7%9B%AE%E7%AE%A1%E7%90%86%E6%B5%81%E7%A8%8B/","tags":["管理"],"title":"项目各阶段流程图","uri":"/%E9%A1%B9%E7%9B%AE%E7%AE%A1%E7%90%86%E6%B5%81%E7%A8%8B/"},{"categories":["管理"],"content":"项目各阶段流程图 ","date":"2023-08-23","objectID":"/%E9%A1%B9%E7%9B%AE%E7%AE%A1%E7%90%86%E6%B5%81%E7%A8%8B/:0:0","tags":["管理"],"title":"项目各阶段流程图","uri":"/%E9%A1%B9%E7%9B%AE%E7%AE%A1%E7%90%86%E6%B5%81%E7%A8%8B/"},{"categories":["管理"],"content":"各阶段文档清单 ","date":"2023-08-23","objectID":"/%E9%A1%B9%E7%9B%AE%E7%AE%A1%E7%90%86%E6%B5%81%E7%A8%8B/:1:0","tags":["管理"],"title":"项目各阶段流程图","uri":"/%E9%A1%B9%E7%9B%AE%E7%AE%A1%E7%90%86%E6%B5%81%E7%A8%8B/"},{"categories":["管理"],"content":"项目流程分工图 ","date":"2023-08-23","objectID":"/%E9%A1%B9%E7%9B%AE%E7%AE%A1%E7%90%86%E6%B5%81%E7%A8%8B/:2:0","tags":["管理"],"title":"项目各阶段流程图","uri":"/%E9%A1%B9%E7%9B%AE%E7%AE%A1%E7%90%86%E6%B5%81%E7%A8%8B/"},{"categories":["管理"],"content":"开发分工协作图 ","date":"2023-08-23","objectID":"/%E9%A1%B9%E7%9B%AE%E7%AE%A1%E7%90%86%E6%B5%81%E7%A8%8B/:3:0","tags":["管理"],"title":"项目各阶段流程图","uri":"/%E9%A1%B9%E7%9B%AE%E7%AE%A1%E7%90%86%E6%B5%81%E7%A8%8B/"},{"categories":["管理"],"content":"上线工作指南 ","date":"2023-08-23","objectID":"/%E9%A1%B9%E7%9B%AE%E7%AE%A1%E7%90%86%E6%B5%81%E7%A8%8B/:4:0","tags":["管理"],"title":"项目各阶段流程图","uri":"/%E9%A1%B9%E7%9B%AE%E7%AE%A1%E7%90%86%E6%B5%81%E7%A8%8B/"},{"categories":["管理"],"content":"云平台上线流程 ","date":"2023-08-23","objectID":"/%E9%A1%B9%E7%9B%AE%E7%AE%A1%E7%90%86%E6%B5%81%E7%A8%8B/:5:0","tags":["管理"],"title":"项目各阶段流程图","uri":"/%E9%A1%B9%E7%9B%AE%E7%AE%A1%E7%90%86%E6%B5%81%E7%A8%8B/"},{"categories":["测试"],"content":"系统、数据库性能测试记录","date":"2023-08-05","objectID":"/%E6%B5%8B%E8%AF%95%E5%B7%A5%E4%BD%9C%E9%97%AE%E9%A2%98%E5%92%8C%E6%80%BB%E7%BB%93/","tags":["测试"],"title":"系统、数据库性能测试记录","uri":"/%E6%B5%8B%E8%AF%95%E5%B7%A5%E4%BD%9C%E9%97%AE%E9%A2%98%E5%92%8C%E6%80%BB%E7%BB%93/"},{"categories":["测试"],"content":"系统、数据库性能测试记录 系统、数据库性能测试记录 createBy lln createTime 2023-03-01 Jmeter version: V5.3 背景: 公司内部某ToB大型项目前期准备工作之一，评估在特定条件下的系统性能、数据库性能情况，通过此测试决定需要申请的资源数量。 使用Jmeter完成Api接口测试及数据库吞吐测试。 ","date":"2023-08-05","objectID":"/%E6%B5%8B%E8%AF%95%E5%B7%A5%E4%BD%9C%E9%97%AE%E9%A2%98%E5%92%8C%E6%80%BB%E7%BB%93/:0:0","tags":["测试"],"title":"系统、数据库性能测试记录","uri":"/%E6%B5%8B%E8%AF%95%E5%B7%A5%E4%BD%9C%E9%97%AE%E9%A2%98%E5%92%8C%E6%80%BB%E7%BB%93/"},{"categories":["测试"],"content":"前期思考 如何评估软件系统所需要的资源信息 如何进行接口性能测试 如何进行数据库性能测试 如何使用Jmeter进行测试 如何获取测试报告记录 Jmeter学习记录 ","date":"2023-08-05","objectID":"/%E6%B5%8B%E8%AF%95%E5%B7%A5%E4%BD%9C%E9%97%AE%E9%A2%98%E5%92%8C%E6%80%BB%E7%BB%93/:1:0","tags":["测试"],"title":"系统、数据库性能测试记录","uri":"/%E6%B5%8B%E8%AF%95%E5%B7%A5%E4%BD%9C%E9%97%AE%E9%A2%98%E5%92%8C%E6%80%BB%E7%BB%93/"},{"categories":["测试"],"content":"梳理和拆分\u0026测试记录 线程组 配置原件 控制器 取样器 处理器 本质上是对一组资源的生命周期进行管理。 资源即需要测试的场景，这个场景可以是接口、可以是SQL语句等等。 然后针对该资源，进行相应的配置，如接口地址，请求数据，jdbc连接参数等等。 对于资源的请求，又可以进行各种逻辑的控制，如多线程的执行，顺序的执行，循环执行等等。 对于资源的请求结果，可以进行后置的处理，断言，数据处理等等。 对于资源的整个生命周期，又可以生成报告，包含了资源的请求信息，结果信息，异常信息，吞吐信息等等。 ","date":"2023-08-05","objectID":"/%E6%B5%8B%E8%AF%95%E5%B7%A5%E4%BD%9C%E9%97%AE%E9%A2%98%E5%92%8C%E6%80%BB%E7%BB%93/:2:0","tags":["测试"],"title":"系统、数据库性能测试记录","uri":"/%E6%B5%8B%E8%AF%95%E5%B7%A5%E4%BD%9C%E9%97%AE%E9%A2%98%E5%92%8C%E6%80%BB%E7%BB%93/"},{"categories":["测试"],"content":"配置元件 HTTP配置 JDBC配置，需要将驱动文件，导入指定目录，或者放入jmeter中lib目录下 ","date":"2023-08-05","objectID":"/%E6%B5%8B%E8%AF%95%E5%B7%A5%E4%BD%9C%E9%97%AE%E9%A2%98%E5%92%8C%E6%80%BB%E7%BB%93/:2:1","tags":["测试"],"title":"系统、数据库性能测试记录","uri":"/%E6%B5%8B%E8%AF%95%E5%B7%A5%E4%BD%9C%E9%97%AE%E9%A2%98%E5%92%8C%E6%80%BB%E7%BB%93/"},{"categories":["测试"],"content":"取样器 自定义url，token变量 测试线程递增配置-插件 Stepping Thread Group 的安装和处理 ","date":"2023-08-05","objectID":"/%E6%B5%8B%E8%AF%95%E5%B7%A5%E4%BD%9C%E9%97%AE%E9%A2%98%E5%92%8C%E6%80%BB%E7%BB%93/:2:2","tags":["测试"],"title":"系统、数据库性能测试记录","uri":"/%E6%B5%8B%E8%AF%95%E5%B7%A5%E4%BD%9C%E9%97%AE%E9%A2%98%E5%92%8C%E6%80%BB%E7%BB%93/"},{"categories":["测试"],"content":"控制器 一些特殊测试情况，不可让测试用例随机执行，如顺序执行，循环执行等情况。使用控制器进行管理。 多线程下取样顺序执行 逻辑控制器-临界资源控制器，给每个请求进行加锁 || 或单线程，设置一个线程顺序执行，会按照取样上下顺序 多线程下只进行一次取样 逻辑控制器-仅一次控制器 CVS文件 对于大批量的数据，如批量的URL，批量的SQL语句等，可以通过CVS文件读取的方式，快速执行取样配置 ","date":"2023-08-05","objectID":"/%E6%B5%8B%E8%AF%95%E5%B7%A5%E4%BD%9C%E9%97%AE%E9%A2%98%E5%92%8C%E6%80%BB%E7%BB%93/:2:3","tags":["测试"],"title":"系统、数据库性能测试记录","uri":"/%E6%B5%8B%E8%AF%95%E5%B7%A5%E4%BD%9C%E9%97%AE%E9%A2%98%E5%92%8C%E6%80%BB%E7%BB%93/"},{"categories":["测试"],"content":"测试报告 环境配置及命令 linux中环境的配置 https://blog.csdn.net/Mrlijie00/article/details/121040418 -n 非GUI 模式运行 JMeter -t 选择 .jmx 运行的jMeter 测试脚本文件 -l 结果 日志文件，记录结果的文件 后缀要是 .jtl -e 生成报告 -o 输出报告文件 删除测试报告记录 rm -rf /sda/apache-jmeter-5.3/bin/report_output 删除测试日志 rm -rf /sda/apache-jmeter-5.3/bin/logFile 执行测试语句 ./jmeter.sh -n -t /sda/apache-jmeter-5.3/jmx/test.jmx -l logFile-e -o ./report_output 测试报告的汉化操作 https://gitee.com/smooth00/jmeter-cn-report-template ","date":"2023-08-05","objectID":"/%E6%B5%8B%E8%AF%95%E5%B7%A5%E4%BD%9C%E9%97%AE%E9%A2%98%E5%92%8C%E6%80%BB%E7%BB%93/:3:0","tags":["测试"],"title":"系统、数据库性能测试记录","uri":"/%E6%B5%8B%E8%AF%95%E5%B7%A5%E4%BD%9C%E9%97%AE%E9%A2%98%E5%92%8C%E6%80%BB%E7%BB%93/"},{"categories":["测试"],"content":"服务器监控 对于Api测试，试用k8s中的Prometheus+Grafana 进行性能的监控 对于数据测试，因为是裸服务器，只有基本数据库和数据，无权限按照其他监控软件。故使用 sar 命令进行监控，将监控数据导出为文件，处理至excel后，转为折线图，展示性能情况。 后台执行cpu监测，5秒一次，执行180次==15分钟 nohup sar -u 5 180 \u003e/sarCpu.txt \u0026 后台执行Mem监测，5秒一次，执行180次==15分钟 nohup sar -r 5 180 \u003e/sarMem.txt \u0026 ","date":"2023-08-05","objectID":"/%E6%B5%8B%E8%AF%95%E5%B7%A5%E4%BD%9C%E9%97%AE%E9%A2%98%E5%92%8C%E6%80%BB%E7%BB%93/:4:0","tags":["测试"],"title":"系统、数据库性能测试记录","uri":"/%E6%B5%8B%E8%AF%95%E5%B7%A5%E4%BD%9C%E9%97%AE%E9%A2%98%E5%92%8C%E6%80%BB%E7%BB%93/"},{"categories":["测试"],"content":"复盘\u0026思考 ","date":"2023-08-05","objectID":"/%E6%B5%8B%E8%AF%95%E5%B7%A5%E4%BD%9C%E9%97%AE%E9%A2%98%E5%92%8C%E6%80%BB%E7%BB%93/:5:0","tags":["测试"],"title":"系统、数据库性能测试记录","uri":"/%E6%B5%8B%E8%AF%95%E5%B7%A5%E4%BD%9C%E9%97%AE%E9%A2%98%E5%92%8C%E6%80%BB%E7%BB%93/"},{"categories":["测试"],"content":"Jmeter可以在开发中提供哪些帮助 分布式数据幂等性测试，大批测试数据入库 ","date":"2023-08-05","objectID":"/%E6%B5%8B%E8%AF%95%E5%B7%A5%E4%BD%9C%E9%97%AE%E9%A2%98%E5%92%8C%E6%80%BB%E7%BB%93/:5:1","tags":["测试"],"title":"系统、数据库性能测试记录","uri":"/%E6%B5%8B%E8%AF%95%E5%B7%A5%E4%BD%9C%E9%97%AE%E9%A2%98%E5%92%8C%E6%80%BB%E7%BB%93/"},{"categories":["测试"],"content":"如果再来一次，该如何优化以上过程 使用工具如jenkins，将脚本自动化执行，完成测试，输出报告，输出内容的过程。可以写代码处理。而不是手动执行，手动录入。（经验不足导致） ","date":"2023-08-05","objectID":"/%E6%B5%8B%E8%AF%95%E5%B7%A5%E4%BD%9C%E9%97%AE%E9%A2%98%E5%92%8C%E6%80%BB%E7%BB%93/:5:2","tags":["测试"],"title":"系统、数据库性能测试记录","uri":"/%E6%B5%8B%E8%AF%95%E5%B7%A5%E4%BD%9C%E9%97%AE%E9%A2%98%E5%92%8C%E6%80%BB%E7%BB%93/"},{"categories":["测试"],"content":"其他思考 【设计】GUI界面设计的灵活性 【对比】postman、apipost差异 【源码】线程组设计，自己设计一个线程处理函数，可以扩展，动态配置 【源码】POI模板报告的组合与生成 ","date":"2023-08-05","objectID":"/%E6%B5%8B%E8%AF%95%E5%B7%A5%E4%BD%9C%E9%97%AE%E9%A2%98%E5%92%8C%E6%80%BB%E7%BB%93/:5:3","tags":["测试"],"title":"系统、数据库性能测试记录","uri":"/%E6%B5%8B%E8%AF%95%E5%B7%A5%E4%BD%9C%E9%97%AE%E9%A2%98%E5%92%8C%E6%80%BB%E7%BB%93/"},{"categories":["其他"],"content":"三方对接思考","date":"2023-07-29","objectID":"/%E4%B8%89%E6%96%B9%E5%AF%B9%E6%8E%A5%E6%80%9D%E8%80%83/","tags":["其他"],"title":"三方对接思考","uri":"/%E4%B8%89%E6%96%B9%E5%AF%B9%E6%8E%A5%E6%80%9D%E8%80%83/"},{"categories":["其他"],"content":"三方对接思考 ","date":"2023-07-29","objectID":"/%E4%B8%89%E6%96%B9%E5%AF%B9%E6%8E%A5%E6%80%9D%E8%80%83/:0:0","tags":["其他"],"title":"三方对接思考","uri":"/%E4%B8%89%E6%96%B9%E5%AF%B9%E6%8E%A5%E6%80%9D%E8%80%83/"},{"categories":["其他"],"content":"一 使用HTTP协议，来进行交互，对失败的请求进行内存重试3次，3次后丢弃 ","date":"2023-07-29","objectID":"/%E4%B8%89%E6%96%B9%E5%AF%B9%E6%8E%A5%E6%80%9D%E8%80%83/:1:0","tags":["其他"],"title":"三方对接思考","uri":"/%E4%B8%89%E6%96%B9%E5%AF%B9%E6%8E%A5%E6%80%9D%E8%80%83/"},{"categories":["其他"],"content":"二 对失败的数据进行持久化重试，存放于数据库中，用定时任务来对失败的数据进行重新处理，重试3次以后丢弃，3次的间隔时间固定 ","date":"2023-07-29","objectID":"/%E4%B8%89%E6%96%B9%E5%AF%B9%E6%8E%A5%E6%80%9D%E8%80%83/:2:0","tags":["其他"],"title":"三方对接思考","uri":"/%E4%B8%89%E6%96%B9%E5%AF%B9%E6%8E%A5%E6%80%9D%E8%80%83/"},{"categories":["其他"],"content":"三 优化重试策略，考虑到如果重试时间间隔设置得太短，三方宕机短时间内无法恢复，会跳过3次重试时间隔离。 如果重试次数太多，比如设置10次，1是耗资源（对方服务短时间内能恢复的就已经恢复了，恢复不了的，短时间内重试这么多次也没有意义），2是定时任务不能很快的处理到新产生的数据 如果重试时间间隔太长，三方系统恢复后，又需要很长时间才能接收到。 折中的方案是优化策略为指数的重试方式，1次失败1分钟，2次失败2分钟后重试，3次失败4分钟后重试，以此累加 ","date":"2023-07-29","objectID":"/%E4%B8%89%E6%96%B9%E5%AF%B9%E6%8E%A5%E6%80%9D%E8%80%83/:3:0","tags":["其他"],"title":"三方对接思考","uri":"/%E4%B8%89%E6%96%B9%E5%AF%B9%E6%8E%A5%E6%80%9D%E8%80%83/"},{"categories":["其他"],"content":"四 重试是由定时任务发起，为了不重复执行，所以执行线程只有1个，数据量过大，可能会显得力不从心 这时候可能考虑多开几个线程并行跑，来加快数据的传输 想要多开线程，就需要考虑线程之间的任务分配，可以通过取模，范围等方式来做任务分配，来达到加快同步效率的目的 ","date":"2023-07-29","objectID":"/%E4%B8%89%E6%96%B9%E5%AF%B9%E6%8E%A5%E6%80%9D%E8%80%83/:4:0","tags":["其他"],"title":"三方对接思考","uri":"/%E4%B8%89%E6%96%B9%E5%AF%B9%E6%8E%A5%E6%80%9D%E8%80%83/"},{"categories":["其他"],"content":"五 单机情况下的线程任务，存在线程中断，阻塞与单机瓶颈问题， 线程中断是指，程序业务逻辑出现未知异常导致线程中断，中断后该线程所负责的任务不能得到执行（比如该线程负责的1-100条之间的记录） 线程阻塞是指，HTTP网络阻塞（比如 restTemplate的超时时间会导致此问题），或者CPU未分配到执行此任务的片短，CPU在忙着搞其他具有更高优先级的事情，或者有其他线程一直占用着CPU使用权导致该任务线程一直挂起 单机瓶颈是指该服务一台机器处理能力有限 或者 由于异常问题导致宕机，假死，等不可控因素时任务得不到执行 考虑到以上问题，可能需求使用到分布式任务系统，当一个线程死掉后，有其他线程来完成他的工作，当一台机器死掉后，有其他机器来完成这台机器的工作 ","date":"2023-07-29","objectID":"/%E4%B8%89%E6%96%B9%E5%AF%B9%E6%8E%A5%E6%80%9D%E8%80%83/:5:0","tags":["其他"],"title":"三方对接思考","uri":"/%E4%B8%89%E6%96%B9%E5%AF%B9%E6%8E%A5%E6%80%9D%E8%80%83/"},{"categories":["其他"],"content":"六 与三方同步发生异常时研发团队得不到通知，发生问题不能得到及时处理，等到用户发现，或者三方研发发现，再返馈到我方，就太晚了，所以需要一套完整的业务监控系统，通过先于用户，先于三方发现问题，并解决问题 ","date":"2023-07-29","objectID":"/%E4%B8%89%E6%96%B9%E5%AF%B9%E6%8E%A5%E6%80%9D%E8%80%83/:6:0","tags":["其他"],"title":"三方对接思考","uri":"/%E4%B8%89%E6%96%B9%E5%AF%B9%E6%8E%A5%E6%80%9D%E8%80%83/"},{"categories":["其他"],"content":"七 公司团队的业务很多，只要不是孤岛，很多业务都需要与三方对接，每一次的对接成本都做到这种程度，是一件即废人力，又废物力，又浪费时间的做法 如果能将这一套流程平台化，抽象为一个与三方对接的公共平台，那业务团队只需要做一件事，那就是将“需要同步的数据存在自己业务的数据库里\"，后面的事情交给专门的系统来做专业的事情 来达到每一次对接都是最高的对接，每一次对接的成本都是最低 ","date":"2023-07-29","objectID":"/%E4%B8%89%E6%96%B9%E5%AF%B9%E6%8E%A5%E6%80%9D%E8%80%83/:7:0","tags":["其他"],"title":"三方对接思考","uri":"/%E4%B8%89%E6%96%B9%E5%AF%B9%E6%8E%A5%E6%80%9D%E8%80%83/"},{"categories":["其他"],"content":"八 既然做了平台化，那似乎还可以做更多的事情 任务可以实现动态分配，线程数，任务数，频次，重试策略，延迟投放，去重 等，来满足不停变化的需求与数据 每一条数据的来往，三方的处理结果都清晰的存在平台数据库中，能够实现后期排查定位和分析 三方团队研发能力或需求理解能力不一，常常程序运行一段时间后，希望我们重新推送，以往是遇到这种情况，可能需求手动刷库，一是不安全，二是不方便。平台可以通过可视化操作，对指定数据来重放，实现重新推送 能够监控到每一个与三方的同步情况，同步了多少数据，还剩多少，有多少成功的，有多少失败的，同步的性能怎么样，三方的处理能力怎么样，等等执行情况 ","date":"2023-07-29","objectID":"/%E4%B8%89%E6%96%B9%E5%AF%B9%E6%8E%A5%E6%80%9D%E8%80%83/:8:0","tags":["其他"],"title":"三方对接思考","uri":"/%E4%B8%89%E6%96%B9%E5%AF%B9%E6%8E%A5%E6%80%9D%E8%80%83/"},{"categories":["分布式"],"content":"分布式常见问题记录","date":"2023-07-29","objectID":"/%E5%88%86%E5%B8%83%E5%BC%8F%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/","tags":["分布式"],"title":"分布式常见问题记录","uri":"/%E5%88%86%E5%B8%83%E5%BC%8F%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/"},{"categories":["分布式"],"content":"分布式幂等、分布式锁 ","date":"2023-07-29","objectID":"/%E5%88%86%E5%B8%83%E5%BC%8F%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/:0:0","tags":["分布式"],"title":"分布式常见问题记录","uri":"/%E5%88%86%E5%B8%83%E5%BC%8F%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/"},{"categories":["分布式"],"content":"概念理解： 对于相同的请求应该返回相同的结果，所以查询类接口是天然的幂等性接口。 或者说：幂等指的是相同请求（identical request）执行一次或者多次所带来的副作 用（side-effects）是一样的。 在分布式条件下服务的设计中，如果与其他服务（或者是第三方）有复杂且密度很高的交互，且这种交互无法主动控制，那么必须使用一些策略来保证数据幂等。 ","date":"2023-07-29","objectID":"/%E5%88%86%E5%B8%83%E5%BC%8F%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/:1:0","tags":["分布式"],"title":"分布式常见问题记录","uri":"/%E5%88%86%E5%B8%83%E5%BC%8F%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/"},{"categories":["分布式"],"content":"什么常见会出现幂等？ 场景1：前端调后端接口发起支付超时，然后再次发起重试。可能会导致多次支付。 场景2：页面上未做防抖进行了多次点击。 场景3：被动订阅其他服务数据时，无法控制对方的推送，则需要在自己服务内做幂等处理。 ","date":"2023-07-29","objectID":"/%E5%88%86%E5%B8%83%E5%BC%8F%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/:2:0","tags":["分布式"],"title":"分布式常见问题记录","uri":"/%E5%88%86%E5%B8%83%E5%BC%8F%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/"},{"categories":["分布式"],"content":"总结：: 接口的幂等性实际上就是接口可重复调用，在调用方多次调用的情况下，接口最终得到的结果是一致的 。 ","date":"2023-07-29","objectID":"/%E5%88%86%E5%B8%83%E5%BC%8F%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/:3:0","tags":["分布式"],"title":"分布式常见问题记录","uri":"/%E5%88%86%E5%B8%83%E5%BC%8F%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/"},{"categories":["分布式"],"content":"解决方案 各种各样的技术方案，总的来说都是无非就是基于语言特性（底层cpu的原子性）或者基于 CAS（Compare And Swap）的概念进行不同的处理 ","date":"2023-07-29","objectID":"/%E5%88%86%E5%B8%83%E5%BC%8F%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/:4:0","tags":["分布式"],"title":"分布式常见问题记录","uri":"/%E5%88%86%E5%B8%83%E5%BC%8F%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/"},{"categories":["分布式"],"content":"语言层面 synchronized或者java原子类 AtomicInteger， 利用CPU提供的CAS操作来保证原子性（除了AtomicInteger外，还有AtomicBoolean、AtomicLong、AtomicReference等众多原子类） ","date":"2023-07-29","objectID":"/%E5%88%86%E5%B8%83%E5%BC%8F%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/:4:1","tags":["分布式"],"title":"分布式常见问题记录","uri":"/%E5%88%86%E5%B8%83%E5%BC%8F%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/"},{"categories":["分布式"],"content":"数据库层面 悲观锁（select …… for update） 会在数据库加上排它锁，直到事务提交或回滚时才会释放排它锁； 在此期间，如果其他线程试图更新该玩家信息或者执行select for update，会被阻塞 ","date":"2023-07-29","objectID":"/%E5%88%86%E5%B8%83%E5%BC%8F%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/:4:2","tags":["分布式"],"title":"分布式常见问题记录","uri":"/%E5%88%86%E5%B8%83%E5%BC%8F%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/"},{"categories":["分布式"],"content":"业务层面 乐观锁 乐观锁即版本号机制，本身是不加锁的，存于数据库中，通过唯一标识，时间戳、唯一索引等，在操作数据时先插叙，再进行比较，从而判断数据是否应该处理 分布式锁 即：SET EX|PX NX + 校验唯一随机值 EX参数用于设置键的过期时间，单位为秒。 PX参数用于设置键的过期时间，单位为毫秒。 NX: 如果key不存在，则会将key设置为value，并返回1；如果key存在，不会有任务影响，返回0。 锁命名规范：命名空间（Namespace）：业务标识（Business Identifier）：版本号（Versioning）：节点标识（Node Identifier）：唯一标识（结合业务自定义） eg: SJZT:USER_UPDATE:v1:NODE1（数据中台：用户更新：版本v1：节点1：自定义标识） 链接参考： https://www.cnblogs.com/linjiqin/p/8003838.html https://blog.csdn.net/weixin_43844718/article/details/126463959 示例代码 使用的时候很简单，spring中封装了redisson，需要注意解锁的处理 RLock lock = this.redissonClient.getLock(MessageTypeEnum.getRedisLockName(msgType) + dto.getId()); boolean lockSuccess = false; try { lockSuccess = lock.tryLock(5L , TimeUnit.SECONDS); if (! lockSuccess) { return MessageBuilder.failed(\"添加用户：数据校验失败，获取锁失败！\"); } // do somthing if (lock.isLocked() \u0026\u0026 lock.isHeldByCurrentThread()) { lock.unlock(); } } catch (InterruptedException e) { throw new DataException(e.getMessage()); } finally { if (lockSuccess \u0026\u0026 lock.isLocked() \u0026\u0026 lock.isHeldByCurrentThread()) { lock.unlock(); }} ","date":"2023-07-29","objectID":"/%E5%88%86%E5%B8%83%E5%BC%8F%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/:4:3","tags":["分布式"],"title":"分布式常见问题记录","uri":"/%E5%88%86%E5%B8%83%E5%BC%8F%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/"},{"categories":["分布式"],"content":"一些问题 ","date":"2023-07-29","objectID":"/%E5%88%86%E5%B8%83%E5%BC%8F%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/:5:0","tags":["分布式"],"title":"分布式常见问题记录","uri":"/%E5%88%86%E5%B8%83%E5%BC%8F%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/"},{"categories":["分布式"],"content":"乐观锁和悲观锁优缺点和适用场景 乐观锁和悲观锁并没有优劣之分，它们有各自适合的场景；下面从两个方面进行说明。 功能限制 与悲观锁相比，乐观锁适用的场景受到了更多的限制，无论是CAS还是版本号机制。 例如，CAS只能保证单个变量操作的原子性，当涉及到多个变量时，CAS是无能为力的，而synchronized则可以通过对整个代码块加锁来处理。 再比如版本号机制，如果query的时候是针对表1，而update的时候是针对表2，也很难通过简单的版本号来实现乐观锁。 竞争激烈程度 如果悲观锁和乐观锁都可以使用，那么选择就要考虑竞争的激烈程度 当竞争不激烈 (出现并发冲突的概率小)时，乐观锁更有优势，因为悲观锁会锁住代码块或数据，其他线程无法同时访问，影响并发，而且加锁和释放锁都需要消耗额外的资源。 当竞争激烈(出现并发冲突的概率大)时，悲观锁更有优势，因为乐观锁在执行更新时频繁失败，需要不断重试，浪费CPU资源。 ","date":"2023-07-29","objectID":"/%E5%88%86%E5%B8%83%E5%BC%8F%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/:5:1","tags":["分布式"],"title":"分布式常见问题记录","uri":"/%E5%88%86%E5%B8%83%E5%BC%8F%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/"},{"categories":["分布式"],"content":"CAS中的ABA问题 1.ABA问题 假设有两个线程——线程1和线程2，两个线程按照顺序进行以下操作： (1)线程1读取内存中数据为A； (2)线程2将该数据修改为B； (3)线程2将该数据修改为A； (4)线程1对数据进行CAS操作 在第(4)步中，由于内存中数据仍然为A，因此CAS操作成功，但实际上该数据已经被线程2修改过了。这就是ABA问题。 在AtomicInteger的例子中，ABA似乎没有什么危害。 但是在某些场景下，ABA却会带来隐患，例如栈顶问题：一个栈的栈顶经过两次(或多次)变化又恢复了原值，但是栈可能已发生了变化。 对于ABA问题，比较有效的方案是引入版本号，内存中的值每发生一次变化，版本号都+1； 在进行CAS操作时，不仅比较内存中的值，也会比较版本号，只有当二者都没有变化时，CAS才能执行成功。 Java中的AtomicStampedReference类便是使用版本号来解决ABA问题的。 2.高竞争下的开销问题 在并发冲突概率大的高竞争环境下，如果CAS一直失败，会一直重试，CPU开销较大。 针对这个问题的一个思路是引入退出机制，如重试次数超过一定阈值后失败退出。 当然，更重要的是避免在高竞争环境下使用乐观锁。 3.功能限制 CAS的功能是比较受限的，例如CAS只能保证单个变量（或者说单个内存值）操作的原子性，这意味着： (1)原子性不一定能保证线程安全，例如在Java中需要与volatile配合来保证线程安全； (2)当涉及到多个变量(内存值)时，CAS也无能为力。 除此之外，CAS的实现需要硬件层面处理器的支持，在Java中普通用户无法直接使用，只能借助atomic包下的原子类使用，灵活性受到限制。 分布式事务 这个讲的很清楚 https://www.zhihu.com/question/64921387/answer/225784480 【以下为复制】 关于分布式事务，工程领域主要讨论的是强一致性和最终一致性的解决方案。典型方案包括： 两阶段提交（2PC, Two-phase Commit）方案 eBay 事件队列方案 TCC 补偿模式 缓存数据最终一致性 ","date":"2023-07-29","objectID":"/%E5%88%86%E5%B8%83%E5%BC%8F%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/:5:2","tags":["分布式"],"title":"分布式常见问题记录","uri":"/%E5%88%86%E5%B8%83%E5%BC%8F%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/"},{"categories":["分布式"],"content":"一、一致性理论 分布式事务的目的是保障分库数据一致性，而跨库事务会遇到各种不可控制的问题，如个别节点永久性宕机，像单机事务一样的ACID是无法奢望的。另外，业界著名的CAP理论 也告诉我们，对分布式系统，需要将数据一致性和系统可用性、分区容忍性放在天平上一起考虑。 两阶段提交协议（简称2PC）是实现分布式事务较为经典的方案，但2PC 的可扩展性很差，在分布式架构下应用代价较大，eBay 架构师 Dan Pritchett 提出了BASE 理论，用于解决大规模分布式系统下的数据一致性问题。BASE 理论告诉我们：可以通过放弃系统在每个时刻的强一致性来换取系统的可扩展性。 ","date":"2023-07-29","objectID":"/%E5%88%86%E5%B8%83%E5%BC%8F%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/:6:0","tags":["分布式"],"title":"分布式常见问题记录","uri":"/%E5%88%86%E5%B8%83%E5%BC%8F%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/"},{"categories":["分布式"],"content":"1、CAP理论 在分布式系统中，一致性（Consistency）、可用性（Availability）和分区容忍性 （Partition Tolerance）3 个要素最多只能同时满足两个，不可兼得。其中，分区容忍性又是不可或缺的。 一致性：分布式环境下多个节点的数据是否强一致。 可用性：分布式服务能一直保证可用状态。当用户发出一个请求后，服务能在有限时间内返回结果。 分区容忍性：特指对网络分区 的容忍性。 举例：Cassandra、Dynamo 等，默认优先选择AP，弱化C；HBase、MongoDB 等，默认优先选择CP，弱化A。 ","date":"2023-07-29","objectID":"/%E5%88%86%E5%B8%83%E5%BC%8F%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/:6:1","tags":["分布式"],"title":"分布式常见问题记录","uri":"/%E5%88%86%E5%B8%83%E5%BC%8F%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/"},{"categories":["分布式"],"content":"2、BASE 理论 核心思想： 基本可用（Basically Available）：指分布式系统在出现故障时，允许损失部分的可用性来保证核心可用。 软状态（Soft State）：指允许分布式系统存在中间状态，该中间状态不会影响到系统的整体可用性。 最终一致性（Eventual Consistency）：指分布式系统中的所有副本数据经过一定时间后，最终能够达到一致的状态。 ","date":"2023-07-29","objectID":"/%E5%88%86%E5%B8%83%E5%BC%8F%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/:6:2","tags":["分布式"],"title":"分布式常见问题记录","uri":"/%E5%88%86%E5%B8%83%E5%BC%8F%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/"},{"categories":["分布式"],"content":"二、一致性模型 数据的一致性模型可以分成以下 3 类： 强一致性：数据更新成功后，任意时刻所有副本中的数据都是一致的，一般采用同步的方式实现。 弱一致性：数据更新成功后，系统不承诺立即可以读到最新写入的值，也不承诺具体多久之后可以读到。 最终一致性：弱一致性的一种形式，数据更新成功后，系统不承诺立即可以返回最新写入的值，但是保证最终会返回上一次更新操作的值。 分布式系统数据一致性模型可以通过Quorum NRW算法分析。 不少朋友向我们反馈处理企业数据一致性时成本过高、事务执行状态不透明，如果您也遇到同样的情况，欢迎了解网易数帆【分布式事务GTXS】，限时领取定制化企业方案，帮您解决数据一致性处理难题： ","date":"2023-07-29","objectID":"/%E5%88%86%E5%B8%83%E5%BC%8F%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/:7:0","tags":["分布式"],"title":"分布式常见问题记录","uri":"/%E5%88%86%E5%B8%83%E5%BC%8F%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/"},{"categories":["分布式"],"content":"三、分布式事务解决方案 ","date":"2023-07-29","objectID":"/%E5%88%86%E5%B8%83%E5%BC%8F%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/:8:0","tags":["分布式"],"title":"分布式常见问题记录","uri":"/%E5%88%86%E5%B8%83%E5%BC%8F%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/"},{"categories":["分布式"],"content":"1、2PC方案——强一致性 2PC的核心原理是通过提交分阶段和记日志的方式，记录下事务提交所处的阶段状态，在组件宕机重启后，可通过日志恢复事务提交的阶段状态，并在这个状态节点重试，如Coordinator重启后，通过日志可以确定提交处于Prepare还是PrepareAll状态，若是前者，说明有节点可能没有Prepare成功，或所有节点Prepare成功但还没有下发Commit，状态恢复后给所有节点下发RollBack；若是PrepareAll状态，需要给所有节点下发Commit，数据库节点需要保证Commit幂 等。 2PC方案的问题： 同步阻塞。 数据不一致。 单点问题。 升级的3PC方案旨在解决这些问题，主要有两个改进： 增加超时机制。 两阶段之间插入准备阶段。 但三阶段提交 也存在一些缺陷，要彻底从协议层面避免数据不一致，可以采用Paxos 或者Raft 算法 。 ","date":"2023-07-29","objectID":"/%E5%88%86%E5%B8%83%E5%BC%8F%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/:8:1","tags":["分布式"],"title":"分布式常见问题记录","uri":"/%E5%88%86%E5%B8%83%E5%BC%8F%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/"},{"categories":["分布式"],"content":"2、eBay 事件队列方案——最终一致性 eBay 的架构师Dan Pritchett，曾在一篇解释BASE 原理的论文《Base：An Acid Alternative 》中提到一个eBay 分布式 系统一致性问题的解决方案。它的核心思想是将需要分布式处理的任务通过消息或者日志的方式来异步执行，消息或日志可以存到本地文件、数据库或消息队列 ，再通过业务规则进行失败重试，它要求各服务的接口是幂等 的。 描述的场景为，有用户表user 和交易表transaction，用户表存储用户信息、总销售额和总购买额，交易表存储每一笔交易的流水号、买家信息、卖家信息和交易金额 。如果产生了一笔交易，需要在交易表增加记录，同时还要修改用户表的金额。 论文中提出的解决方法是将更新交易表记录和用户表更新消息放在一个本地事务来完成，为了避免重复消费用户表更新消息带来的问题，增加一个操作记录表updates_applied来记录已经完成的交易相关的信息。 这个方案的核心在于第二阶段的重试和幂等执行。失败后重试，这是一种补偿机制 ，它是能保证系统最终一致的关键流程。 ","date":"2023-07-29","objectID":"/%E5%88%86%E5%B8%83%E5%BC%8F%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/:8:2","tags":["分布式"],"title":"分布式常见问题记录","uri":"/%E5%88%86%E5%B8%83%E5%BC%8F%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/"},{"categories":["分布式"],"content":"3、TCC （Try-Confirm-Cancel）补偿模式——最终一致性 某业务模型如图，由服务 A、服务B、服务C、服务D 共同组成的一个微服务架构 系统。服务A 需要依次调用服务B、服务C 和服务D 共同完成一个操作。当服务A 调用服务D 失败时，若要保证整个系统数据的一致性，就要对服务B 和服务C 的invoke 操作进行回滚，执行反向的revert 操作。回滚成功后，整个微服务系统是数据一致的。 实现关键要素： 服务调用链必须被记录下来。 每个服务提供者都需要提供一组业务逻辑相反的操作，互为补偿，同时回滚操作要保证幂等。 必须按失败原因执行不同的回滚策略。 ","date":"2023-07-29","objectID":"/%E5%88%86%E5%B8%83%E5%BC%8F%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/:8:3","tags":["分布式"],"title":"分布式常见问题记录","uri":"/%E5%88%86%E5%B8%83%E5%BC%8F%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/"},{"categories":["分布式"],"content":"4、缓存数据最终一致性 在我们的业务系统中，缓存（Redis 或者Memcached）通常被用在数据库前面，作为数据读取的缓冲，使得I/O 操作不至于直接落在数据库上。以商品详情页 为例，假如卖家修改了商品信息 ，并写回到数据库，但是这时候用户从商品详情页看到的信息还是从缓存中拿到的过时数据，这就出现了缓存系统和数据库系统 中的数据不一致的现象。 要解决该场景下缓存和数据库数据不一致的问题我们有以下两种解决方案： 为缓存数据设置过期时间。当缓存中数据过期后，业务系统会从数据库中获取数据，并将新值放入缓存。这个过期时间就是系统可以达到最终一致的容忍时间。 更新数据库数据后同时清除缓存数据。数据库数据更新后，同步删除缓存中数据，使得下次对商品详情的获取直接从数据库中获取，并同步到缓存。 网易数帆分布式事务，高性能、高可靠、低成本，保障数据一致性，目前已成熟运用于金融、能源等行业。欢迎体验，一起保卫企业数据安全~ ","date":"2023-07-29","objectID":"/%E5%88%86%E5%B8%83%E5%BC%8F%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/:8:4","tags":["分布式"],"title":"分布式常见问题记录","uri":"/%E5%88%86%E5%B8%83%E5%BC%8F%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/"},{"categories":["分布式"],"content":"四、选择建议 最后，面临数据一致性问题的时候，主要从业务需求的角度出发，确定我们对于3 种一致性模型的接受程度，再通过具体场景来决定解决方案。 从应用角度看，分布式事务的现实场景常常无法规避，在有能力给出其他解决方案前，2PC也是一个不错的选择。对购物转账等电商和金融业务，中间件 层的2PC最大问题在于业务不可见，一旦出现不可抗力或意想不到的一致性破坏，如数据节点永久性宕机，业务难以根据2PC的日志进行补偿。金融场景下，数据一致性是命根，业务需要对数据有百分之百的掌控力，建议使用TCC这类分布式事务模型 ，或基于消息队列的柔性事务框架，这两种方案都在业务层实现，业务开发者具有足够掌控力，可以结合SOA框架来架构，包括Dubbo、Spring Cloud等 分布式ID 唯一性：确保生成的ID是全网唯一的。 有序递增性：确保生成的ID是对于某个用户或者业务是按一定的数字有序递增的。 高可用性：确保任何时候都能正确的生成ID。 带时间：ID里面包含时间，一眼扫过去就知道哪天的交易。 ","date":"2023-07-29","objectID":"/%E5%88%86%E5%B8%83%E5%BC%8F%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/:9:0","tags":["分布式"],"title":"分布式常见问题记录","uri":"/%E5%88%86%E5%B8%83%E5%BC%8F%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/"},{"categories":["分布式"],"content":"1. UUID 算法的核心思想是结合机器的网卡、当地时间、一个随记数来生成UUID。 优点：本地生成，生成简单，性能好，没有高可用风险 缺点：长度过长，存储冗余，且无序不可读，查询效率低 ","date":"2023-07-29","objectID":"/%E5%88%86%E5%B8%83%E5%BC%8F%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/:10:0","tags":["分布式"],"title":"分布式常见问题记录","uri":"/%E5%88%86%E5%B8%83%E5%BC%8F%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/"},{"categories":["分布式"],"content":"2. 数据库自增ID 使用数据库的id自增策略，如 MySQL 的 auto_increment。并且可以使用两台数据库分别设置不同 步长，生成不重复ID的策略来实现高可用。 优点：数据库生成的ID绝对有序，高可用实现方式简单 缺点：需要独立部署数据库实例，成本高，有性能瓶颈 ","date":"2023-07-29","objectID":"/%E5%88%86%E5%B8%83%E5%BC%8F%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/:11:0","tags":["分布式"],"title":"分布式常见问题记录","uri":"/%E5%88%86%E5%B8%83%E5%BC%8F%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/"},{"categories":["分布式"],"content":"批量生成ID 一次按需批量生成多个ID，每次生成都需要访问数据库，将数据库修改为最大的ID值，并在内存中 记录当前值及最大值。 优点：避免了每次生成ID都要访问数据库并带来压力，提高性能 缺点：属于本地生成策略，存在单点故障，服务重启造成ID不连续 ","date":"2023-07-29","objectID":"/%E5%88%86%E5%B8%83%E5%BC%8F%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/:12:0","tags":["分布式"],"title":"分布式常见问题记录","uri":"/%E5%88%86%E5%B8%83%E5%BC%8F%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/"},{"categories":["分布式"],"content":"Redis生成ID Redis的所有命令操作都是单线程的，本身提供像 incr 和 increby 这样的自增原子命令，所以能保 证生成的 ID 肯定是唯一有序的。 优点：不依赖于数据库，灵活方便，且性能优于数据库；数字ID天然排序，对分页或者需要排序的结果很有帮助。 缺点：如果系统中没有Redis，还需要引入新的组件，增加系统复杂度；需要编码和配置的工作 量比较大。 考虑到单节点的性能瓶颈，可以使用 Redis 集群来获取更高的吞吐量。假如一个集群中有5台 Redis。可以初始化每台 Redis 的值分别是1, 2, 3, 4, 5，然后步长都是 5 Redis 的自增功能，通过 INCR 命令来实现。你可以为每个需要生成唯一 ID 的实体创建一个自增的计数器。 例如，对于用户，你可以创建一个键为 “user:id” 的计数器，每次需要生成新用户的 ID 时，可以使用 INCR 命令获取下一个唯一 ID。 127.0.0.1:6379\u003e SET user:id 1000 # 设置初始 ID OK 127.0.0.1:6379\u003e INCR user:id # 生成下一个唯一 ID (integer) 1001 127.0.0.1:6379\u003e INCR user:id # 再次生成下一个唯一 ID (integer) 1002 ","date":"2023-07-29","objectID":"/%E5%88%86%E5%B8%83%E5%BC%8F%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/:13:0","tags":["分布式"],"title":"分布式常见问题记录","uri":"/%E5%88%86%E5%B8%83%E5%BC%8F%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/"},{"categories":["分布式"],"content":"雪花算法 Snowflake Snowflake 算法由下面几部分组成： 1位符号位： 由于 long 类型在 java 中带符号的，最高位为符号位，正数为 0，负数为 1，且实际系统中所使用 的ID一般都是正数，所以最高位为 0。 41位时间戳（毫秒级）： 需要注意的是此处的 41 位时间戳并非存储当前时间的时间戳，而是存储时间戳的差值（当前时间 戳 - 起始时间戳），这里的起始时间戳一般是ID生成器开始使用的时间戳，由程序来指定，所以41 位毫秒时间戳最多可以使用 (1 « 41) / (1000x60x60x24x365) = 69年 。 10位数据机器位： 包括5位数据标识位和5位机器标识位，这10位决定了分布式系统中最多可以部署 1 « 10 = 1024 个节点。超过这个数量，生成的ID就有可能会冲突。 12位毫秒内的序列： 这 12 位计数支持每个节点每毫秒（同一台机器，同一时刻）最多生成 1 « 12 = 4096个ID 加起来刚好64位，为一个Long型。 优点：高性能，低延迟，按时间有序，一般不会造成ID碰撞 缺点：需要独立的开发和部署，依赖于机器的时钟 限流和熔断 参考博客 https://zhuanlan.zhihu.com/p/391779142 这个示例很清楚 https://blog.csdn.net/qq_38322527/article/details/106253143 官方文档 https://github.com/alibaba/Sentinel/wiki/%E4%BB%8B%E7%BB%8D 【以下为复制】 当系统的处理能力不能应对外部请求的突增流量时，为了不让系统崩溃，必须采取限流的措施。 在分布式系统中，如果某个服务节点发生故障或者网络发生异常，都有可能导致调用方被阻塞等待，如果超时时间设置很长，调用方资源很可能被耗尽。这又导致了调用方的上游系统发生资源耗尽的情况，最终导致系统雪崩。 如下图： 如果D服务发生了故障不能响应，B服务调用D时只能阻塞等待。假如B服务调用D服务设置超时时间是10秒，请求速率是每秒100个，那10秒内就会有1000个请求线程被阻塞等待，如果B的线程池大小设置1000，那B系统因为线程资源耗尽已经不能对外提供服务了。而这又影响了入口系统A的服务，最终导致系统全面崩溃。 提高系统的整体容错能力是防止系统雪崩的有效手段。 在Martin Fowler和James Lewis的文章 《Microservices: a definition of this new architectural term》[1]中，提出了微服务的9个特征，其中一个是容错设计。 要防止系统发生雪崩，就必须要有容错设计。如果遇到突增流量，一般的做法是对非核心业务功能采用熔断和服务降级的措施来保护核心业务功能正常服务，而对于核心功能服务，则需要采用限流的措施。 今天我们来聊一聊系统容错中的限流、熔断和服务降级。 ","date":"2023-07-29","objectID":"/%E5%88%86%E5%B8%83%E5%BC%8F%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/:14:0","tags":["分布式"],"title":"分布式常见问题记录","uri":"/%E5%88%86%E5%B8%83%E5%BC%8F%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/"},{"categories":["分布式"],"content":"1 限流 当系统的处理能力不能应对外部请求的突增流量时，为了不让系统崩溃，必须采取限流的措施。 ","date":"2023-07-29","objectID":"/%E5%88%86%E5%B8%83%E5%BC%8F%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/:15:0","tags":["分布式"],"title":"分布式常见问题记录","uri":"/%E5%88%86%E5%B8%83%E5%BC%8F%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/"},{"categories":["分布式"],"content":"1.1 限流指标 ","date":"2023-07-29","objectID":"/%E5%88%86%E5%B8%83%E5%BC%8F%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/:16:0","tags":["分布式"],"title":"分布式常见问题记录","uri":"/%E5%88%86%E5%B8%83%E5%BC%8F%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/"},{"categories":["分布式"],"content":"1.1.1 TPS 系统吞吐量是衡量系统性能的关键指标，按照事务的完成数量来限流是最合理的。 但是对实操性来说，按照事务来限流并不现实。在分布式系统中完成一笔事务需要多个系统的配合。比如我们在电商系统购物，需要订单、库存、账户、支付等多个服务配合完成，有的服务需要异步返回，这样完成一笔事务花费的时间可能会很长。如果按照TPS来进行限流，时间粒度可能会很大大，很难准确评估系统的响应性能。 ","date":"2023-07-29","objectID":"/%E5%88%86%E5%B8%83%E5%BC%8F%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/:17:0","tags":["分布式"],"title":"分布式常见问题记录","uri":"/%E5%88%86%E5%B8%83%E5%BC%8F%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/"},{"categories":["分布式"],"content":"1.1.2 HPS 每秒请求数，指每秒钟服务端收到客户端的请求数量。 如果一个请求完成一笔事务，那TPS和HPS是等同的。但在分布式场景下，完成一笔事务可能需要多次请求，所以TPS和HPS指标不能等同看待。 ","date":"2023-07-29","objectID":"/%E5%88%86%E5%B8%83%E5%BC%8F%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/:18:0","tags":["分布式"],"title":"分布式常见问题记录","uri":"/%E5%88%86%E5%B8%83%E5%BC%8F%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/"},{"categories":["分布式"],"content":"1.1.3 QPS 服务端每秒能够响应的客户端查询请求数量。 如果后台只有一台服务器，那HPS和QPS是等同的。但是在分布式场景下，每个请求需要多个服务器配合完成响应。 目前主流的限流方法多采用HPS作为限流指标。 ","date":"2023-07-29","objectID":"/%E5%88%86%E5%B8%83%E5%BC%8F%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/:19:0","tags":["分布式"],"title":"分布式常见问题记录","uri":"/%E5%88%86%E5%B8%83%E5%BC%8F%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/"},{"categories":["分布式"],"content":"1.2 限流方法 ","date":"2023-07-29","objectID":"/%E5%88%86%E5%B8%83%E5%BC%8F%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/:20:0","tags":["分布式"],"title":"分布式常见问题记录","uri":"/%E5%88%86%E5%B8%83%E5%BC%8F%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/"},{"categories":["分布式"],"content":"1.2.1 流量计数器 这是最简单直接的方法，比如限制每秒请求数量100，超过100的请求就拒绝掉。 但是这个方法存在2个明显的问题： 单位时间(比如1s)很难把控，如下图：这张图上，从下面时间看，HPS没有超过100，但是从上面看HPS超过100了。 有一段时间流量超了，也不一定真的需要限流，如下图，系统HPS限制50，虽然前3s流量超了，但是如果都超时时间设置为5s，并不需要限流。 ","date":"2023-07-29","objectID":"/%E5%88%86%E5%B8%83%E5%BC%8F%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/:21:0","tags":["分布式"],"title":"分布式常见问题记录","uri":"/%E5%88%86%E5%B8%83%E5%BC%8F%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/"},{"categories":["分布式"],"content":"1.2.2 滑动时间窗口 滑动时间窗口算法是目前比较流行的限流算法，主要思想是把时间看做是一个向前滚动的窗口，如下图： 开始的时候，我们把t1~t5看做一个时间窗口，每个窗口1s，如果我们定的限流目标是每秒50个请求，那t1~t5这个窗口的请求总和不能超过250个。 这个窗口是滑动的，下一秒的窗口成了t2~t6，这时把t1时间片的统计抛弃，加入t6时间片进行统计。这段时间内的请求数量也不能超过250个。 滑动时间窗口的优点是解决了流量计数器算法的缺陷，但是也有2个问题： 流量超过就必须抛弃或者走降级逻辑 对流量控制不够精细，不能限制集中在短时间内的流量，也不能削峰填谷 ","date":"2023-07-29","objectID":"/%E5%88%86%E5%B8%83%E5%BC%8F%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/:22:0","tags":["分布式"],"title":"分布式常见问题记录","uri":"/%E5%88%86%E5%B8%83%E5%BC%8F%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/"},{"categories":["分布式"],"content":"1.2.3 漏桶算法 漏桶算法的思想如下图： 在客户端的请求发送到服务器之前，先用漏桶缓存起来，这个漏桶可以是一个长度固定的队列，这个队列中的请求均匀地发送到服务端。 如果客户端的请求速率太快，漏桶的队列满了，就会被拒绝掉，或者走降级处理逻辑。这样服务端就不会受到突发流量的冲击。 漏桶算法的优点是实现简单，可以使用消息队列来削峰填谷。 但是也有3个问题需要考虑: 漏桶的大小，如果太大，可能给服务端带来较大处理压力，太小可能会有大量请求被丢弃。 漏桶给服务端的请求发送速率。 使用缓存请求的方式，会使请求响应时间变长。 ❝ 漏桶大小和发送速率这2个值在项目上线初期都会根据测试结果选择一个值，但是随着架构的改进和集群的伸缩，这2个值也会随之发生改变。 ❞ ","date":"2023-07-29","objectID":"/%E5%88%86%E5%B8%83%E5%BC%8F%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/:23:0","tags":["分布式"],"title":"分布式常见问题记录","uri":"/%E5%88%86%E5%B8%83%E5%BC%8F%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/"},{"categories":["分布式"],"content":"1.2.4 令牌桶算法 令牌桶算法就跟病人去医院看病一样，找医生之前需要先挂号，而医院每天放的号是有限的。当天的号用完了，第二天又会放一批号。 算法的基本思想就是周期性地执行下面的流程： 客户端在发送请求时，都需要先从令牌桶中获取令牌，如果取到了，就可以把请求发送给服务端，取不到令牌，就只能被拒绝或者走服务降级的逻辑。如下图： ❝ 令牌桶算法解决了漏桶算法的问题，而且实现并不复杂，使用信号量就可以实现。在实际限流场景中使用最多，比如google的guava中就实现了令牌桶算法限流，感兴趣可以研究一下。 ❞ ","date":"2023-07-29","objectID":"/%E5%88%86%E5%B8%83%E5%BC%8F%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/:24:0","tags":["分布式"],"title":"分布式常见问题记录","uri":"/%E5%88%86%E5%B8%83%E5%BC%8F%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/"},{"categories":["分布式"],"content":"1.2.5 分布式限流 如果在分布式系统场景下，上面介绍的4种限流算法是否还适用呢？ 以令牌桶算法为例，假如在电商系统中客户下了一笔订单，如下图： 如果我们把令牌桶单独保存在一个地方(比如redis中)供整个分布式系统用，那客户端在调用组合服务，组合服务调用订单、库存和账户服务都需要跟令牌桶交互，交互次数明显增加了很多。 有一种改进就是客户端调用组合服务之前首先获取四个令牌，调用组合服务时减去一个令牌并且传递给组合服务三个令牌，组合服务调用下面三个服务时依次消耗一个令牌。 ","date":"2023-07-29","objectID":"/%E5%88%86%E5%B8%83%E5%BC%8F%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/:25:0","tags":["分布式"],"title":"分布式常见问题记录","uri":"/%E5%88%86%E5%B8%83%E5%BC%8F%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/"},{"categories":["分布式"],"content":"1.2.6 hystrix限流 hystrix可以使用信号量和线程池来进行限流。 ","date":"2023-07-29","objectID":"/%E5%88%86%E5%B8%83%E5%BC%8F%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/:26:0","tags":["分布式"],"title":"分布式常见问题记录","uri":"/%E5%88%86%E5%B8%83%E5%BC%8F%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/"},{"categories":["分布式"],"content":"1.2.6.1 信号量限流 hystrix可以使用信号量进行限流，比如在提供服务的方法上加下面的注解。这样只能有20个并发线程来访问这个方法，超过的就被转到了errMethod这个降级方法。 @HystrixCommand( commandProperties= { @HystrixProperty(name=\"execution.isolation.strategy\", value=\"SEMAPHORE\"), @HystrixProperty(name=\"execution.isolation.semaphore.maxConcurrentRequests\", value=\"20\") }, fallbackMethod = \"errMethod\" ) ","date":"2023-07-29","objectID":"/%E5%88%86%E5%B8%83%E5%BC%8F%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/:27:0","tags":["分布式"],"title":"分布式常见问题记录","uri":"/%E5%88%86%E5%B8%83%E5%BC%8F%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/"},{"categories":["分布式"],"content":"1.2.6.2 线程池限流 hystrix也可以使用线程池进行限流，在提供服务的方法上加下面的注解，当线程数量 @HystrixCommand( commandProperties = { @HystrixProperty(name = \"execution.isolation.strategy\", value = \"THREAD\") }, threadPoolKey = \"createOrderThreadPool\", threadPoolProperties = { @HystrixProperty(name = \"coreSize\", value = \"20\"), @HystrixProperty(name = \"maxQueueSize\", value = \"100\"), @HystrixProperty(name = \"maximumSize\", value = \"30\"), @HystrixProperty(name = \"queueSizeRejectionThreshold\", value = \"120\") }, fallbackMethod = \"errMethod\" ) ❝ 这里要注意：在java的线程池中，如果线程数量超过coreSize，创建线程请求会优先进入队列，如果队列满了，就会继续创建线程直到线程数量达到maximumSize，之后走拒绝策略。但在hystrix配置的线程池中多了一个参数queueSizeRejectionThreshold，如果queueSizeRejectionThreshold \u003c maxQueueSize,队列数量达到queueSizeRejectionThreshold就会走拒绝策略了，因此maximumSize失效了。如果queueSizeRejectionThreshold \u003e maxQueueSize,队列数量达到maxQueueSize时，maximumSize是有效的，系统会继续创建线程直到数量达到maximumSize。Hytrix线程池设置坑[2] ❞ 熔断 相信大家对断路器并不陌生，它就相当于一个开关，打开后可以阻止流量通过。比如保险丝，当电流过大时，就会熔断，从而避免元器件损坏。 服务熔断是指调用方访问服务时通过断路器做代理进行访问，断路器会持续观察服务返回的成功、失败的状态，当失败超过设置的阈值时断路器打开，请求就不能真正地访问到服务了。 为了更好地理解，我画了下面的时序图： ","date":"2023-07-29","objectID":"/%E5%88%86%E5%B8%83%E5%BC%8F%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/:28:0","tags":["分布式"],"title":"分布式常见问题记录","uri":"/%E5%88%86%E5%B8%83%E5%BC%8F%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/"},{"categories":["分布式"],"content":"2.1 断路器的状态 断路器有3种状态： CLOSED：默认状态。断路器观察到请求失败比例没有达到阈值，断路器认为被代理服务状态良好。 OPEN：断路器观察到请求失败比例已经达到阈值，断路器认为被代理服务故障，打开开关，请求不再到达被代理的服务，而是快速失败。 HALF OPEN：断路器打开后，为了能自动恢复对被代理服务的访问，会切换到半开放状态，去尝试请求被代理服务以查看服务是否已经故障恢复。如果成功，会转成CLOSED状态，否则转到OPEN状态。 断路器的状态切换图如下： ","date":"2023-07-29","objectID":"/%E5%88%86%E5%B8%83%E5%BC%8F%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/:29:0","tags":["分布式"],"title":"分布式常见问题记录","uri":"/%E5%88%86%E5%B8%83%E5%BC%8F%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/"},{"categories":["分布式"],"content":"2.2 需要考虑的问题 使用断路器需要考虑一些问题： 针对不同的异常，定义不同的熔断后处理逻辑。 设置熔断的时长，超过这个时长后切换到HALF OPEN进行重试。 记录请求失败日志，供监控使用。 主动重试，比如对于connection timeout造成的熔断，可以用异步线程进行网络检测，比如telenet，检测到网络畅通时切换到HALF OPEN进行重试。 补偿接口，断路器可以提供补偿接口让运维人员手工关闭。 重试时，可以使用之前失败的请求进行重试，但一定要注意业务上是否允许这样做。 ","date":"2023-07-29","objectID":"/%E5%88%86%E5%B8%83%E5%BC%8F%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/:30:0","tags":["分布式"],"title":"分布式常见问题记录","uri":"/%E5%88%86%E5%B8%83%E5%BC%8F%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/"},{"categories":["分布式"],"content":"2.3 使用场景 服务故障或者升级时，让客户端快速失败 失败处理逻辑容易定义 响应耗时较长，客户端设置的read timeout会比较长，防止客户端大量重试请求导致的连接、线程资源不能释放 ","date":"2023-07-29","objectID":"/%E5%88%86%E5%B8%83%E5%BC%8F%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/:31:0","tags":["分布式"],"title":"分布式常见问题记录","uri":"/%E5%88%86%E5%B8%83%E5%BC%8F%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/"},{"categories":["分布式"],"content":"3 服务降级 前面讲了限流和熔断，相比来说，服务降级是站在系统全局的视角来考虑的。 在服务发生熔断后，一般会让请求走事先配置的处理方法，这个处理方法就是一个降级逻辑。 服务降级是对非核心、非关键的服务进行降级。 ","date":"2023-07-29","objectID":"/%E5%88%86%E5%B8%83%E5%BC%8F%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/:32:0","tags":["分布式"],"title":"分布式常见问题记录","uri":"/%E5%88%86%E5%B8%83%E5%BC%8F%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/"},{"categories":["分布式"],"content":"3.1 使用场景 服务处理异常，把异常信息直接反馈给客户端，不再走其他逻辑 服务处理异常，把请求缓存下来，给客户端返回一个中间态，事后再重试缓存的请求 监控系统检测到突增流量，为了避免非核心业务功能耗费系统资源，关闭这些非核心功能 数据库请求压力大，可以考虑返回缓存中的数据 对于耗时的写操作，可以改为异步写 暂时关闭跑批任务，以节省系统资源 ","date":"2023-07-29","objectID":"/%E5%88%86%E5%B8%83%E5%BC%8F%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/:33:0","tags":["分布式"],"title":"分布式常见问题记录","uri":"/%E5%88%86%E5%B8%83%E5%BC%8F%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/"},{"categories":["分布式"],"content":"3.2 使用hystrix降级 ","date":"2023-07-29","objectID":"/%E5%88%86%E5%B8%83%E5%BC%8F%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/:34:0","tags":["分布式"],"title":"分布式常见问题记录","uri":"/%E5%88%86%E5%B8%83%E5%BC%8F%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/"},{"categories":["分布式"],"content":"3.2.1 异常降级 hystrix降级时可以忽略某个异常，在方法上加上@HystrixCommand注解： 下面的代码定义降级方法是errMethod，对ParamErrorException和BusinessTypeException这两个异常不做降级处理。 @HystrixCommand( fallbackMethod = \"errMethod\", ignoreExceptions = {ParamErrorException.class, BusinessTypeException.class} ) ","date":"2023-07-29","objectID":"/%E5%88%86%E5%B8%83%E5%BC%8F%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/:35:0","tags":["分布式"],"title":"分布式常见问题记录","uri":"/%E5%88%86%E5%B8%83%E5%BC%8F%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/"},{"categories":["分布式"],"content":"3.2.2 调用超时降级 专门针对调用第三方接口超时降级。 下面的方法是调用第三方接口3秒未收到响应就降级到errMethod方法。 @HystrixCommand( commandProperties = { @HystrixProperty(name=\"execution.timeout.enabled\", value=\"true\"), @HystrixProperty(name=\"execution.isolation.thread.timeoutInMilliseconds\", value=\"3000\"), }, fallbackMethod = \"errMethod\" ) ","date":"2023-07-29","objectID":"/%E5%88%86%E5%B8%83%E5%BC%8F%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/:36:0","tags":["分布式"],"title":"分布式常见问题记录","uri":"/%E5%88%86%E5%B8%83%E5%BC%8F%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/"},{"categories":["分布式"],"content":"总结 限流、熔断和服务降级是系统容错的重要设计模式，从一定意义上讲限流和熔断也是一种服务降级的手段。 熔断和服务降级主要是针对非核心业务功能，而核心业务如果流程超过预估的峰值，就需要进行限流。 对于限流，选择合理的限流算法很重要，令牌桶算法优势很明显，也是使用最多的限流算法。 在系统设计的时候，这些模式需要配合业务量的预估、性能测试的数据进行相应阈值的配置，而这些阈值最好保存在配置中心，方便实时修改。 ","date":"2023-07-29","objectID":"/%E5%88%86%E5%B8%83%E5%BC%8F%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/:37:0","tags":["分布式"],"title":"分布式常见问题记录","uri":"/%E5%88%86%E5%B8%83%E5%BC%8F%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/"},{"categories":["领域驱动设计"],"content":"领域驱动开发说明","date":"2023-07-29","objectID":"/sinfcloud-%E9%A2%86%E5%9F%9F%E9%A9%B1%E5%8A%A8%E5%BC%80%E5%8F%91%E8%AF%B4%E6%98%8E/","tags":["领域驱动设计"],"title":"领域驱动开发说明","uri":"/sinfcloud-%E9%A2%86%E5%9F%9F%E9%A9%B1%E5%8A%A8%E5%BC%80%E5%8F%91%E8%AF%B4%E6%98%8E/"},{"categories":["领域驱动设计"],"content":"领域驱动开发说明 SinfCloud-领域驱动开发说明 CreateBy lln CreateTime 2023-06-26 UpdateTime 2023-07-03 文章内容说明： ​ 本文以不动产登记系统-档案管理子系统为例，分别进行与框架默认结构的对比和改造流程、单体微服务结构说明、服务间调用说明、代码包拆分说明、代码层级调用链说明，用于描述领域驱动在项目中落地的整体流程，以供设计人员、开发人员参考。 关键字：【领域驱动设计】【框架改造】【代码结构】 ","date":"2023-07-29","objectID":"/sinfcloud-%E9%A2%86%E5%9F%9F%E9%A9%B1%E5%8A%A8%E5%BC%80%E5%8F%91%E8%AF%B4%E6%98%8E/:0:0","tags":["领域驱动设计"],"title":"领域驱动开发说明","uri":"/sinfcloud-%E9%A2%86%E5%9F%9F%E9%A9%B1%E5%8A%A8%E5%BC%80%E5%8F%91%E8%AF%B4%E6%98%8E/"},{"categories":["领域驱动设计"],"content":"一、基于领域驱动的代码结构说明 ","date":"2023-07-29","objectID":"/sinfcloud-%E9%A2%86%E5%9F%9F%E9%A9%B1%E5%8A%A8%E5%BC%80%E5%8F%91%E8%AF%B4%E6%98%8E/:1:0","tags":["领域驱动设计"],"title":"领域驱动开发说明","uri":"/sinfcloud-%E9%A2%86%E5%9F%9F%E9%A9%B1%E5%8A%A8%E5%BC%80%E5%8F%91%E8%AF%B4%E6%98%8E/"},{"categories":["领域驱动设计"],"content":"1.1 单系统（微服务）结构说明 ​ 下图为单个微服务的整体结构，描述了消费者和提供者的整体关系、消费者、提供者内部结构、代码包结构的情况。详细说明如下。 ","date":"2023-07-29","objectID":"/sinfcloud-%E9%A2%86%E5%9F%9F%E9%A9%B1%E5%8A%A8%E5%BC%80%E5%8F%91%E8%AF%B4%E6%98%8E/:2:0","tags":["领域驱动设计"],"title":"领域驱动开发说明","uri":"/sinfcloud-%E9%A2%86%E5%9F%9F%E9%A9%B1%E5%8A%A8%E5%BC%80%E5%8F%91%E8%AF%B4%E6%98%8E/"},{"categories":["领域驱动设计"],"content":"1.1.1 消费者结构说明 ​ 【代码结构】消费者层，controller层负责当前微服务对外（指所有WEB端、移动端）提供接口，entitydto层负责处理外部接口调用后的数据转换和业务调用，拆解为多个不同的提供者实体（entitydo层），拆解后，调用不同的提供者服务（api层），向不同的提供者分发业务逻辑。 ","date":"2023-07-29","objectID":"/sinfcloud-%E9%A2%86%E5%9F%9F%E9%A9%B1%E5%8A%A8%E5%BC%80%E5%8F%91%E8%AF%B4%E6%98%8E/:2:1","tags":["领域驱动设计"],"title":"领域驱动开发说明","uri":"/sinfcloud-%E9%A2%86%E5%9F%9F%E9%A9%B1%E5%8A%A8%E5%BC%80%E5%8F%91%E8%AF%B4%E6%98%8E/"},{"categories":["领域驱动设计"],"content":"1.1.2 提供者结构说明 ​ 1、【整体架构-提供者版本控制】每个提供者内部通过划分版本包结构的方式，进行不同版本如V1_0、V2_0的划分。版本内部结构完全一致，如需更新应用版本时，将需要更新版本的相关代码进行拷贝复制至新版本包中，并更新接口层中的版本符号，完成后续应用接口开发和更新操作。 ​ 2、【代码结构-接口层】infrastructure层中，controller包提供接口信息，包含所有的当前REST接口信息，并调用应用服务层(service层)中的方法进行业务处理；api层记录调用的其他提供者的RPC信息； dto层存储对接其他提供者服务的数据模型；convertor层处理对接其他提供者服务时的数据映射和转换。 ​ 3、【代码结构-应用层】event层，负责触发和监听领域消息，根据实际业务场景，对不同聚合中的领域事件服务（Domain-service）进行业务层面的组装；组装业务后，由应用服务层（Application-service）进行统一调用，service层由接口层中的controller进行调用。service往往与controller提供的接口一一对应。 ​ 4、【代码结构-领域层】entitydo领域事件层，调用entitypo（持久化对象层）进行CRUD操作,获取结果处理所有当前领域相关的业务逻辑，；entitypo（持久化对象层）只用于接收参数，组装SQL查询并返回结果，不处理任何逻辑。model层（数据库实体映射）存放entity（实体映射层，贫血对象）作为数据数据库表的一对一映射，ex（实体扩展）只用于处理非库表结构的字段增加和补充，不做业务逻辑处理和数据校验。service（领域服务层）调用组装各个领域事件（entitydo），组装各个领域的业务逻辑，最终完成整个领域服务业务逻辑，供应用层（Application-event）进行组装调用。 ​ 5、【代码结构-基础层】infrastructure层严格意义上来说并不处于最下面一层。在上面三层中，所有的外部依赖（DB、缓存、中间件、服务调用）都使用接口的方式来避免和具体技术耦合。基础层提供了这些接口的具体实现，需要保障依赖关系不能倒置，即：除了基础层不能有对外部依赖的具体实现。 ","date":"2023-07-29","objectID":"/sinfcloud-%E9%A2%86%E5%9F%9F%E9%A9%B1%E5%8A%A8%E5%BC%80%E5%8F%91%E8%AF%B4%E6%98%8E/:2:2","tags":["领域驱动设计"],"title":"领域驱动开发说明","uri":"/sinfcloud-%E9%A2%86%E5%9F%9F%E9%A9%B1%E5%8A%A8%E5%BC%80%E5%8F%91%E8%AF%B4%E6%98%8E/"},{"categories":["领域驱动设计"],"content":"1.1.3 总调用链 ​ 下图为整体业务流程的调用链说明。 ","date":"2023-07-29","objectID":"/sinfcloud-%E9%A2%86%E5%9F%9F%E9%A9%B1%E5%8A%A8%E5%BC%80%E5%8F%91%E8%AF%B4%E6%98%8E/:2:3","tags":["领域驱动设计"],"title":"领域驱动开发说明","uri":"/sinfcloud-%E9%A2%86%E5%9F%9F%E9%A9%B1%E5%8A%A8%E5%BC%80%E5%8F%91%E8%AF%B4%E6%98%8E/"},{"categories":["领域驱动设计"],"content":"1.2 微服务间调用示意图 ​ 接口层（Interfaces）中的controller提供REST接口；api层进行RPC调用；需要适配的其他提供者实体模型，放入dto层存储，通过convertor层进行实体对象之间的转换。 ​ 应用服务（Application-service）之间的数据传递，通过基础层提供的中间件服务，如Redis、RabbtiMq等组件进行调用。 ​ 下图为微服务的间调用的关系图，描述了领域驱动架构中，微服务调用的关系。 ","date":"2023-07-29","objectID":"/sinfcloud-%E9%A2%86%E5%9F%9F%E9%A9%B1%E5%8A%A8%E5%BC%80%E5%8F%91%E8%AF%B4%E6%98%8E/:3:0","tags":["领域驱动设计"],"title":"领域驱动开发说明","uri":"/sinfcloud-%E9%A2%86%E5%9F%9F%E9%A9%B1%E5%8A%A8%E5%BC%80%E5%8F%91%E8%AF%B4%E6%98%8E/"},{"categories":["领域驱动设计"],"content":"1.3 包结构说明 ​ 下面基于不动产登记系统-档案管理子系统的领域设计，生成的基于领域驱动的代码结构，具体如下图。 ","date":"2023-07-29","objectID":"/sinfcloud-%E9%A2%86%E5%9F%9F%E9%A9%B1%E5%8A%A8%E5%BC%80%E5%8F%91%E8%AF%B4%E6%98%8E/:4:0","tags":["领域驱动设计"],"title":"领域驱动开发说明","uri":"/sinfcloud-%E9%A2%86%E5%9F%9F%E9%A9%B1%E5%8A%A8%E5%BC%80%E5%8F%91%E8%AF%B4%E6%98%8E/"},{"categories":["领域驱动设计"],"content":"1.3.1 消费者结构 ​ 下图为档案系统的消费者结构说明和代码层级图 |-- ./v1_0 |-- ./api 接口防腐层，定义了provider(生产者)的PRC调用信息 |-- ./controller web对外接口控制层 |-- ./entitydo 领域对象，可以拆分为多个po（实体）对象 |-- ./entitydto 数据传输对象，可以拆分为多个do（领域对象） ","date":"2023-07-29","objectID":"/sinfcloud-%E9%A2%86%E5%9F%9F%E9%A9%B1%E5%8A%A8%E5%BC%80%E5%8F%91%E8%AF%B4%E6%98%8E/:4:1","tags":["领域驱动设计"],"title":"领域驱动开发说明","uri":"/sinfcloud-%E9%A2%86%E5%9F%9F%E9%A9%B1%E5%8A%A8%E5%BC%80%E5%8F%91%E8%AF%B4%E6%98%8E/"},{"categories":["领域驱动设计"],"content":"1.3.2 提供者结构 ​ 下图为档案系统的提供者结构说明和代码层级图，与1.1 单系统（微服务）结构说明中的示意图对应。 |-- ./v1_0 版本v1_0 | |-- ./v1_0/app 应用层 | | |-- ./v1_0/app/event 组装领域事件 | | `-- ./v1_0/app/service 应用服务 | |-- ./v1_0/domain 领域对象层，包含多个业务聚合 | | |-- ./v1_0/domain/dabhgz 聚合：档案编号规则 | | |-- ./v1_0/domain/darq 聚合：档案容器 | | |-- ./v1_0/domain/dayjjl 聚合：档案移交记录 | | |-- ./v1_0/domain/dzjbxx 聚合：档案基本信息 | |-- ./v1_0/infrastructure 基础支持层 | | `-- ./v1_0/infrastructure/util 公共工具层 | `-- ./v1_0/interfaces 接口层 | |-- ./v1_0/interfaces/api 接口防腐层(内部) | |-- ./v1_0/interfaces/controller 出入参转换器 | |-- ./v1_0/interfaces/convertor 提供者对外接口层 | |-- ./v1_0/interfaces/dto 数据传输模型 `-- ./v2_0 版本v2_0 ... `-- ./v3_0 版本v3_0 ... ​ 整体包结构图 ​ 包结构展开说明图 ​ 领域层包对象拆分逻辑，在目录2.2.2提供者改造方案中有详细描述。 ","date":"2023-07-29","objectID":"/sinfcloud-%E9%A2%86%E5%9F%9F%E9%A9%B1%E5%8A%A8%E5%BC%80%E5%8F%91%E8%AF%B4%E6%98%8E/:4:2","tags":["领域驱动设计"],"title":"领域驱动开发说明","uri":"/sinfcloud-%E9%A2%86%E5%9F%9F%E9%A9%B1%E5%8A%A8%E5%BC%80%E5%8F%91%E8%AF%B4%E6%98%8E/"},{"categories":["领域驱动设计"],"content":"1.3.3 代码版本控制说明 ​ 在系统开发中，往往会随着业务需求的变化，对已有代码进行升级和迭代，形成两个类型的代码版本。 ​ API版本说明： ​ 将不同时期变化的代码，称之为“API版本”。API版本通过在消费者、提供者跟目录下，拆分新的代码包，如V1_0,V2_0等等进行管理,同时将相关的API的URL地址进行修改，从V1_0修改为V2_0。 ​ 区域版本说明： ​ 如有某个地市级系统的业务，有区别于省级系统的定制化的专属需求，将不同地域的定制化版本，称之为“区域版本”。区域版本的控制，通过抽取公共开放代码，迁移至扩展开放版本中，将开放版本通过依赖引入至具体的某个区域定制版本中作为基础模块使用。具体设计内容参考《不动产登记云平台版本化管理及开发规范v1.0》的说明。（https://docs.qq.com/doc/DRFlqWEdqdnNRclpE）。 ​ 为了更好的维护不同时期的代码版本、不同地域的代码版本，在代码架构中，使用如下图所示的方案，进行代码版本划分。 ​ ","date":"2023-07-29","objectID":"/sinfcloud-%E9%A2%86%E5%9F%9F%E9%A9%B1%E5%8A%A8%E5%BC%80%E5%8F%91%E8%AF%B4%E6%98%8E/:4:3","tags":["领域驱动设计"],"title":"领域驱动开发说明","uri":"/sinfcloud-%E9%A2%86%E5%9F%9F%E9%A9%B1%E5%8A%A8%E5%BC%80%E5%8F%91%E8%AF%B4%E6%98%8E/"},{"categories":["领域驱动设计"],"content":"二、与框架默认结构的对比和改造方案 ​ 与SinfCloud框架的默认生成结构相比，需要进行一些改变和重构，在不改变SinfCloud的原有框架设计的情况下，则需要对原有代码结构更进一步的进行软件包的拆分，才能够体现在领域驱动设计中的四层模型概念，也能与每个系统的领域驱动设计文档有所关联和映射。下面对提供者和消费者分别进行说明。 ","date":"2023-07-29","objectID":"/sinfcloud-%E9%A2%86%E5%9F%9F%E9%A9%B1%E5%8A%A8%E5%BC%80%E5%8F%91%E8%AF%B4%E6%98%8E/:5:0","tags":["领域驱动设计"],"title":"领域驱动开发说明","uri":"/sinfcloud-%E9%A2%86%E5%9F%9F%E9%A9%B1%E5%8A%A8%E5%BC%80%E5%8F%91%E8%AF%B4%E6%98%8E/"},{"categories":["领域驱动设计"],"content":"2.1 消费者 2.1.1 消费者改造 ​ 与原结构相比，修改后的结构，去除了generate的包分类。按照领域驱动中，接口层的拆分规范进行包结构定义。 2.1.2 消费者总体结构对比 ","date":"2023-07-29","objectID":"/sinfcloud-%E9%A2%86%E5%9F%9F%E9%A9%B1%E5%8A%A8%E5%BC%80%E5%8F%91%E8%AF%B4%E6%98%8E/:5:1","tags":["领域驱动设计"],"title":"领域驱动开发说明","uri":"/sinfcloud-%E9%A2%86%E5%9F%9F%E9%A9%B1%E5%8A%A8%E5%BC%80%E5%8F%91%E8%AF%B4%E6%98%8E/"},{"categories":["领域驱动设计"],"content":"2.2 提供者 2.2.1 提供者改造 ​ 提供者的改造基于领域驱动中的四层模型进行包结构的拆分。如图所示： ​ 提供者中Domain层的聚合，基于领域设计中的聚合分析进行包结构的拆分，如图所示： ​ 修改内容为： ​ 1、基于领域四层模型创建代码包。 ​ 2、基于领域设计中的聚合分析，对框架默认包进行移动和重构。内容如下： ​ 2.1、将默认结构中，【entity】中的所有Ex类，移动至【domain】-【业务聚合包】-【po】-【ex】包中。需要基于设计来定义Ex所对应的聚合。 ​ 2.2、将默认结构中，【entitydo】中的所有Do类，移动至【domain】-【业务聚合包】-【entitydo】包中。需要基于设计来定义Do类所对应的聚合。 ​ 2.3、将默认结构中，【generate】-【controller】包中所有的Controller类，移动至【interfaces】-【controller】包中。 ​ 2.4、将默认结构中，【generate】-【entity】包中所有的Po类，移动至【domain】-【业务聚合包】-【po】包中。需要基于设计来定义Po类所对应的聚合。 ​ 2.5、将默认结构中，【generate】-【entity】包中所有的entity实体类，移动至【domain】-【业务聚合包】-【model】包中。需要基于设计来定义entity实体类所对应的聚合。 如2.2.2 中结构对比图所示。 2.2.2 提供者总体结构对比 ​ 原有代码结构如图所示 ","date":"2023-07-29","objectID":"/sinfcloud-%E9%A2%86%E5%9F%9F%E9%A9%B1%E5%8A%A8%E5%BC%80%E5%8F%91%E8%AF%B4%E6%98%8E/:5:2","tags":["领域驱动设计"],"title":"领域驱动开发说明","uri":"/sinfcloud-%E9%A2%86%E5%9F%9F%E9%A9%B1%E5%8A%A8%E5%BC%80%E5%8F%91%E8%AF%B4%E6%98%8E/"},{"categories":["领域驱动设计"],"content":"2.3 改造遇到的问题 ​ 1、需要移动和重构的代码比较多，手动重构的话很容器有遗漏，或没有按照领域驱动设计图的聚合进行移动。但是代码生成器也无法按照领域设计进行代码生成。这块需要思考如何减少工作量。 ​ 2、改造后的结构去除了默认生成的generate包结构，将其中的代码进行了拆分，是否需要保留generate这部分的设计，需要思考。 ​ 3、领域驱动下的业务调用链比较长，如何在开发中进行规范话的管控，避免开发人员将所有逻辑堆砌到上层，将结果进行数据透传的为了DDD而DDD的错误操作，需要思考。 ","date":"2023-07-29","objectID":"/sinfcloud-%E9%A2%86%E5%9F%9F%E9%A9%B1%E5%8A%A8%E5%BC%80%E5%8F%91%E8%AF%B4%E6%98%8E/:5:3","tags":["领域驱动设计"],"title":"领域驱动开发说明","uri":"/sinfcloud-%E9%A2%86%E5%9F%9F%E9%A9%B1%E5%8A%A8%E5%BC%80%E5%8F%91%E8%AF%B4%E6%98%8E/"},{"categories":["领域驱动设计"],"content":"三、开发注意事项 ​ 1、使用IDEA进行开发时，需统一安装 Alibaba 代码质量检测插件 【Alibaba Java Coding Guidelines】 ​ 2、尽量避免和处理编译器层面的Warnning警告提示 ​ 3、尽量不要使用JsonObject或者Map进行数据透传 ​ 4、在Ex层不要处理业务逻辑和SQL ​ 5、具体编码细节参考OA文档中的开发规范 ","date":"2023-07-29","objectID":"/sinfcloud-%E9%A2%86%E5%9F%9F%E9%A9%B1%E5%8A%A8%E5%BC%80%E5%8F%91%E8%AF%B4%E6%98%8E/:6:0","tags":["领域驱动设计"],"title":"领域驱动开发说明","uri":"/sinfcloud-%E9%A2%86%E5%9F%9F%E9%A9%B1%E5%8A%A8%E5%BC%80%E5%8F%91%E8%AF%B4%E6%98%8E/"},{"categories":["领域驱动设计"],"content":"参考内容 关于DDD的认知 https://www.bilibili.com/video/BV1Ns4y197WD/?spm_id_from=333.337.search-card.all.click\u0026vd_source=93189541b207f6eb4c8a443ffe4140e7 https://mp.weixin.qq.com/s/g2k9LhmNwuBJ9h00fxul1w 阿里COLA框架地址 https://github.com/alibaba/COLA COLA架构的结构分析 https://blog.csdn.net/significantfrank/article/details/110934799 COLA项目实践 https://baijiahao.baidu.com/s?id=1717604031061047078\u0026wfr=spider\u0026for=pc SinfCloud的设计概念 https://note.youdao.com/s/XdBavsxl 关于贫血模型和充血模型 https://blog.csdn.net/m0_51358164/article/details/125744851 ","date":"2023-07-29","objectID":"/sinfcloud-%E9%A2%86%E5%9F%9F%E9%A9%B1%E5%8A%A8%E5%BC%80%E5%8F%91%E8%AF%B4%E6%98%8E/:7:0","tags":["领域驱动设计"],"title":"领域驱动开发说明","uri":"/sinfcloud-%E9%A2%86%E5%9F%9F%E9%A9%B1%E5%8A%A8%E5%BC%80%E5%8F%91%E8%AF%B4%E6%98%8E/"},{"categories":["其他"],"content":"信创适配流程图","date":"2023-07-15","objectID":"/%E4%BF%A1%E5%88%9B/","tags":["其他"],"title":"信创适配流程图","uri":"/%E4%BF%A1%E5%88%9B/"},{"categories":["其他"],"content":"总体适配流程 ","date":"2023-07-15","objectID":"/%E4%BF%A1%E5%88%9B/:1:0","tags":["其他"],"title":"信创适配流程图","uri":"/%E4%BF%A1%E5%88%9B/"},{"categories":["其他"],"content":"数据库适配迁移流程 ","date":"2023-07-15","objectID":"/%E4%BF%A1%E5%88%9B/:2:0","tags":["其他"],"title":"信创适配流程图","uri":"/%E4%BF%A1%E5%88%9B/"},{"categories":null,"content":" 总体流程学习和记录 1、K8s学习，研发环境搭建 2、评估和规划迁移资源的范围 3、整理当前集群所使用的配置信息和依赖卷信息以及在k8s中如何配置 4、使用Kompose工具Docker Compose文件转换为K8s配置文件（如Deployment、Service、ConfigMap、Secret、Pod、Volume等） 5、研发环境打包脚本，流水线自动化到k8s 6、腾讯云TKE、TSF组件学习 7、云服务资源申请，网络申请，迁移云服务后的测试、性能监控与调试 ","date":"2023-04-16","objectID":"/docker%E9%9B%86%E7%BE%A4%E8%BF%81%E7%A7%BBk8s%E8%AE%B0%E5%BD%95/:0:0","tags":null,"title":"Docker集群迁移K8s记录","uri":"/docker%E9%9B%86%E7%BE%A4%E8%BF%81%E7%A7%BBk8s%E8%AE%B0%E5%BD%95/"},{"categories":null,"content":"一、K8s学习 ","date":"2023-04-16","objectID":"/docker%E9%9B%86%E7%BE%A4%E8%BF%81%E7%A7%BBk8s%E8%AE%B0%E5%BD%95/:1:0","tags":null,"title":"Docker集群迁移K8s记录","uri":"/docker%E9%9B%86%E7%BE%A4%E8%BF%81%E7%A7%BBk8s%E8%AE%B0%E5%BD%95/"},{"categories":null,"content":"官网文档 https://kubernetes.io/zh-cn/docs/concepts/security/secrets-good-practices/ 博客 https://jimmysong.io/ ","date":"2023-04-16","objectID":"/docker%E9%9B%86%E7%BE%A4%E8%BF%81%E7%A7%BBk8s%E8%AE%B0%E5%BD%95/:1:1","tags":null,"title":"Docker集群迁移K8s记录","uri":"/docker%E9%9B%86%E7%BE%A4%E8%BF%81%E7%A7%BBk8s%E8%AE%B0%E5%BD%95/"},{"categories":null,"content":"目标 安装 kubernetes 集群。包括 minikube，云平台搭建，裸机搭建 部署项目到集群中，对外暴露服务端口 部署数据库这种有状态的应用，数据持久化 集群中配置文件和密码文件 使用 Helm 应用商店快速安装第三方应用 Ingress 对外提供服务 ","date":"2023-04-16","objectID":"/docker%E9%9B%86%E7%BE%A4%E8%BF%81%E7%A7%BBk8s%E8%AE%B0%E5%BD%95/:1:2","tags":null,"title":"Docker集群迁移K8s记录","uri":"/docker%E9%9B%86%E7%BE%A4%E8%BF%81%E7%A7%BBk8s%E8%AE%B0%E5%BD%95/"},{"categories":null,"content":"差异对比 传统部署方式： 应用直接在物理机上部署，机器资源分配不好控制，出现Bug时，可能机器的大部分资源被某个应用占用，导致其他应用无法正常运行，无法做到应用隔离。 虚拟机部署 在单个物理机上运行多个虚拟机，每个虚拟机都是完整独立的系统，性能损耗大。 容器部署 所有容器共享主机的系统，轻量级的虚拟机，性能损耗小，资源隔离，CPU和内存可按需分配 ","date":"2023-04-16","objectID":"/docker%E9%9B%86%E7%BE%A4%E8%BF%81%E7%A7%BBk8s%E8%AE%B0%E5%BD%95/:1:3","tags":null,"title":"Docker集群迁移K8s记录","uri":"/docker%E9%9B%86%E7%BE%A4%E8%BF%81%E7%A7%BBk8s%E8%AE%B0%E5%BD%95/"},{"categories":null,"content":"关键概念 master 主节点，控制平台，不需要很高性能，不跑任务，通常一个就行了，也可以开多个主节点来提高集群可用度。 worker 工作节点，可以是虚拟机或物理计算机，任务都在这里跑，机器性能需要好点；通常都有很多个，可以不断加机器扩大集群；每个工作节点由主节点管理 Pod K8S 调度、管理的最小单位，一个 Pod 可以包含一个或多个容器，每个 Pod 有自己的虚拟IP。一个工作节点可以有多个 pod，主节点会考量负载自动调度 pod 到哪个节点运行。 ### Kubernetes 组件 kube-apiserver API 服务器，公开了 Kubernetes API etcd 键值数据库，可以作为保存 Kubernetes 所有集群数据的后台数据库 kube-scheduler 调度 Pod 到哪个节点运行 kube-controller 集群控制器 cloud-controller 与云服务商交互 namespace pvc service pod StatefulSet 持久化配置 Deployment configmap ","date":"2023-04-16","objectID":"/docker%E9%9B%86%E7%BE%A4%E8%BF%81%E7%A7%BBk8s%E8%AE%B0%E5%BD%95/:1:4","tags":null,"title":"Docker集群迁移K8s记录","uri":"/docker%E9%9B%86%E7%BE%A4%E8%BF%81%E7%A7%BBk8s%E8%AE%B0%E5%BD%95/"},{"categories":null,"content":"Docker镜像管理 docker Registry Harbor harbor离线搭建，本地登录 离线安装 使用官方离线包，解压后一键进行安装 离线镜像导入和同步 单个镜像导入 离线框架多镜像批量导入 获取当前容器中所有离线sinfcloud镜像 dk images | grep sinfcloud | awk '{print $1}' 脚本批量循环导入 在线安装 在线镜像同步，远程库-本地库 配置远程仓库的同步复制，指定标签、版本等信息 ","date":"2023-04-16","objectID":"/docker%E9%9B%86%E7%BE%A4%E8%BF%81%E7%A7%BBk8s%E8%AE%B0%E5%BD%95/:1:5","tags":null,"title":"Docker集群迁移K8s记录","uri":"/docker%E9%9B%86%E7%BE%A4%E8%BF%81%E7%A7%BBk8s%E8%AE%B0%E5%BD%95/"},{"categories":null,"content":"文件系统 NFS系统 主节点搭建NFS，存储共享文件，安装包及配置文件，子节点挂载目录 ","date":"2023-04-16","objectID":"/docker%E9%9B%86%E7%BE%A4%E8%BF%81%E7%A7%BBk8s%E8%AE%B0%E5%BD%95/:1:6","tags":null,"title":"Docker集群迁移K8s记录","uri":"/docker%E9%9B%86%E7%BE%A4%E8%BF%81%E7%A7%BBk8s%E8%AE%B0%E5%BD%95/"},{"categories":null,"content":"异常处理 yaml文件写错 kube-linter这个工具来检查yaml语法是否有误 系统版本与脚本不匹配 节点ip变化 主节点 node 如何保障ip变化不影响集群运行 ndf客户端挂载报错 mount: 文件系统类型错误、选项错误 上有坏超级块...... 将节点机器安装nfs客户端依赖，再进行连接测试 写错挂载地址，且未使用软连接，导致挂载目录无法df -h 、ll 等命令进行查看 强行取消挂载点 umount -fl /opt/nfs_data nfs实现共享目录对于集群高可用风险，nfs客户端容易卡死 客户端nfs中有一个内核级别的线程，nfsv4.1-svc，该线程会一直和nfs服务端进行通信，且无法被kill掉。（停止客户端Nfs服务，设置开机不自启动，并卸载nfs，重启主机才能让该线程停掉）。 mount -t nfs -o rw,intr,soft,timeo=30,retry=3 nfs-server://share-path local-path 主节点ip变化 固定虚拟机ip，进行端口转发配置 harbor 离线导入失败 镜像命名需要与harbor的规则一致 导入镜像时区不正确 ","date":"2023-04-16","objectID":"/docker%E9%9B%86%E7%BE%A4%E8%BF%81%E7%A7%BBk8s%E8%AE%B0%E5%BD%95/:1:7","tags":null,"title":"Docker集群迁移K8s记录","uri":"/docker%E9%9B%86%E7%BE%A4%E8%BF%81%E7%A7%BBk8s%E8%AE%B0%E5%BD%95/"},{"categories":null,"content":"语句 k8s 删除指定名称的子节点 kubectl delete node \u003cnodeName\u003e 配置主机hostname hostnamectl set-hostname kubernetes调度pod运行于master节点上 让 master节点恢复不参与POD负载的命令为 kubectl taint nodes \u003cnode-name\u003e node-role.kubernetes.io/master=:NoSchedule 让 master节点恢复不参与POD负载，并将Node上已经存在的Pod驱逐出去的命令 kubectl taint nodes \u003cnode-name\u003e node-role.kubernetes.io/master=:NoExecute 子节点加入主节点 kubeadm join \u003cmaster‐ip\u003e:6443 ‐‐token \u003ckubernetes‐token\u003e --discovery-tokenunsafe-skip-ca-verification 脚本执行 子节点安装并加入主节点 chmod +x install.sh \u0026\u0026 ./install.sh join \u003cmaster‐ip\u003e:6443 ‐‐token \u003ckubernetes‐token\u003e 安装主节点 chmod +x install.sh \u0026\u0026 ./install.sh master docker 离线安装compose 复制离线文件、授权 sudo chmod +x /usr/local/bin/docker-compose 常用命令 重新加载配置文件并重启 systemctl daemon-reload \u0026\u0026 systemctl restart docker 查看包含某个名字的镜像信息，查看列 dk images | grep sinfcloud | awk '{print $1}' ","date":"2023-04-16","objectID":"/docker%E9%9B%86%E7%BE%A4%E8%BF%81%E7%A7%BBk8s%E8%AE%B0%E5%BD%95/:1:8","tags":null,"title":"Docker集群迁移K8s记录","uri":"/docker%E9%9B%86%E7%BE%A4%E8%BF%81%E7%A7%BBk8s%E8%AE%B0%E5%BD%95/"},{"categories":null,"content":"二、迁移准备和环境布置 因为所有服务已经容器化，基本上无需特殊处理，修改部署脚本后进行上传测试即可 以下流程整理自各种博客和chatgpt的提示，基本上迁移的步骤也是按照这个来的 ","date":"2023-04-16","objectID":"/docker%E9%9B%86%E7%BE%A4%E8%BF%81%E7%A7%BBk8s%E8%AE%B0%E5%BD%95/:2:0","tags":null,"title":"Docker集群迁移K8s记录","uri":"/docker%E9%9B%86%E7%BE%A4%E8%BF%81%E7%A7%BBk8s%E8%AE%B0%E5%BD%95/"},{"categories":null,"content":"清理Docker镜像 审查并清理Docker镜像，删除不必要的组件和文件，确保镜像精简且包含应用程序的所有必要部分。 ","date":"2023-04-16","objectID":"/docker%E9%9B%86%E7%BE%A4%E8%BF%81%E7%A7%BBk8s%E8%AE%B0%E5%BD%95/:2:1","tags":null,"title":"Docker集群迁移K8s记录","uri":"/docker%E9%9B%86%E7%BE%A4%E8%BF%81%E7%A7%BBk8s%E8%AE%B0%E5%BD%95/"},{"categories":null,"content":"配置环境变量 将Docker容器中使用的环境变量和配置文件迁移到Kubernetes中的ConfigMaps和Secrets中，以确保在Kubernetes中正确设置运行时变量。 ","date":"2023-04-16","objectID":"/docker%E9%9B%86%E7%BE%A4%E8%BF%81%E7%A7%BBk8s%E8%AE%B0%E5%BD%95/:2:2","tags":null,"title":"Docker集群迁移K8s记录","uri":"/docker%E9%9B%86%E7%BE%A4%E8%BF%81%E7%A7%BBk8s%E8%AE%B0%E5%BD%95/"},{"categories":null,"content":"创建Deployment 使用Kubernetes的Deployment资源来定义应用程序的期望状态和副本数量。Deployment负责在集群中创建Pod，并确保它们按照定义的规则进行运行。 ","date":"2023-04-16","objectID":"/docker%E9%9B%86%E7%BE%A4%E8%BF%81%E7%A7%BBk8s%E8%AE%B0%E5%BD%95/:2:3","tags":null,"title":"Docker集群迁移K8s记录","uri":"/docker%E9%9B%86%E7%BE%A4%E8%BF%81%E7%A7%BBk8s%E8%AE%B0%E5%BD%95/"},{"categories":null,"content":"创建Service 使用Service资源定义将外部流量引导到应用程序的方式。Service提供了一个稳定的网络端点，使得应用程序可以被集群内和集群外的其他组件访问。 ","date":"2023-04-16","objectID":"/docker%E9%9B%86%E7%BE%A4%E8%BF%81%E7%A7%BBk8s%E8%AE%B0%E5%BD%95/:2:4","tags":null,"title":"Docker集群迁移K8s记录","uri":"/docker%E9%9B%86%E7%BE%A4%E8%BF%81%E7%A7%BBk8s%E8%AE%B0%E5%BD%95/"},{"categories":null,"content":"添加健康检查 Kubernetes通过健康检查确定Pod的运行状况。确保在Docker容器中添加适当的健康检查，以便Kubernetes可以正确监控和管理Pod的状态。 ","date":"2023-04-16","objectID":"/docker%E9%9B%86%E7%BE%A4%E8%BF%81%E7%A7%BBk8s%E8%AE%B0%E5%BD%95/:2:5","tags":null,"title":"Docker集群迁移K8s记录","uri":"/docker%E9%9B%86%E7%BE%A4%E8%BF%81%E7%A7%BBk8s%E8%AE%B0%E5%BD%95/"},{"categories":null,"content":"采用Kubernetes标准 遵循Kubernetes的最佳实践，例如使用标签（Labels）和注释（Annotations）来描述和组织应用程序。 ","date":"2023-04-16","objectID":"/docker%E9%9B%86%E7%BE%A4%E8%BF%81%E7%A7%BBk8s%E8%AE%B0%E5%BD%95/:2:6","tags":null,"title":"Docker集群迁移K8s记录","uri":"/docker%E9%9B%86%E7%BE%A4%E8%BF%81%E7%A7%BBk8s%E8%AE%B0%E5%BD%95/"},{"categories":null,"content":"使用PV/PVC管理持久化数据 容器中的存储都是临时的，因此Pod重启的时候，内部的数据会发生丢失。实际应用中，我们有些应用是无状态，有些应用则需要保持状态数据，确保Pod重启之后能够读取到之前的状态数据，有些应用则作为集群提供服务。这三种服务归纳为无状态服务、有状态服务以及有状态的集群服务，其中后面两个存在数据保存与共享的需求，因此就要采用容器外的存储方案。 ","date":"2023-04-16","objectID":"/docker%E9%9B%86%E7%BE%A4%E8%BF%81%E7%A7%BBk8s%E8%AE%B0%E5%BD%95/:2:7","tags":null,"title":"Docker集群迁移K8s记录","uri":"/docker%E9%9B%86%E7%BE%A4%E8%BF%81%E7%A7%BBk8s%E8%AE%B0%E5%BD%95/"},{"categories":null,"content":"使用ConfigMap管理应用配置文件 在DevOps的部署流水线中，我们强调代码和配置的分离，这样更容易实现流水线的编排。在Kubernetes中提供了ConfigMap资源对象，其实ConfigMap和Secret都是一种卷类型，可以从文件、文件夹等途径创建ConfigMap。然后再Pod中挂载使用。 ","date":"2023-04-16","objectID":"/docker%E9%9B%86%E7%BE%A4%E8%BF%81%E7%A7%BBk8s%E8%AE%B0%E5%BD%95/:2:8","tags":null,"title":"Docker集群迁移K8s记录","uri":"/docker%E9%9B%86%E7%BE%A4%E8%BF%81%E7%A7%BBk8s%E8%AE%B0%E5%BD%95/"},{"categories":null,"content":"实施滚动更新和回滚策略 滚动更新 使用Deployment的滚动更新功能，逐步将新版本的Pod引入集群，确保应用程序在升级过程中保持稳定。 回滚策略 如果升级后发现问题，可以使用Deployment的回滚策略，将应用程序回滚到之前的稳定版本。 ","date":"2023-04-16","objectID":"/docker%E9%9B%86%E7%BE%A4%E8%BF%81%E7%A7%BBk8s%E8%AE%B0%E5%BD%95/:2:9","tags":null,"title":"Docker集群迁移K8s记录","uri":"/docker%E9%9B%86%E7%BE%A4%E8%BF%81%E7%A7%BBk8s%E8%AE%B0%E5%BD%95/"},{"categories":null,"content":"资源定义 Kubernetes使用资源定义（Resource Requests）和资源限制（Resource Limits）来控制Pod对集群资源的使用。Requests定义了Pod所需资源的最小量，而Limits定义了Pod在超出此限制时可能被终止的资源量。 ","date":"2023-04-16","objectID":"/docker%E9%9B%86%E7%BE%A4%E8%BF%81%E7%A7%BBk8s%E8%AE%B0%E5%BD%95/:2:10","tags":null,"title":"Docker集群迁移K8s记录","uri":"/docker%E9%9B%86%E7%BE%A4%E8%BF%81%E7%A7%BBk8s%E8%AE%B0%E5%BD%95/"},{"categories":null,"content":"节点选择和亲和性 通过Node选择器和亲和性规则，可以将Pod调度到特定的节点上，以满足应用程序对硬件特性或数据存储的需求，从而实现更灵活的资源管理。 ","date":"2023-04-16","objectID":"/docker%E9%9B%86%E7%BE%A4%E8%BF%81%E7%A7%BBk8s%E8%AE%B0%E5%BD%95/:2:11","tags":null,"title":"Docker集群迁移K8s记录","uri":"/docker%E9%9B%86%E7%BE%A4%E8%BF%81%E7%A7%BBk8s%E8%AE%B0%E5%BD%95/"},{"categories":null,"content":"横向Pod自动伸缩 使用Horizontal Pod Autoscaler（HPA）自动根据CPU或内存的使用情况调整Pod的副本数量。HPA可确保在高负载时增加实例，在低负载时减少实例，以有效利用集群资源。 ","date":"2023-04-16","objectID":"/docker%E9%9B%86%E7%BE%A4%E8%BF%81%E7%A7%BBk8s%E8%AE%B0%E5%BD%95/:2:12","tags":null,"title":"Docker集群迁移K8s记录","uri":"/docker%E9%9B%86%E7%BE%A4%E8%BF%81%E7%A7%BBk8s%E8%AE%B0%E5%BD%95/"},{"categories":null,"content":"Pod的水平扩展 Kubernetes允许手动调整Deployment的副本数量，实现Pod的水平扩展。通过以下命令可以增加或减少Pod的实例数量。 ","date":"2023-04-16","objectID":"/docker%E9%9B%86%E7%BE%A4%E8%BF%81%E7%A7%BBk8s%E8%AE%B0%E5%BD%95/:2:13","tags":null,"title":"Docker集群迁移K8s记录","uri":"/docker%E9%9B%86%E7%BE%A4%E8%BF%81%E7%A7%BBk8s%E8%AE%B0%E5%BD%95/"},{"categories":null,"content":"自动缩放 利用Kubernetes的自动缩放机制，集群可以根据负载的变化自动增加或减少节点的数量。这样可以确保在高负载时有足够的资源，并在低负载时减少资源浪费。 ","date":"2023-04-16","objectID":"/docker%E9%9B%86%E7%BE%A4%E8%BF%81%E7%A7%BBk8s%E8%AE%B0%E5%BD%95/:2:14","tags":null,"title":"Docker集群迁移K8s记录","uri":"/docker%E9%9B%86%E7%BE%A4%E8%BF%81%E7%A7%BBk8s%E8%AE%B0%E5%BD%95/"},{"categories":null,"content":"网络通信 在Kubernetes环境中，确保容器之间的安全网络通信至关重要。本节将介绍如何实现容器间的网络隔离以及使用Kubernetes Network Policies加强安全性。 ","date":"2023-04-16","objectID":"/docker%E9%9B%86%E7%BE%A4%E8%BF%81%E7%A7%BBk8s%E8%AE%B0%E5%BD%95/:2:15","tags":null,"title":"Docker集群迁移K8s记录","uri":"/docker%E9%9B%86%E7%BE%A4%E8%BF%81%E7%A7%BBk8s%E8%AE%B0%E5%BD%95/"},{"categories":null,"content":"容器间的网络隔离 Kubernetes使用命名空间（Namespace）来提供虚拟的集群，可以将不同的资源隔离开。容器在同一命名空间中共享网络命名空间，但可以通过使用不同的命名空间来实现网络隔离。 ","date":"2023-04-16","objectID":"/docker%E9%9B%86%E7%BE%A4%E8%BF%81%E7%A7%BBk8s%E8%AE%B0%E5%BD%95/:2:16","tags":null,"title":"Docker集群迁移K8s记录","uri":"/docker%E9%9B%86%E7%BE%A4%E8%BF%81%E7%A7%BBk8s%E8%AE%B0%E5%BD%95/"},{"categories":null,"content":"Pod之间的通信 通过Service资源，Kubernetes提供了一种逻辑上的抽象，将一组Pod封装在一个虚拟的服务IP地址下。这种方式实现了容器间的通信，同时隐藏了底层Pod的IP地址变化。 ","date":"2023-04-16","objectID":"/docker%E9%9B%86%E7%BE%A4%E8%BF%81%E7%A7%BBk8s%E8%AE%B0%E5%BD%95/:2:17","tags":null,"title":"Docker集群迁移K8s记录","uri":"/docker%E9%9B%86%E7%BE%A4%E8%BF%81%E7%A7%BBk8s%E8%AE%B0%E5%BD%95/"},{"categories":null,"content":"监控和管理 使用开源监控工具（如Prometheus、Grafana）或云服务提供商的监控服务，设置应用程序的监控系统。监控关键指标，如CPU使用率、内存消耗、请求响应时间等。 ","date":"2023-04-16","objectID":"/docker%E9%9B%86%E7%BE%A4%E8%BF%81%E7%A7%BBk8s%E8%AE%B0%E5%BD%95/:2:18","tags":null,"title":"Docker集群迁移K8s记录","uri":"/docker%E9%9B%86%E7%BE%A4%E8%BF%81%E7%A7%BBk8s%E8%AE%B0%E5%BD%95/"},{"categories":null,"content":"日志收集 使用日志收集工具（如ELK Stack、Fluentd）或云服务提供商的日志服务，集中管理应用程序生成的日志。通过搜索和分析日志，可以更容易地诊断问题并进行性能优化。 ","date":"2023-04-16","objectID":"/docker%E9%9B%86%E7%BE%A4%E8%BF%81%E7%A7%BBk8s%E8%AE%B0%E5%BD%95/:2:19","tags":null,"title":"Docker集群迁移K8s记录","uri":"/docker%E9%9B%86%E7%BE%A4%E8%BF%81%E7%A7%BBk8s%E8%AE%B0%E5%BD%95/"},{"categories":null,"content":"配置CI/CD流水线 选择适用于Kubernetes的CI/CD工具（如Jenkins、GitLab CI、CircleCI），配置流水线以自动构建Docker镜像、运行测试，并将应用程序部署到Kubernetes集群。 ","date":"2023-04-16","objectID":"/docker%E9%9B%86%E7%BE%A4%E8%BF%81%E7%A7%BBk8s%E8%AE%B0%E5%BD%95/:2:20","tags":null,"title":"Docker集群迁移K8s记录","uri":"/docker%E9%9B%86%E7%BE%A4%E8%BF%81%E7%A7%BBk8s%E8%AE%B0%E5%BD%95/"},{"categories":null,"content":"其他： ","date":"2023-04-16","objectID":"/docker%E9%9B%86%E7%BE%A4%E8%BF%81%E7%A7%BBk8s%E8%AE%B0%E5%BD%95/:2:21","tags":null,"title":"Docker集群迁移K8s记录","uri":"/docker%E9%9B%86%E7%BE%A4%E8%BF%81%E7%A7%BBk8s%E8%AE%B0%E5%BD%95/"},{"categories":null,"content":"时区的配置问题 从官方下载的镜像都会有默认时区，一般我们使用的时候都需要更改时区，更改时区的方式有多种，这里简单说两种。一是将容器镜像的/etc/loacltime根据需要设置为对应的时区，二是采用配置文件中的volume挂载宿主机对应的localtime文件的方式。推荐采用第二种方式。 ","date":"2023-04-16","objectID":"/docker%E9%9B%86%E7%BE%A4%E8%BF%81%E7%A7%BBk8s%E8%AE%B0%E5%BD%95/:2:22","tags":null,"title":"Docker集群迁移K8s记录","uri":"/docker%E9%9B%86%E7%BE%A4%E8%BF%81%E7%A7%BBk8s%E8%AE%B0%E5%BD%95/"},{"categories":null,"content":"使用 Helm 使用 Helm 管理所有的 资源对象的定义（yaml文件）； ","date":"2023-04-16","objectID":"/docker%E9%9B%86%E7%BE%A4%E8%BF%81%E7%A7%BBk8s%E8%AE%B0%E5%BD%95/:2:23","tags":null,"title":"Docker集群迁移K8s记录","uri":"/docker%E9%9B%86%E7%BE%A4%E8%BF%81%E7%A7%BBk8s%E8%AE%B0%E5%BD%95/"},{"categories":null,"content":"Service 的命名 一般是 “业务名-应用服务器类型-其他标识” ","date":"2023-04-16","objectID":"/docker%E9%9B%86%E7%BE%A4%E8%BF%81%E7%A7%BBk8s%E8%AE%B0%E5%BD%95/:2:24","tags":null,"title":"Docker集群迁移K8s记录","uri":"/docker%E9%9B%86%E7%BE%A4%E8%BF%81%E7%A7%BBk8s%E8%AE%B0%E5%BD%95/"},{"categories":null,"content":"NameSpace的区分 集群内部同时运行开发、测试、staging、生产环境，通过NameSpace实现不同运行环境的隔离，同时应用软件在不同的运行环境之间也不会产生命名冲突。 ","date":"2023-04-16","objectID":"/docker%E9%9B%86%E7%BE%A4%E8%BF%81%E7%A7%BBk8s%E8%AE%B0%E5%BD%95/:2:25","tags":null,"title":"Docker集群迁移K8s记录","uri":"/docker%E9%9B%86%E7%BE%A4%E8%BF%81%E7%A7%BBk8s%E8%AE%B0%E5%BD%95/"},{"categories":null,"content":"三、脚本记录 ","date":"2023-04-16","objectID":"/docker%E9%9B%86%E7%BE%A4%E8%BF%81%E7%A7%BBk8s%E8%AE%B0%E5%BD%95/:3:0","tags":null,"title":"Docker集群迁移K8s记录","uri":"/docker%E9%9B%86%E7%BE%A4%E8%BF%81%E7%A7%BBk8s%E8%AE%B0%E5%BD%95/"},{"categories":null,"content":"Namespace apiVersion: v1 kind: Namespace metadata: name: sinfcloud ","date":"2023-04-16","objectID":"/docker%E9%9B%86%E7%BE%A4%E8%BF%81%E7%A7%BBk8s%E8%AE%B0%E5%BD%95/:3:1","tags":null,"title":"Docker集群迁移K8s记录","uri":"/docker%E9%9B%86%E7%BE%A4%E8%BF%81%E7%A7%BBk8s%E8%AE%B0%E5%BD%95/"},{"categories":null,"content":"Pvc ############################ ####### 默认nfs为存储 ######## ############################ kind: PersistentVolume apiVersion: v1 metadata: name: sc-pv-sinfcloud-data namespace: sinfcloud annotations: pv.kubernetes.io/provisioned-by: cluster.local/nfs-client-nfs-client-provisioner finalizers: - kubernetes.io/pv-protection spec: capacity: storage: 10Gi nfs: server: 192.168.1.187 path: /home/nfs #确保当前路径存在 accessModes: - ReadWriteOnce persistentVolumeReclaimPolicy: Delete storageClassName: nfs-client volumeMode: Filesystem --- kind: PersistentVolumeClaim apiVersion: v1 metadata: name: sincloud-pvc namespace: sinfcloud annotations: kubesphere.io/creator: admin pv.kubernetes.io/bind-completed: 'yes' pv.kubernetes.io/bound-by-controller: 'yes' volume.beta.kubernetes.io/storage-provisioner: cluster.local/nfs-client-nfs-client-provisioner finalizers: - kubernetes.io/pvc-protection spec: accessModes: - ReadWriteOnce resources: requests: storage: 10Gi volumeName: sc-pv-sinfcloud-data storageClassName: nfs-client volumeMode: Filesystem ","date":"2023-04-16","objectID":"/docker%E9%9B%86%E7%BE%A4%E8%BF%81%E7%A7%BBk8s%E8%AE%B0%E5%BD%95/:3:2","tags":null,"title":"Docker集群迁移K8s记录","uri":"/docker%E9%9B%86%E7%BE%A4%E8%BF%81%E7%A7%BBk8s%E8%AE%B0%E5%BD%95/"},{"categories":null,"content":"K8sYaml kind: Deployment apiVersion: apps/v1 metadata: name: remp-nrp-tpi namespace: remp spec: replicas: 1 strategy: rollingUpdate: maxSurge: 1 maxUnavailable: 25% type: RollingUpdate selector: matchLabels: app: remp-nrp-tpi template: metadata: creationTimestamp: null labels: app: remp-nrp-tpi spec: imagePullSecrets: - name: remp-harbor-secret containers: - name: consumer-public-ability-nrp-tpi-app image: hub.sinfcloud.com/remp/consumer-public-ability-nrp-tpi-v1:latest imagePullPolicy: Always env: - name: TZ value: Asia/Shanghai - name: NACOS_URL value: ibase-nacos-headless.ibase-kingbase:8848 - name: REGISTRY_MODE value: nacos - name: CONFIG_USERNAME value: ibaseconf - name: CONFIG_PASSWORD value: super56\u0026*9 resources: {} command: [\"/bin/sh\"] args: [\"-c\",\"java -Djava.security.egd=file:/dev/./urandom -jar ./app.jar\"] - name: consumer-sso-nrp-tpi-app image: hub.sinfcloud.com/remp/consumer-sso-nrp-tpi-v1:latest imagePullPolicy: Always env: - name: TZ value: Asia/Shanghai - name: NACOS_URL value: ibase-nacos-headless.ibase-kingbase:8848 - name: REGISTRY_MODE value: nacos - name: CONFIG_USERNAME value: ibaseconf - name: CONFIG_PASSWORD value: super56\u0026*9 resources: {} command: [\"/bin/sh\"] args: [\"-c\",\"java -Djava.security.egd=file:/dev/./urandom -jar ./app.jar\"] - name: consumer-user-nrp-tpi-app image: hub.sinfcloud.com/remp/consumer-user-nrp-tpi-v1:latest imagePullPolicy: Always env: - name: TZ value: Asia/Shanghai - name: NACOS_URL value: ibase-nacos-headless.ibase-kingbase:8848 - name: REGISTRY_MODE value: nacos - name: CONFIG_USERNAME value: ibaseconf - name: CONFIG_PASSWORD value: super56\u0026*9 resources: {} command: [\"/bin/sh\"] args: [\"-c\",\"java -Djava.security.egd=file:/dev/./urandom -jar ./app.jar\"] - name: provider-public-ability-nrp-tpi-app image: hub.sinfcloud.com/remp/provider-public-ability-nrp-tpi-v1:latest imagePullPolicy: Always env: - name: TZ value: Asia/Shanghai - name: NACOS_URL value: ibase-nacos-headless.ibase-kingbase:8848 - name: REGISTRY_MODE value: nacos - name: CONFIG_USERNAME value: ibaseconf - name: CONFIG_PASSWORD value: super56\u0026*9 resources: {} command: [\"/bin/sh\"] args: [\"-c\",\"java -Djava.security.egd=file:/dev/./urandom -jar ./app.jar\"] restartPolicy: Always terminationGracePeriodSeconds: 30 ","date":"2023-04-16","objectID":"/docker%E9%9B%86%E7%BE%A4%E8%BF%81%E7%A7%BBk8s%E8%AE%B0%E5%BD%95/:3:3","tags":null,"title":"Docker集群迁移K8s记录","uri":"/docker%E9%9B%86%E7%BE%A4%E8%BF%81%E7%A7%BBk8s%E8%AE%B0%E5%BD%95/"},{"categories":null,"content":"DockerFile #Docker FROM hub.sinfcloud.com/support/openjdk8-openj9:alpine-slim-jre #作者邮箱必写 MAINTAINER liulining@supermap.com #同步时间 RUN ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime #创建一个文件夹 RUN mkdir -p /ThirdParty-PublicAbility-App-v1/agent #指定一个工作空间 WORKDIR /ThirdParty-PublicAbility-App-v1 #指定端口 EXPOSE 7806 #将其编译之后的jar文件添加 ADD ./target/ThirdParty-PublicAbility-App.jar ./app.jar #wait-for ADD ./wait-for ./ RUN chmod +x wait-for # 添加wait-for-it.sh ADD ./wait-for-it.sh ./ RUN chmod +x wait-for-it.sh #运行命令 #CMD java -Djava.security.egd=file:/dev/./urandom -jar app.jar ${JAVA_OPTS: } ENTRYPOINT [\"java\",\"-Djava.security.egd=file:/dev/./urandom\",\"-jar\",\"app.jar\"] Arm-aarch64 ","date":"2023-04-16","objectID":"/docker%E9%9B%86%E7%BE%A4%E8%BF%81%E7%A7%BBk8s%E8%AE%B0%E5%BD%95/:3:4","tags":null,"title":"Docker集群迁移K8s记录","uri":"/docker%E9%9B%86%E7%BE%A4%E8%BF%81%E7%A7%BBk8s%E8%AE%B0%E5%BD%95/"},{"categories":null,"content":"DockerCompose version: '2' services: ams-consumer-app: image: ${HUB_URL}/${PROJECT_NAME}/ams-consumer-app:${TAG} build: dockerfile: ./Dockerfile context: ./ams-consumer-app # ams-dajy-provider-app: # image: ${HUB_URL}/${PROJECT_NAME}/ams-dajy-provider-app:${TAG} # build: # dockerfile: ./Dockerfile # context: ./ams-dajy-provider-app ams-st-provider-app: image: ${HUB_URL}/${PROJECT_NAME}/ams-st-provider-app:${TAG} build: dockerfile: ./Dockerfile context: ./ams-st-provider-app remp-dj-db-provider-app: image: ${HUB_URL}/${PROJECT_NAME}/remp-dj-db-provider-app:${TAG} build: dockerfile: ./Dockerfile context: ./remp-dj-db-provider-app # remp-dj-gis-provider-app: # image: ${HUB_URL}/${PROJECT_NAME}/remp-dj-gis-provider-app:${TAG} # build: # dockerfile: ./Dockerfile # context: ./remp-dj-gis-provider-app # remp-dj-sjsh-consumer-app: image: ${HUB_URL}/${PROJECT_NAME}/remp-dj-sjsh-consumer-app:${TAG} build: dockerfile: ./Dockerfile context: ./remp-dj-sjsh-consumer-app remp-dj-sjsh-provider-app: image: ${HUB_URL}/${PROJECT_NAME}/remp-dj-sjsh-provider-app:${TAG} build: dockerfile: ./Dockerfile context: ./remp-dj-sjsh-provider-app remp-dj-sl-consumer-app: image: ${HUB_URL}/${PROJECT_NAME}/remp-dj-sl-consumer-app:${TAG} build: dockerfile: ./Dockerfile context: ./remp-dj-sl-consumer-app remp-dj-sl-provider-app: image: ${HUB_URL}/${PROJECT_NAME}/remp-dj-sl-provider-app:${TAG} build: dockerfile: ./Dockerfile context: ./remp-dj-sl-provider-app remp-dj-ywcx-consumer-app: image: ${HUB_URL}/${PROJECT_NAME}/remp-dj-ywcx-consumer-app:${TAG} build: dockerfile: ./Dockerfile context: ./remp-dj-ywcx-consumer-app remp-dj-ywcx-provider-app: image: ${HUB_URL}/${PROJECT_NAME}/remp-dj-ywcx-provider-app:${TAG} build: dockerfile: ./Dockerfile context: ./remp-dj-ywcx-provider-app remp-dj-ywgl-consumer-app: image: ${HUB_URL}/${PROJECT_NAME}/remp-dj-ywgl-consumer-app:${TAG} build: dockerfile: ./Dockerfile context: ./remp-dj-ywgl-consumer-app remp-dj-ywgl-provider-app: image: ${HUB_URL}/${PROJECT_NAME}/remp-dj-ywgl-provider-app:${TAG} build: dockerfile: ./Dockerfile context: ./remp-dj-ywgl-provider-app # remp-dj-ywjggl-consumer-app: # image: ${HUB_URL}/${PROJECT_NAME}/remp-dj-ywjggl-consumer-app:${TAG} # build: # dockerfile: ./Dockerfile # context: ./remp-dj-ywjggl-consumer-app # # remp-dj-ywjggl-provider-app: # image: ${HUB_URL}/${PROJECT_NAME}/remp-dj-ywjggl-provider-app:${TAG} # build: # dockerfile: ./Dockerfile # context: ./remp-dj-ywjggl-provider-app # smpm-consumer-app: # image: ${HUB_URL}/${PROJECT_NAME}/smpm-consumer-app:${TAG} # build: # dockerfile: ./Dockerfile # context: ./smpm-consumer-app # # smpm-dj-arcgis-provider-app: # image: ${HUB_URL}/${PROJECT_NAME}/smpm-dj-arcgis-provider-app:${TAG} # build: # dockerfile: ./Dockerfile # context: ./smpm-dj-arcgis-provider-app # # smpm-dj-cg-provider-app: # image: ${HUB_URL}/${PROJECT_NAME}/smpm-dj-cg-provider-app:${TAG} # build: # dockerfile: ./Dockerfile # context: ./smpm-dj-cg-provider-app # # smpm-dj-gis-provider-app: # image: ${HUB_URL}/${PROJECT_NAME}/smpm-dj-gis-provider-app:${TAG} # build: # dockerfile: ./Dockerfile # context: ./smpm-dj-gis-provider-app # # smpm-dj-jg-provider-app: # image: ${HUB_URL}/${PROJECT_NAME}/smpm-dj-jg-provider-app:${TAG} # build: # dockerfile: ./Dockerfile # context: ./smpm-dj-jg-provider-app # # smpm-dj-sl-provider-app: # image: ${HUB_URL}/${PROJECT_NAME}/smpm-dj-sl-provider-app:${TAG} # build: # dockerfile: ./Dockerfile # context: ./smpm-dj-sl-provider-app # -------------------------------------------------------------------------------------------------------- # nrp-tpi 构建 START # updateBy lln # updateTime 23-08-31 # 三方接入-公共能力消费者 ThirdParty-PublicAbility-Consumer-App: image: hub.sinfcloud.com/remp/consumer-public-ability-nrp-tpi-v1:latest build: context: ./ThirdParty-PublicAbility-Consumer-App dockerfile: ./Dockerfile # 三方接入-单点登录消费者 ThirdParty-SSO-Consumer-App: image: hub.sinfcloud.com/remp/consumer-sso-nrp-tpi-v1:latest build: context: ./ThirdParty-SSO-Consumer-App dockerfile","date":"2023-04-16","objectID":"/docker%E9%9B%86%E7%BE%A4%E8%BF%81%E7%A7%BBk8s%E8%AE%B0%E5%BD%95/:3:5","tags":null,"title":"Docker集群迁移K8s记录","uri":"/docker%E9%9B%86%E7%BE%A4%E8%BF%81%E7%A7%BBk8s%E8%AE%B0%E5%BD%95/"},{"categories":null,"content":"jenkinsFile #!/usr/bin/env groovy Jenkinsfile pipeline { agent any environment{ MAVEN_HOME = \"/home/maven/apache-maven-3.8.8\" } stages { stage('拉取代码') { steps { checkout([$class: 'SubversionSCM', additionalCredentials: [], excludedCommitMessages: '', excludedRegions: '', excludedRevprop: '', excludedUsers: '', filterChangelog: false, ignoreDirPropChanges: false, includedRegions: '', locations: [[cancelProcessOnExternalsFail: true, credentialsId: 'remp-svn', depthOption: 'infinity', ignoreExternalsOption: true, local: '.', remote: 'http://115.236.9.62:20020/NRP-REMPVE6/trunk/nrp-parent/nrp-tpi']], quietOperation: true, workspaceUpdater: [$class: 'UpdateUpdater']]) } } stage('编译代码') { steps { echo \"开始编译打包\" sh \"mvn clean package -Dmaven.test.skip=true -U -T 4\" echo \"编译打包完成\" sh \"rm -rf ./.svn\" } } stage('制作镜像') { parallel { stage('制作消费者【publicAbility-consumer】') { steps { sh \"docker build -t hub.sinfcloud.com/remp/consumer-public-ability-nrp-tpi-v1:latest .././nrp-publish/ThirdParty-PublicAbility-Consumer-App\" } } stage('制作消费者【sso-consumer】') { steps { sh \"docker build -t hub.sinfcloud.com/remp/consumer-sso-nrp-tpi-v1:latest .././nrp-publish/ThirdParty-SSO-Consumer-App\" } } stage('制作消费者【user-consumer】') { steps { sh \"docker build -t hub.sinfcloud.com/remp/consumer-user-nrp-tpi-v1:latest .././nrp-publish/ThirdParty-User-Consumer-App\" } } stage('制作提供者【ThirdParty-Provider-App】') { steps { sh \"docker build -t hub.sinfcloud.com/remp/provider-public-ability-nrp-tpi-v1:latest .././nrp-publish/ThirdParty-PublicAbility-App\" } } } } stage('推送仓库') { parallel { stage('推送消费者【publicAbility-consumer】'){ steps { sh \"docker push hub.sinfcloud.com/remp/consumer-public-ability-nrp-tpi-v1:latest\" } } stage('推送消费者【sso-consumer】'){ steps { sh \"docker push hub.sinfcloud.com/remp/consumer-sso-nrp-tpi-v1:latest\" } } stage('推送消费者【user-consumer】'){ steps { sh \"docker push hub.sinfcloud.com/remp/consumer-user-nrp-tpi-v1:latest\" } } stage('推送提供者【publicAbility-provider】'){ steps { sh \"docker push hub.sinfcloud.com/remp/provider-public-ability-nrp-tpi-v1:latest\" } } } } stage('更新服务'){ steps { sshPublisher(publishers: [sshPublisherDesc(configName: 'kubernetes-master', transfers: [sshTransfer(cleanRemote: false, excludes: '', execCommand: 'kubectl rollout restart deployment remp-nrp-tpi -n remp \u0026\u0026 kubectl rollout status deployment remp-nrp-tpi -n remp', execTimeout: 120000, flatten: false, makeEmptyDirs: false, noDefaultExcludes: false, patternSeparator: '[, ]+', remoteDirectory: '', remoteDirectorySDF: false, removePrefix: '', sourceFiles: '')], usePromotionTimestamp: false, useWorkspaceInPromotion: false, verbose: true)]) } } } } 四、腾讯云使用 TKE https://cloud.tencent.com/document/product/457 TSF https://cloud.tencent.com/document/product/649 五、资源申请 基于在研发环境的压测情况，和裸数据库的压测情况，结合各个市租户的历史的并发数量，进行估算。 提供申请资源量的支撑材料， 按一个租户（市县）用户200人，因登记中心业务时间较为集中，故按50%人数计算并发量（20050%=100）， 一个租户互联网用户2000，按5%计算并发量（20005%=100）， 故一个市的并发量为200，一期上线3个市共600并发，按照相应公式申请如下容器资源： 业务名称 容器名 负载 配置 利用率 容器数量 全局管理服务 全局管理服务 CPU 16核 37.89% 1 内存 32 G 23.28% 访问控制服务 访问控制服务 CPU 16核 59.21% 1 内存 32 G 25.24% 工作流服务 工作流服务 CPU 16核 56.68% 1 内存 32 G 19.2% 编码中心服务 编码中心服务 CPU 16核 28.74% 1 内存 32 G 21.03% 单点登录服务 单点登录服务 CPU 16核 76.15% 1 内存 32 G 18.73% 不动产登记系统服务 不动产登记系统服务 CPU 16核 23.24% 1 内存 32 G 26.99% 地籍系统服务 地籍系统服务 CPU 16核 34.28% 1 内存 32 G 15.79% 通用组件服务 通用组件服务 CPU 16核 35.46% 1 内存 32 G 28.81% 档案系统服务 档案系统服务 CPU 16核 21.26% 1 内存 32 G 19.51% 中文名称 CPU 内存 测试规格 测试场景 申请规格 申请数量 申请说明 全局管理服务 37.89% 23.28% 16C 32GB 100 8C 16GB 5 以100并发进行测试，CPU使用37.89%，内存使用23.28%，按比例得出600并发时，该场景所需资源为：37.89%* 6=227.34%（CPU），转换为CPU核数约为16C*227.34%=36C，23.28%6=139.68%（内存），转换为内存约为32GB139.68%=45GB，故该场景需要申请5个 8核CPU、内存16 G 容器较为符合场景需求。 访问控制服务 59.21% 25.24% 16C 32GB 100 16C 16GB 4 以100并发进行测试，CPU使用59.21%，内存使用25.24%，按比例得出600并发时，该场景所需资源为：59.21%* 6=355.26%（CPU），转换为CPU核数约为16C*355.26%=57C，25.24%6=151.44%（内存），转换为内存约为32GB151.44%=48GB，该服务CPU资源使用率较高，故该场景需要申请4个 16核CPU、内存16 G 容器较为符合场景需求。 工作流服务 56.68% 19.2% 16C 32GB 100 16C 16GB 4 以100并发进行测试，CPU使用56.68%，内存使用19.2%，按比例得出600并发时，该场景所需资源","date":"2023-04-16","objectID":"/docker%E9%9B%86%E7%BE%A4%E8%BF%81%E7%A7%BBk8s%E8%AE%B0%E5%BD%95/:3:6","tags":null,"title":"Docker集群迁移K8s记录","uri":"/docker%E9%9B%86%E7%BE%A4%E8%BF%81%E7%A7%BBk8s%E8%AE%B0%E5%BD%95/"},{"categories":["其他"],"content":"代码加密工具Proguard使用说明","date":"2023-03-04","objectID":"/%E4%BB%A3%E7%A0%81%E5%8A%A0%E5%AF%86/","tags":["其他"],"title":"代码加密工具Proguard使用说明","uri":"/%E4%BB%A3%E7%A0%81%E5%8A%A0%E5%AF%86/"},{"categories":["其他"],"content":"系统、数据库性能测试记录 代码加密工具Proguard使用说明 CreateBy lln CreateTime 2023-02-01 ProguardVersion 7.2.2 ","date":"2023-03-04","objectID":"/%E4%BB%A3%E7%A0%81%E5%8A%A0%E5%AF%86/:0:0","tags":["其他"],"title":"代码加密工具Proguard使用说明","uri":"/%E4%BB%A3%E7%A0%81%E5%8A%A0%E5%AF%86/"},{"categories":["其他"],"content":"一、需求背景 需要对提供给客户的Java客户端代码进行混淆，破坏其可读性，防止核心代码被反编译。 ","date":"2023-03-04","objectID":"/%E4%BB%A3%E7%A0%81%E5%8A%A0%E5%AF%86/:1:0","tags":["其他"],"title":"代码加密工具Proguard使用说明","uri":"/%E4%BB%A3%E7%A0%81%E5%8A%A0%E5%AF%86/"},{"categories":["其他"],"content":"二、技术选型 采用 ProGuard 工具软件进行代码加密混淆工作。 ProGuard是Java类文件收缩器、优化器、混淆器和预验证器。可以使代码库更小、更有效、更好地抵御逆向工程。 官网地址 https://github.com/Guardsquare/proguard 参考博客 https://blog.csdn.net/weixin_44462773/article/details/124172382 ","date":"2023-03-04","objectID":"/%E4%BB%A3%E7%A0%81%E5%8A%A0%E5%AF%86/:2:0","tags":["其他"],"title":"代码加密工具Proguard使用说明","uri":"/%E4%BB%A3%E7%A0%81%E5%8A%A0%E5%AF%86/"},{"categories":["其他"],"content":"三、混淆效果展示 对于包名称，不进行混淆（可在加密时进行配置，但不推荐，会影响反射调用） 对于类，进行名称混淆。 对于特定的文件，如启动类、资源文件，不进行混淆。 ","date":"2023-03-04","objectID":"/%E4%BB%A3%E7%A0%81%E5%8A%A0%E5%AF%86/:3:0","tags":["其他"],"title":"代码加密工具Proguard使用说明","uri":"/%E4%BB%A3%E7%A0%81%E5%8A%A0%E5%AF%86/"},{"categories":["其他"],"content":"四、配置流程 以下是配置加密的步骤流程。 ","date":"2023-03-04","objectID":"/%E4%BB%A3%E7%A0%81%E5%8A%A0%E5%AF%86/:4:0","tags":["其他"],"title":"代码加密工具Proguard使用说明","uri":"/%E4%BB%A3%E7%A0%81%E5%8A%A0%E5%AF%86/"},{"categories":["其他"],"content":"1 、打开GUI界面 通过官网下载最新的安装包，打开如图所示GUI操作界面，如下图所示。 ","date":"2023-03-04","objectID":"/%E4%BB%A3%E7%A0%81%E5%8A%A0%E5%AF%86/:4:1","tags":["其他"],"title":"代码加密工具Proguard使用说明","uri":"/%E4%BB%A3%E7%A0%81%E5%8A%A0%E5%AF%86/"},{"categories":["其他"],"content":"2、功能菜单说明 ProGuard 主界面，用于加载配置文件 Input/Output 包选择界面，配置目标包信息和依赖包信息 Shrinking 代码收缩配置【未测试使用】 Obfuscation 代码加密配置 Optimization 代码优化配置【未测试使用】 Information 相关信息 Process 运行界面 ReTrace 回溯界面 ","date":"2023-03-04","objectID":"/%E4%BB%A3%E7%A0%81%E5%8A%A0%E5%AF%86/:4:2","tags":["其他"],"title":"代码加密工具Proguard使用说明","uri":"/%E4%BB%A3%E7%A0%81%E5%8A%A0%E5%AF%86/"},{"categories":["其他"],"content":"3、加载配置文件 选择【Load configuration】加载【qjdc3d.pro】配置文件。 ","date":"2023-03-04","objectID":"/%E4%BB%A3%E7%A0%81%E5%8A%A0%E5%AF%86/:4:3","tags":["其他"],"title":"代码加密工具Proguard使用说明","uri":"/%E4%BB%A3%E7%A0%81%E5%8A%A0%E5%AF%86/"},{"categories":["其他"],"content":"4、添加包信息 添加要加密的jar包、导出的jar包、依赖的jar包 ","date":"2023-03-04","objectID":"/%E4%BB%A3%E7%A0%81%E5%8A%A0%E5%AF%86/:4:4","tags":["其他"],"title":"代码加密工具Proguard使用说明","uri":"/%E4%BB%A3%E7%A0%81%E5%8A%A0%E5%AF%86/"},{"categories":["其他"],"content":"5、进行加密配置 需要特殊配置的信息如下 1、项目代码的包结构，包的名称、不可变（影响部分反射代码） 2、ctrlAction相关的代码，类名称不可变（桌面端插件信息读取，需要扫描配置在xml中的类名称） 3、所有反射用到的实体类信息，字段及构造方法，不可变（有部分工具代码，是从dataset数据中通过实体对象的字段反射进行数据的匹配） 4、启动配置类，类名称、方法不可变（启动类有main函数） ","date":"2023-03-04","objectID":"/%E4%BB%A3%E7%A0%81%E5%8A%A0%E5%AF%86/:4:5","tags":["其他"],"title":"代码加密工具Proguard使用说明","uri":"/%E4%BB%A3%E7%A0%81%E5%8A%A0%E5%AF%86/"},{"categories":["其他"],"content":"五、采坑记录 1、所有参与了反射调用的代码、第三方框架的代码，通过类加载器进行特殊操作的代码，都不可变。否则会出现难以理解和调试的错误。如奇怪的Npe调用，奇怪的报错，程序秒退等。 2、不建议对包结构和路径进行改变，如名称混淆、压缩等。 3、在客户端插件系统中，不建议对代码进行压缩和优化操作，出现了很多无法处理的问题，如action无法识别，打不开部分功能。只建议进行加密操作。 ","date":"2023-03-04","objectID":"/%E4%BB%A3%E7%A0%81%E5%8A%A0%E5%AF%86/:5:0","tags":["其他"],"title":"代码加密工具Proguard使用说明","uri":"/%E4%BB%A3%E7%A0%81%E5%8A%A0%E5%AF%86/"},{"categories":["其他"],"content":"六、配置文件修改步骤 加载配置文件后，导入的包路径，都不是自己的本地路径，可以将【.pro】文件打开，批量替换路径为自己的本地包，如下图。建议将jre的包和desktopx的所有包，都放在同一文件夹中，便于修改和关联。 ","date":"2023-03-04","objectID":"/%E4%BB%A3%E7%A0%81%E5%8A%A0%E5%AF%86/:6:0","tags":["其他"],"title":"代码加密工具Proguard使用说明","uri":"/%E4%BB%A3%E7%A0%81%E5%8A%A0%E5%AF%86/"},{"categories":["其他"],"content":"七、思考和总结 1、如果需要代码加密工作，最好是在软件开发之初就进行规划，和不断集成测试。而不是在收尾阶段进行。 2、java代码的加密工作，注意事项，总得来说有2点，其一是所有和反射调用有上下文关联的代码，都要筛选出来进行特殊处理；其二是和资源文件关联的代码，也要注意不要因为特殊的混淆，导致文件名找不到而引发的后续报错。 3、如何进行有效的规划？最好在代码设计之初，就规划好哪些包需要加密（如核心算法，核心业务逻辑），在代码结构上加以区分，以便于后续处理。 ","date":"2023-03-04","objectID":"/%E4%BB%A3%E7%A0%81%E5%8A%A0%E5%AF%86/:7:0","tags":["其他"],"title":"代码加密工具Proguard使用说明","uri":"/%E4%BB%A3%E7%A0%81%E5%8A%A0%E5%AF%86/"},{"categories":["分布式"],"content":"多租户设计记录","date":"2022-07-29","objectID":"/%E5%A4%9A%E7%A7%9F%E6%88%B7%E8%AE%BE%E8%AE%A1/","tags":["架构"],"title":"多租户设计记录","uri":"/%E5%A4%9A%E7%A7%9F%E6%88%B7%E8%AE%BE%E8%AE%A1/"},{"categories":["分布式"],"content":"多租户对于用户来说，最主要的一点就在于数据隔离，不可以说，我登了A用户的号，但是看到了B用户的数据。 常见的大概就四种： ","date":"2022-07-29","objectID":"/%E5%A4%9A%E7%A7%9F%E6%88%B7%E8%AE%BE%E8%AE%A1/:0:0","tags":["架构"],"title":"多租户设计记录","uri":"/%E5%A4%9A%E7%A7%9F%E6%88%B7%E8%AE%BE%E8%AE%A1/"},{"categories":["分布式"],"content":"方案一： 单数据源单数据库单数据表 所有租户使用同一数据源下同一数据库下共同数据表，在每一个数据表中增加一列租户ID，用以区分租户的数据。增删查改时，一定要带上租户ID，否则就会操作到其他租户的数据 典型的解决方案就是通过AOP，隐式的为我们的每一个SQL带上这个租户ID。 而在orm框架如mybatis中，可以拦截器插件进行SQL层面的拦截拼接，而MyBatis-Plus高版本则提供了更加方便的拦截器，并且已经将多租户插件放入JAR包，将该插件加入到MyBatis的拦截器链中，就可以不用再显式的拼接租户ID字段 优缺点： 该方案成本最低，安全性也是最低，所有数据都放在一起，单个租户的数据恢复和备份会很复杂。 比如，有ABC三个租户共同使用，当C租户已经确定以后不再使用了，他的数据也不好从数据库中剔除。如果某一数据出现了问题，也不便于租户问题的排查。 这就得保证对开发者的严苛要求，最主要还是增加了对数据的管理复杂度。尤其注意，尽量不要去手动显式的设置租户ID到SQL，否则一旦出现问题，纠正是很复杂的 ","date":"2022-07-29","objectID":"/%E5%A4%9A%E7%A7%9F%E6%88%B7%E8%AE%BE%E8%AE%A1/:1:0","tags":["架构"],"title":"多租户设计记录","uri":"/%E5%A4%9A%E7%A7%9F%E6%88%B7%E8%AE%BE%E8%AE%A1/"},{"categories":["分布式"],"content":"方案二：单数据源单数据库多数据表 所有租户使用同一数据源下同一数据库下不同数据表 比如租户A的用户表叫user_001，用户B的用户表叫user_002 数据库难以实现连表查询，只能进行多次单表查询，对事务的控制基本为0。 一般来说，对于小场景而言，这种架构的设计已经完全够用了 新建租户时需要建表，每次建表，都要使用DDL建新租户所使用的所有表。 优缺点： 该方案提供了一定的数据隔离，但不是完全的隔离，由于数据库是共享的，所以成本也不是很高。 ","date":"2022-07-29","objectID":"/%E5%A4%9A%E7%A7%9F%E6%88%B7%E8%AE%BE%E8%AE%A1/:2:0","tags":["架构"],"title":"多租户设计记录","uri":"/%E5%A4%9A%E7%A7%9F%E6%88%B7%E8%AE%BE%E8%AE%A1/"},{"categories":["分布式"],"content":"方案三：单数据源多数据库多数据表 所有租户使用同一数据源下不同数据库下不同数据表 将租户数据彻底隔离，给每个租户创建一个数据库 基本上和方案二类似 在完成数据表的创建后，然后就是具体的增删改查问题。还是可以使用MyBatis插件，动态的改造表名，在表名前拼接上数据库名，具体的实现也是非常简单，直接拿方案二稍微改改即可。 使用这种单数据源方案可以轻松实现跨数据库执行SQL和事务执行。 优缺点： 该方案其实和方案二大同小异，对单数据源来说，都不是彻底的隔离。成本和方案二差不多。 ","date":"2022-07-29","objectID":"/%E5%A4%9A%E7%A7%9F%E6%88%B7%E8%AE%BE%E8%AE%A1/:3:0","tags":["架构"],"title":"多租户设计记录","uri":"/%E5%A4%9A%E7%A7%9F%E6%88%B7%E8%AE%BE%E8%AE%A1/"},{"categories":["分布式"],"content":"方案四：单数据源多数据库多数据表 所有租户使用不同数据源下不同数据库下不同数据表 在单数据源中，跨数据库操作和数据库事务是已经被支持的。 但是在多数据源中，传统的跨库操作和数据库事务已经难以适用，甚至有时候会出现动态的新增租户，并且租户数据源动态配置等问题。 这时，光靠简单的几百行代码已经无法实现。以下是几个方案来： 使用AOP加注解动态切换数据源 使用MyBatis插件切换数据源（可以比较方便的判断SQL类型，区分读写操作） 多个MyBatis配置来引入多个数据源（比较占内存） 这种多数据源方案，目前也有一些开源项目实现了这一方案。就是为不同的租户提供独立的数据库，数据库由租户自己购买，或商家购买，然后配置到系统中，满足不同租户的独特需求，如果出现故障，数据恢复也比较简单。 优缺点： 这种方案增加了数据库的安装数量，单个数据库的资源利用率就不高了，而且数据库的数量一多，成本就高了，安全性的代价就是成本。还要考虑到多数据库的事务问题，多数据库的数据源切换问题，这代码复杂度和成本就上来了，相当费钱 ","date":"2022-07-29","objectID":"/%E5%A4%9A%E7%A7%9F%E6%88%B7%E8%AE%BE%E8%AE%A1/:4:0","tags":["架构"],"title":"多租户设计记录","uri":"/%E5%A4%9A%E7%A7%9F%E6%88%B7%E8%AE%BE%E8%AE%A1/"},{"categories":["分布式"],"content":"ELK日志框架集成","date":"2022-03-05","objectID":"/elk%E6%97%A5%E5%BF%97/","tags":["分布式"],"title":"ELK日志框架集成","uri":"/elk%E6%97%A5%E5%BF%97/"},{"categories":["分布式"],"content":"ELK日志框架集成 createBy jdzt.lln createTime 2022-01-01 业务场景及需求说明 公司现在有内网虚拟机多台，分别部署了多个不同环境（测试环境、试用环境、演示环境等）的项目（地灾、岩土、地勘等），同时对接了多个外部服务（致远OA，在线预览、python算法等），在开发阶段处理不同环境出现的问题时，基于日志来定位问题十分关键，但现阶段对于日志管理还处于十分混乱的情况，没有进行统一的收集和处理，导致开发人员在定位和处理不同项目的不同环境的不同数据的相同问题时，定位和分析十分困难。 ELK即作为新框架EasyCloud的架构的重要组成部分，也为解决以上问题，具备了实际需求和场景。 ELK是由elasticsearch+Logstash+kibana三款开源软件组合而成的日志收集处理套件，其中Logstash负责日志收集，elasticsearch负责日志的搜索、统计，而kibana则是ES的展示。 使用版本信息如下： Elasticsearch version 7.16.2 Logstash version 7.16.2 kibana version 7.16.2 参考文档 官网文档 https://www.elastic.co/guide/en/elasticsearch/reference/current/docker.html https://www.elastic.co/guide/en/logstash/current/docker.html 博客 https://blog.csdn.net/shykevin/article/details/108251996 https://www.cnblogs.com/chinda/p/13125625.html https://www.cnblogs.com/xiao987334176/p/13565468.html https://blog.csdn.net/soulteary/article/details/105921729 ","date":"2022-03-05","objectID":"/elk%E6%97%A5%E5%BF%97/:0:0","tags":["分布式"],"title":"ELK日志框架集成","uri":"/elk%E6%97%A5%E5%BF%97/"},{"categories":["分布式"],"content":"一 Elasticsearch安装 ","date":"2022-03-05","objectID":"/elk%E6%97%A5%E5%BF%97/:1:0","tags":["分布式"],"title":"ELK日志框架集成","uri":"/elk%E6%97%A5%E5%BF%97/"},{"categories":["分布式"],"content":"1.1 Elasticsearch安装 ","date":"2022-03-05","objectID":"/elk%E6%97%A5%E5%BF%97/:2:0","tags":["分布式"],"title":"ELK日志框架集成","uri":"/elk%E6%97%A5%E5%BF%97/"},{"categories":["分布式"],"content":"1.1.1 docker docker pull docker.elastic.co/elasticsearch/elasticsearch:7.16.2 docker run \\ --name elk_es \\ --privileged=true \\ --restart=always \\ -d \\ -e ES_JAVA_OPTS=\"-Xms512m -Xmx512m\" \\ -e \"discovery.type=single-node\" \\ -v /opt/elk/es/:/usr/elasticsearch/data \\ -v /opt/elk/es/conf/elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml \\ -v /opt/elk/es/plugins:/usr/share/elasticsearch/plugins \\ -p 9200:9200 \\ -p 9300:9300 \\ 66c29cde15ce docker run \\ --name elk_es \\ --privileged=true \\ --restart=always \\ -d \\ -e ES_JAVA_OPTS=\"-Xms512m -Xmx512m\" \\ -e \"discovery.type=single-node\" \\ -v /opt/elk/elasticsearch:/usr/share/elasticsearch \\ -p 9200:9200 \\ -p 9300:9300 \\ elasticsearch:7.16.2 ","date":"2022-03-05","objectID":"/elk%E6%97%A5%E5%BF%97/:2:1","tags":["分布式"],"title":"ELK日志框架集成","uri":"/elk%E6%97%A5%E5%BF%97/"},{"categories":["分布式"],"content":"1.1.2 docker-compose version: '3.7' services: elasticsearch: container_name: es image: elasticsearch:7.16.2 ports: - \"9200:9200\" - \"9300:9300\" volumes: - /opt/elk/es/conf/elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml - /opt/elk/es/data:/usr/share/elasticsearch/data - /opt/elk/es/plugins:/usr/share/elasticsearch/plugins environment: - \"ES_JAVA_OPTS=-Xms512m -Xmx512m\" - \"discovery.type=single-node\" - \"COMPOSE_PROJECT_NAME=es-server\" restart: always ","date":"2022-03-05","objectID":"/elk%E6%97%A5%E5%BF%97/:2:2","tags":["分布式"],"title":"ELK日志框架集成","uri":"/elk%E6%97%A5%E5%BF%97/"},{"categories":["分布式"],"content":"1.2 Elasticsearch-Head安装 ","date":"2022-03-05","objectID":"/elk%E6%97%A5%E5%BF%97/:3:0","tags":["分布式"],"title":"ELK日志框架集成","uri":"/elk%E6%97%A5%E5%BF%97/"},{"categories":["分布式"],"content":"1.2.1 docker docker pull mobz/elasticsearch-head:5-alpine docker run -d \\ --name=elasticsearch-head \\ --restart=always \\ -p 9100:9100 \\ docker.io/mobz/elasticsearch-head:5-alpine ","date":"2022-03-05","objectID":"/elk%E6%97%A5%E5%BF%97/:3:1","tags":["分布式"],"title":"ELK日志框架集成","uri":"/elk%E6%97%A5%E5%BF%97/"},{"categories":["分布式"],"content":"1.2.2 docker-compose version: '3.7' services: elasticsearch-head: image: mobz/elasticsearch-head:5-alpine container_name: elk_es_head restart: always ports: - \"9100:9100\" networks: - elk networks: elk: driver: bridge ","date":"2022-03-05","objectID":"/elk%E6%97%A5%E5%BF%97/:3:2","tags":["分布式"],"title":"ELK日志框架集成","uri":"/elk%E6%97%A5%E5%BF%97/"},{"categories":["分布式"],"content":"1.3配置文件 ","date":"2022-03-05","objectID":"/elk%E6%97%A5%E5%BF%97/:4:0","tags":["分布式"],"title":"ELK日志框架集成","uri":"/elk%E6%97%A5%E5%BF%97/"},{"categories":["分布式"],"content":"elasticsearch.yml ## Default Elasticsearch configuration from elasticsearch-docker. ## from https://github.com/elastic/elasticsearch-docker/blob/master/build/elasticsearch/elasticsearch.yml # cluster.name: \"docker-cluster\" network.host: 0.0.0.0 # minimum_master_nodes need to be explicitly set when bound on a public IP # set to 1 to allow single node clusters # Details: https://github.com/elastic/elasticsearch/pull/17288 discovery.zen.minimum_master_nodes: 1 ## Use single node discovery in order to disable production mode and avoid bootstrap checks ## see https://www.elastic.co/guide/en/elasticsearch/reference/current/bootstrap-checks.html # discovery.type: single-node ## Disable X-Pack ## see https://www.elastic.co/guide/en/x-pack/current/xpack-settings.html ## https://www.elastic.co/guide/en/x-pack/current/installing-xpack.html#xpack-enabling # xpack.security.enabled: false xpack.monitoring.enabled: false xpack.ml.enabled: false xpack.graph.enabled: false xpack.watcher.enabled: false http.cors.enabled : true http.cors.allow-origin : \"*\" http.cors.allow-methods : OPTIONS, HEAD, GET, POST http.cors.allow-headers : X-Requested-With, Content-Type, Content-Length 访问 curl http://127.0.0.1:9200/ 返回 { \"name\" : \"4a8f92502f14\", \"cluster_name\" : \"docker-cluster\", \"cluster_uuid\" : \"cRd8xKAcRyCEa5eO9kuntw\", \"version\" : { \"number\" : \"7.16.2\", \"build_flavor\" : \"default\", \"build_type\" : \"docker\", \"build_hash\" : \"2b937c44140b6559905130a8650c64dbd0879cfb\", \"build_date\" : \"2021-12-18T19:42:46.604893745Z\", \"build_snapshot\" : false, \"lucene_version\" : \"8.10.1\", \"minimum_wire_compatibility_version\" : \"6.8.0\", \"minimum_index_compatibility_version\" : \"6.0.0-beta1\" }, \"tagline\" : \"You Know, for Search\" } 安装成功 ","date":"2022-03-05","objectID":"/elk%E6%97%A5%E5%BF%97/:4:1","tags":["分布式"],"title":"ELK日志框架集成","uri":"/elk%E6%97%A5%E5%BF%97/"},{"categories":["分布式"],"content":"二 Logstash安装 ","date":"2022-03-05","objectID":"/elk%E6%97%A5%E5%BF%97/:5:0","tags":["分布式"],"title":"ELK日志框架集成","uri":"/elk%E6%97%A5%E5%BF%97/"},{"categories":["分布式"],"content":"2.1 docker docker pull logstash:7.16.2 docker run -d \\ --name=elk_logstash \\ -p 5045:5045 \\ --restart=always \\ -v /opt/elk/logstash:/usr/share/logstash \\ -v /www/wwwroot/plmlogs:/www/wwwroot/plmlogs \\ logstash:7.16.2 docker run -d \\ --name=elk_logstash \\ -p 5045:5045 \\ --restart=always \\ -v /opt/elk/logstash:/usr/share/logstash \\ -v /www/wwwroot/plmLogs:/www/wwwroot/plmLogs \\ logstash:7.16.2 ","date":"2022-03-05","objectID":"/elk%E6%97%A5%E5%BF%97/:5:1","tags":["分布式"],"title":"ELK日志框架集成","uri":"/elk%E6%97%A5%E5%BF%97/"},{"categories":["分布式"],"content":"2.2 docker-compos version: '3.7' services: logstash: image: logstash:7.16.2 container_name: elk_logstash restart: always volumes: - /opt/elk/logstash/config/logstash.yml:/usr/share/logstash/config/logstash.yml \\ - /opt/elk/logstash/config/conf.d/:/opt/elk/logstash/config/conf.d/ \\ - /opt/elk/logstash/data:/usr/share/logstash/data \\ - /opt/elk/logstash/pipeline:/usr/share/logstash/pipeline \\ - /opt/elk/logstash/logs:/opt/elk/logstash/logs \\ - /www/wwwroot/plmlogs:/www/wwwroot/plmlogs \\ environment: LS_JAVA_OPTS: \"-Xmx512m -Xms512m\" networks: - elk networks: elk: driver: bridge ","date":"2022-03-05","objectID":"/elk%E6%97%A5%E5%BF%97/:5:2","tags":["分布式"],"title":"ELK日志框架集成","uri":"/elk%E6%97%A5%E5%BF%97/"},{"categories":["分布式"],"content":"2.3 配置文件 主配置文件 http.host: \"0.0.0.0\" xpack.monitoring.elasticsearch.hosts: [ \"http://192.168.23.128:9200\" ] path.config: /opt/elk/logstash/config/conf.d/*.conf path.logs: /opt/elk/logstash/logs 日志conf文件配置（示例） input { file { #标签 type =\u003e \"systemlog-localhost\" #采集点 path =\u003e \"/opt/plmLogs/\" #开始收集点 start_position =\u003e \"beginning\" #扫描间隔时间，默认是1s，建议5s stat_interval =\u003e \"5\" } } output { elasticsearch { hosts =\u003e [\"127.0.0.1:9200\"] index =\u003e \"logstash-system-localhost-%{+YYYY.MM.dd}\" } } ","date":"2022-03-05","objectID":"/elk%E6%97%A5%E5%BF%97/:5:3","tags":["分布式"],"title":"ELK日志框架集成","uri":"/elk%E6%97%A5%E5%BF%97/"},{"categories":["分布式"],"content":"三 kibana安装 ","date":"2022-03-05","objectID":"/elk%E6%97%A5%E5%BF%97/:6:0","tags":["分布式"],"title":"ELK日志框架集成","uri":"/elk%E6%97%A5%E5%BF%97/"},{"categories":["分布式"],"content":"3.1 docker docker pull kibana:7.16.2 docker run -d \\ --name=elk_kibana \\ --privileged=true \\ -p 5601:5601 \\ --restart=always \\ -v /opt/elk/kibana/config/kibana.yml:/usr/share/kibana/config/kibana.yml \\ kibana:7.16.2 ","date":"2022-03-05","objectID":"/elk%E6%97%A5%E5%BF%97/:6:1","tags":["分布式"],"title":"ELK日志框架集成","uri":"/elk%E6%97%A5%E5%BF%97/"},{"categories":["分布式"],"content":"3.2 docker-compose version: '3.7' services: kibana: image: kibana:7.16.2 container_name: elk_kibana restart: always volumes: - /opt/elk/kibana/config/kibana.yml:/usr/share/kibana/config/kibana.yml ports: - \"5601:5601\" networks: - elk networks: elk: driver: bridge ","date":"2022-03-05","objectID":"/elk%E6%97%A5%E5%BF%97/:6:2","tags":["分布式"],"title":"ELK日志框架集成","uri":"/elk%E6%97%A5%E5%BF%97/"},{"categories":["分布式"],"content":"3.3 配置文件 ","date":"2022-03-05","objectID":"/elk%E6%97%A5%E5%BF%97/:6:3","tags":["分布式"],"title":"ELK日志框架集成","uri":"/elk%E6%97%A5%E5%BF%97/"},{"categories":["分布式"],"content":"四 合并docker-compose文件 version: '3.7' services: elasticsearch: image: elasticsearch:7.16.2 container_name: elk_es restart: always ports: - \"9200:9200\" - \"9300:9300\" environment: ES_JAVA_OPTS: \"-Xmx512m -Xms512m\" xpack.security.enabled: \"false\" xpack.monitoring.enabled: \"false\" xpack.graph.enabled: \"false\" xpack.watcher.enabled: \"false\" networks: - elk volumes: - /opt/elk/es/config/elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml - /opt/elk/es/data:/usr/share/elasticsearch/data - /opt/elk/es/plugins:/usr/share/elasticsearch/plugins elasticsearch-head: image: mobz/elasticsearch-head:5-alpine container_name: elk_es_head restart: always ports: - \"9100:9100\" networks: - elk logstash: image: logstash:7.16.2 container_name: elk_logstash restart: always volumes: - /opt/elk/logstash/config/logstash.yml:/usr/share/logstash/config/logstash.yml \\ - /opt/elk/logstash/config/conf.d/:/opt/elk/logstash/config/conf.d/ \\ - /opt/elk/logstash/data:/usr/share/logstash/data \\ - /opt/elk/logstash/pipeline:/usr/share/logstash/pipeline \\ - /opt/elk/logstash/logs:/opt/elk/logstash/logs \\ - /www/wwwroot/plmlogs:/www/wwwroot/plmlogs \\ environment: LS_JAVA_OPTS: \"-Xmx512m -Xms512m\" networks: - elk depends_on: - elasticsearch kibana: image: kibana:7.16.2 container_name: elk_kibana restart: always volumes: - /opt/elk/kibana/config/kibana.yml:/usr/share/kibana/config/kibana.yml ports: - \"5601:5601\" networks: - elk depends_on: - elasticsearch networks: elk: driver: bridge ","date":"2022-03-05","objectID":"/elk%E6%97%A5%E5%BF%97/:7:0","tags":["分布式"],"title":"ELK日志框架集成","uri":"/elk%E6%97%A5%E5%BF%97/"},{"categories":["分布式"],"content":"五 安装时异常处理记录 # 启动报错1 bootstrap checks failed. You must address the points described in the following [1] lines before starting Elasticsearch. areas vm.max_map_count [65530] is too low, increase to at least [262144] 解决方案 https://blog.csdn.net/weixin_44186547/article/details/111474430 启动用户内存设置问题 sysctl -w vm.max_map_count=262144 sysctl -a|grep vm.max_map_count #启动报错2 {\"@timestamp\":\"2022-02-24T06:13:29.287Z\", \"log.level\": \"WARN\", \"message\":\"received plaintext http traffic on an https channel, closing connection Netty4HttpChannel{localAddress=/172.21.0.2:9200, remoteAddress=/192.168.23.1:52180}\", \"ecs.version\": \"1.2.0\",\"service.name\":\"ES_ECS\",\"event.dataset\":\"elasticsearch.server\",\"process.thread.name\":\"elasticsearch[6c35a2a32c9e][transport_worker][T#7]\",\"log.logger\":\"org.elasticsearch.xpack.security.transport.netty4.SecurityNetty4HttpServerTransport\",\"elasticsearch.cluster.uuid\":\"VUG2U5RzQBisYw2XewbopA\",\"elasticsearch.node.id\":\"Z-IvopcWQfGf-05cDPdlLA\",\"elasticsearch.node.name\":\"6c35a2a32c9e\",\"elasticsearch.cluster.name\":\"docker-cluster\"} # kibana启动异常报错 FATAL Error: TaskManager is unable to start as Kibana has no valid UUID assigned to it. Unable to write to UUID file at /usr/share/kibana/data/uuid. Ensure Kibana has sufficient permissions to read / write to this file. Error was: ENOSPC 解决方案 权限不足，修改映射宿主机目录权限为 777 # 启动找不到es地址 Unable to retrieve version information from Elasticsearch nodes. 解决方案 配置elasticsearch.yml和kibana.yml，修改es的ip为docker0 的ip，不是宿主机ip # 无法启动 server is not ready yet 解决方案 映射配置文件位置异常，重新核对解决。 # logstash 启动报错 /usr/local/bin/docker-entrypoint: line 12: exec: logstash: not found 解决方案 权限不足，修改映射宿主机目录权限为 777 ","date":"2022-03-05","objectID":"/elk%E6%97%A5%E5%BF%97/:8:0","tags":["分布式"],"title":"ELK日志框架集成","uri":"/elk%E6%97%A5%E5%BF%97/"},{"categories":["读书笔记"],"content":"【原文摘录】 1 ","date":"2022-01-12","objectID":"/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0--%E4%BA%BA%E6%9C%88%E7%A5%9E%E8%AF%9D--1/:0:0","tags":["读书笔记"],"title":"读书笔记--《人月神话》-- 1","uri":"/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0--%E4%BA%BA%E6%9C%88%E7%A5%9E%E8%AF%9D--1/"},{"categories":["读书笔记"],"content":"焦油坑 过去几十年的大型系统开发就犹如一个焦油坑，很多大型动物在其中剧烈挣扎，他们中大多数开发出了可运行的系统–不过，其中只有非常少数的项目满足了目标、时间进度和预算的要求。 各种团队，大型的和小型的，庞杂的和精干的，一个接一个淹没在了焦油坑中。表面上看起来好像没有任何一个单独的问题会导致困难，每个都能被解决，但是当它们相互纠缠和累积在一起的时候，团队的行动就会变得越来越慢且很难看清问题的本质。 2 ","date":"2022-01-12","objectID":"/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0--%E4%BA%BA%E6%9C%88%E7%A5%9E%E8%AF%9D--1/:1:0","tags":["读书笔记"],"title":"读书笔记--《人月神话》-- 1","uri":"/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0--%E4%BA%BA%E6%9C%88%E7%A5%9E%E8%AF%9D--1/"},{"categories":["读书笔记"],"content":"人月神话 缺乏合理的时间进度是造成项目滞后的最主要原因，它比其他所有因素加起来影响还大。 我们围绕成本核算的估计技术，混淆了工作量和项目进展。人月是危险和带有欺骗性的神话，因为它暗示人员数量和时间是可以相互替换的。 向软件项目中增派人手从三个方面增加了项目必要的总体工作量： 任务重新分配本身和所造成的工作中断； 培训新人员； 额外的相互沟通。 关于进度安排，我的经验是为1/3计划、1/6编码、1/4构件测试以及1/4系统测试。 Brook法则：向进度落后的项目中增加人手，只会使进度更加落后。 特别需要指出的是，不为系统测试安排足够的时间简直就是一场灾难。 在现实情况中，一旦开发团队观察到进度的偏差，总是倾向于对任务进行削减。当项目延期所导致的后续成本非常高时，这常常是唯一可行的方法。 3 ","date":"2022-01-12","objectID":"/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0--%E4%BA%BA%E6%9C%88%E7%A5%9E%E8%AF%9D--1/:2:0","tags":["读书笔记"],"title":"读书笔记--《人月神话》-- 1","uri":"/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0--%E4%BA%BA%E6%9C%88%E7%A5%9E%E8%AF%9D--1/"},{"categories":["读书笔记"],"content":"外科手术队伍 小型、精干队伍是最好的–尽可能的少。 需要协作沟通的人员的数量影响着开发成本，因为成本的主要组成部分是相互的沟通和交流，以及更正沟通不当所引起的不良结果（系统调试）。 Mills建议大型项目的每一个部分由一个团队解决，但是该队伍以类似外科手术的方式组建，而并非一拥而上。 一位首席程序员、类似于外科手术队伍的团队架构提供了一种方法–既能获得由少数头脑产生的产品完整性，又能得到多位协助人员的总体生产率，还彻底地减少了沟通的工作量。 4 ","date":"2022-01-12","objectID":"/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0--%E4%BA%BA%E6%9C%88%E7%A5%9E%E8%AF%9D--1/:3:0","tags":["读书笔记"],"title":"读书笔记--《人月神话》-- 1","uri":"/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0--%E4%BA%BA%E6%9C%88%E7%A5%9E%E8%AF%9D--1/"},{"categories":["读书笔记"],"content":"贵族专制、民主政治和系统设计 为了反映一系列连贯的设计思路，宁可省略一些不规则的特性和改进，也不提倡独立和无法整合的系统，哪怕它们其实包含着许多很好的设计。 同工作的水平分割相比，垂直划分从根本上大大减少了劳动量，结果是使交流彻底地简化，概念完整性得到大幅提高。 5 ","date":"2022-01-12","objectID":"/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0--%E4%BA%BA%E6%9C%88%E7%A5%9E%E8%AF%9D--1/:4:0","tags":["读书笔记"],"title":"读书笔记--《人月神话》-- 1","uri":"/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0--%E4%BA%BA%E6%9C%88%E7%A5%9E%E8%AF%9D--1/"},{"categories":["读书笔记"],"content":"蛇添足 一种普遍倾向是过分地设计第二个系统，向系统添加很多修饰功能和想法，它们曾在第一个系统中被小心谨慎地推迟了。 实际情况中，尽早交流和持续沟通能使结构师有较好的成本意识，以及使开发人员获得对设计的信心，并且不会混淆各自的责任分工。 面对估算过高的难题，结构师有两个选择：削减设计或者建议成本更低的实现方法–挑战估算的结果 6 ","date":"2022-01-12","objectID":"/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0--%E4%BA%BA%E6%9C%88%E7%A5%9E%E8%AF%9D--1/:5:0","tags":["读书笔记"],"title":"读书笔记--《人月神话》-- 1","uri":"/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0--%E4%BA%BA%E6%9C%88%E7%A5%9E%E8%AF%9D--1/"},{"categories":["读书笔记"],"content":"贯彻执行 即使是大型的设计团队，设计结果也必须由一个或两个人来完成，以确保这些决定是一致的。 允许体系结构师对实现人员的询问做出电话应答解释是非常重要的，并且必须进行日志记录和整理发布。 对于存有疑问的实现人员，应鼓励他们打电话询问相应的结构师，而不是一边自行猜测一边工作，这是一项很基本的措施。 7 ","date":"2022-01-12","objectID":"/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0--%E4%BA%BA%E6%9C%88%E7%A5%9E%E8%AF%9D--1/:6:0","tags":["读书笔记"],"title":"读书笔记--《人月神话》-- 1","uri":"/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0--%E4%BA%BA%E6%9C%88%E7%A5%9E%E8%AF%9D--1/"},{"categories":["读书笔记"],"content":"为什么巴比伦塔会失败？ 巴比伦塔项目的失败是因为缺乏交流，以及交流的结果–组织。 “因为左手不知道右手在做什么，从而进度灾难、功能的不合理和系统缺陷纷纷出现。 随着工作的进行，许多小组慢慢地修改自己程序的功能、规模和速度，他们明确或者隐含地更改了一些有效输入和输出结果用法上的约定，而因此给其他部分引发了BUG。 解决方案： 团队应该以尽可能多的方式进行相互之间的交流：非正式、常规项目会议，会上进行简要的技术陈述、共享的正式项目工作手册。举行常规项目会议，会议中，团队一个接一个地进行简要的技术陈述。这种方式非常有用，能澄清成百上千的细小误解。 制定项目工作手册，并实时记录变更：首先，必须在页面上标记发生改变的文本，例如，使用页边上的竖线标记每行变化的文字。第二，分发的变更页附带独立的总结性文字，对变更的重要性以及批注进行记录。 8 ","date":"2022-01-12","objectID":"/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0--%E4%BA%BA%E6%9C%88%E7%A5%9E%E8%AF%9D--1/:7:0","tags":["读书笔记"],"title":"读书笔记--《人月神话》-- 1","uri":"/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0--%E4%BA%BA%E6%9C%88%E7%A5%9E%E8%AF%9D--1/"},{"categories":["读书笔记"],"content":"胸有成竹 编码大约只占了问题的六分之一左右，编码估计或者比率的错误可能会导致不合理的荒谬结果。 对常用编程语句而言。生产率似乎是固定的。这个固定的生产率包括了编程中需要注释，并可能存在错误的情况. 使用适当的高级语言，编程的生产率可以提高5倍。 9 ","date":"2022-01-12","objectID":"/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0--%E4%BA%BA%E6%9C%88%E7%A5%9E%E8%AF%9D--1/:8:0","tags":["读书笔记"],"title":"读书笔记--《人月神话》-- 1","uri":"/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0--%E4%BA%BA%E6%9C%88%E7%A5%9E%E8%AF%9D--1/"},{"categories":["读书笔记"],"content":"削足适履 在大型的团队中，各个小组倾向于不断地局部优化，以满足自己的目标，而较少考虑队用户的整体影响。这种方向性的问题是大型项目的主要危险。 为了满足目标，每个人都在局部优化自己的程序，很少会有人停下来，考虑一下对客户的整体影响。 培养开发人员从系统整体出发、面向用户的态度是软件编程管理人员最重要的职能。 10 ","date":"2022-01-12","objectID":"/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0--%E4%BA%BA%E6%9C%88%E7%A5%9E%E8%AF%9D--1/:9:0","tags":["读书笔记"],"title":"读书笔记--《人月神话》-- 1","uri":"/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0--%E4%BA%BA%E6%9C%88%E7%A5%9E%E8%AF%9D--1/"},{"categories":["读书笔记"],"content":"提纲挈领 如果要制造一台机器，哪些是关键的文档呢？ 目标：定义待满足的目标和需要，定义迫切需要的资源、约束和优先级。 首先，书面记录决策是必要的。只有记录下来，分歧才会明朗，矛盾才会突出。项目经理常常会不断发现，许多理应被普遍认同的策略，完全不为团队的一些成员所知。每个文档本身就可以作为检查列表或者数据库。 项目经理的基本职责是使每个人都向着相同的方向前进。项目经理的主要日常工作是沟通，而不是做出决定；文档使各项计划和决策在整个团队范围内得到交流。 通过周期性的回顾，他能清楚项目所处的状态，以及哪些需要重点进行更改和调整。 11 ","date":"2022-01-12","objectID":"/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0--%E4%BA%BA%E6%9C%88%E7%A5%9E%E8%AF%9D--1/:10:0","tags":["读书笔记"],"title":"读书笔记--《人月神话》-- 1","uri":"/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0--%E4%BA%BA%E6%9C%88%E7%A5%9E%E8%AF%9D--1/"},{"categories":["读书笔记"],"content":"未雨绸缪 变更的客观需要 对于大多数项目，第一个开发的系统并不合用。它可能太慢、太大，而且难以使用，或者三者兼而有之。 用户的实际需要和用户感觉会随着程序的构建、测试和使用而变化。 软件产品易于掌握的特性和不可见性，导致了它的构建人员（特别容易）面临着永恒的需求变更。 目标上（和开发策略上）的一些正常变化无可避免，事先为它们做准备总比假设它们不会出现要好得多。 为变更计划组织结构 当系统发生变化时，管理结构也需要进行调整。只要管理人员和技术人才的天赋允许，老板必须对他们的能力培养给予极大的关注，使管理人员和技术人才具有互换性。 为什么缺陷不能更彻底地被修复？ 首先，看上去很轻微的错误，似乎仅仅是局部操作上的失败，实际上却是系统级别的问题，通常这不是很明显。 设计实现的人员越少、接口越少，产生的错误也就越少。 所有修改都倾向于破坏系统的架构，增加了系统的混乱程度。用在修复原有设计上瑕疵的工作量越来越少，而早期维护活动本身的漏洞所引起修复工作越来越多。 随着时间的推移，系统变得越来越无序，修复工作迟早会失去根基 ，尽管理论上系统一直可用，但实际上，整个系统已经面目全非，无法再成为下一步进展的基础。 机器在变化，配置在变化，用户的需求在变化，所以现实系统不可能永远可用。崭新的、对于原有系统的重新设计是完全必要的。 12 ","date":"2022-01-12","objectID":"/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0--%E4%BA%BA%E6%9C%88%E7%A5%9E%E8%AF%9D--1/:11:0","tags":["读书笔记"],"title":"读书笔记--《人月神话》-- 1","uri":"/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0--%E4%BA%BA%E6%9C%88%E7%A5%9E%E8%AF%9D--1/"},{"categories":["读书笔记"],"content":"干将莫邪 每个编程人员也保留着编辑器、排序、内存信息转储、磁盘实用程序等工具。 这种方法对软件项目来说是愚蠢的。首先，项目的关键问题是沟通，个性化的工具妨碍–而不是促进沟通。 交互式编程 MIT的Multics项目的成果之一，是它对软件编程系统开发的贡献。在那些系统编程所关注的方面，Multics（以及后续系统，IBM的TSS）和其他交互式计算机系统在概念上有很大的不同：多个级别上数据和程序的共享和保护，可延伸的库管理，以及协助终端用户共同开发的设施。我确信在某些应用上，批处理系统决不会被交互式系统所取代。 13 ","date":"2022-01-12","objectID":"/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0--%E4%BA%BA%E6%9C%88%E7%A5%9E%E8%AF%9D--1/:12:0","tags":["读书笔记"],"title":"读书笔记--《人月神话》-- 1","uri":"/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0--%E4%BA%BA%E6%9C%88%E7%A5%9E%E8%AF%9D--1/"},{"categories":["读书笔记"],"content":"整体部分 许许多多的失败完全源于那些产品未精确定义的地方。 “细致的功能定义、详细的规格说明、规范化的功能描述说明以及这些方法的实施，大大减少了系统中必须查找的bug数量。 注: 需求文档越详细，bug越少 在编写任何代码之前，规格说明必须提交给测试小组，以详细地检查说明的完整性和明确性 注: 需求文档给测试过一遍 他将程序开发划分成体系结构设计、设计实现和物理编码实现，每个步骤可以使用自顶向下的方法很好地实现。 好的自顶向下设计从几个方面避免了bug。 首先，清晰的结构和表达方式更容易对需求和模块功能进行精确的描述。 其次，模块分割和模块独立性避免了系统级的bug。 另外，细节的隐藏使结构上的缺陷更加容易识别。 最后，设计在每个精化步骤的层次上是可以测试的，所以测试可以尽早开始，并且每个步骤的重点可以放在合适的级别上。 一些糟糕的系统往往就是试图挽救一个基础很差的设计，而对它添加了很多表面装饰般的补丁。自顶向下的方法减少了这样的企图。 14 ","date":"2022-01-12","objectID":"/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0--%E4%BA%BA%E6%9C%88%E7%A5%9E%E8%AF%9D--1/:13:0","tags":["读书笔记"],"title":"读书笔记--《人月神话》-- 1","uri":"/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0--%E4%BA%BA%E6%9C%88%E7%A5%9E%E8%AF%9D--1/"},{"categories":["读书笔记"],"content":"祸起萧墙 当人们听到某个项目的进度发生了灾难性偏离时，可能会认为项目一定是遭受了一系列重大灾难。然而，通常灾祸来自白蚁的肆虐，而不是龙卷风的侵袭。 里程碑 里程碑的选择只有一个原则，那就是，里程碑必须是具体的、特定的、可度量的事件，能够进行清晰定义。 例如：“结构师和实现人员签字认可的规格说明”，“1%源代码编制完成，纸带打孔完成并输入到磁盘库”，“测试通过了所有的测试用例”。 如果里程碑很模糊，老板就常常会得到一份与实际情况不符的报告。 慢性进度偏离是士气杀手。[Microsoft的Jim McCarthy说：“如果你错过了一个最终期限（deadline），确保制订下一条deadline 如果在某项活动开始之前就着手估计，并且每两周进行一次仔细的修订，根据实际情况动态调整时间。当里程碑没有正确反映损失的时间，并对人们形成误导，以致事态无法挽回的时候，它会彻底碾碎小组的士气。 保持进度透明可见 一线经理的利益和老板的利益是内在冲突的。一线经理担心如果汇报了问题，老板会采取行动,这些行动会取代经理的作用，降低自己的威信，搞乱了其他计划。所以，只要项目经理认为自己可以独立解决问题，他就不会告诉老板。 有两种掀开毯子把污垢展现在老板面前的方法，它们必须都被采用。 一种是减少角色冲突和鼓励状态共享 减少角色的冲突。老板必须规范自己，不对项目经理可以解决的问题做出反应。当项目经理了解到老板收到项目报告之后不会惊慌，或者不会越俎代庖时，他就逐渐会提交真实的评估结果。 另一种是猛地拉开地毯。 猛地拉开地毯。不论协作与否，拥有能了解状态真相的评审机制是必要的。PERT图以及频繁的里程碑是这种评审的基础。大型项目中，可能需要每周对某些部分进行评审，大约一个月左右进行整体评审。 没有银弹软件工程中的根本和次要问题 没有任何技术或管理上的进展，能够独立地许诺十年内使生产率、可靠性或简洁性获得数量级上的进步。因为软件有无法规避的特性：复杂度、一致性、可变性、不可见性。 产品复杂度： 由于复杂度，团队成员之间的沟通非常困难，导致了产品瑕疵、成本超支和进度延迟； 由于复杂度，列举和理解所有可能的状态十分困难，影响了产品的可靠性； 由于函数的复杂度，函数调用变得困难，导致程序难以使用； 由于结构性复杂度，程序难以在不产生副作用的情况下用新函数扩充；由于结构性复杂度，造成很多安全机制状态上的不可见性。 复杂度不仅仅导致技术上的困难，还引发了很多管理上的问题。它使全面理解问题变得困难，从而妨碍了概念上的完整性；它使所有离散出口难以寻找和控制；它引起了大量学习和理解上的负担，使开发慢慢演变成了一场灾难。 软件可变性： 软件实体经常会遭受到持续的变更压力 现实工作中，经常发生两种情况。 当人们发现软件很有用时，会在原有应用范围的边界，或者在超越边界的情况下使用软件。功能扩展的压力主要来自那些喜欢基本功能，又对软件提出了很多新用法的用户们。 其次，软件一定是在某种计算机硬件平台上开发，成功软件的生命期通常比当初的计算机硬件平台要长。即使不是更换计算机，则有可能是换新型号的磁盘、显示器或者打印机。软件必须与各种新生事物保持一致。 软件不可见性 软件是不可见的和无法可视化的。 其中的秘密就是逐步发育成长，而不是一次性搭建。 软件开发是一件棘手的事情，并不会有魔术般的解决方案，现在是从业者研究和分析革命性进展的时刻，而不是等待或希望它的出现。 现在有可能可以在软件生产率上取得逐步的进展，而不是等待不可能到来的大突破。 ","date":"2022-01-12","objectID":"/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0--%E4%BA%BA%E6%9C%88%E7%A5%9E%E8%AF%9D--1/:14:0","tags":["读书笔记"],"title":"读书笔记--《人月神话》-- 1","uri":"/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0--%E4%BA%BA%E6%9C%88%E7%A5%9E%E8%AF%9D--1/"},{"categories":["读书笔记"],"content":"【内容来源于网络和书中内容摘录】 《人月神话》（The Mythical Man-Month）是由Frederick P. Brooks 撰写的一本软件工程学经典巨著。 Brooks博士在1956年获得哈佛大学应用数学博士学位，同年加入IBM公司。他领导了IBM System/360及其操作系统OS/360的研发，被誉为“IBM 360系统之父”。1964年他离开IBM，创建了北卡罗来纳大学计算机科学系，担任系主任长达20年。1975年，Brooks博士总结了他多年在IBM管理OS/360研发期间的经验，以一个个小故事的方式描述了软件工程中存在的现象，探讨软件工程的管理问题，这就是著名的《人月神话》。 一 无法逃脱的宿命 计算机领域经过几十年的飞速发展，软硬件都比作者所处的年代有了极大提升。尤其是硬件资源实现了跨数量级的提升，诞生了著名的“摩尔定律”。PC的普及以及服务器性能的提升，使得计算和存储资源在普通应用程序中越来越宽裕。与此同时，软件的发展伴随着网络性能的飞速发展，编程领域由单机程序迅速向网络分布式系统转换。原书中提到的“高级语言、面向对象、可复用的构件”已经成为默认的事实。除了少量专业领域，绝大部分应用级别的编程系统已经基本脱离了“汇编、指令集”等作者年代的编程技术，都在基于新的行业规则进行开发。甚至原书中提到的新事物：“塑料薄膜包装的成品软件”都已经过时，变成通过网络随时下载更新、持续进化的软件。 即便计算机领域飞速发展了几十年，我们拥有更快的硬件、更快的网络、更多的计算、存储资源、更优秀的重用库、更完善的框架、更方便的语言、更先进的思想等等之前无法想象的海量的资源，让我们感觉软件工程领域的种种问题似乎也应该迎刃而解了，不复存在了，或者最起码也应该是由新的问题来困扰我们了。然而，事实却是： l 我们依旧无法准确的评估工作量 l 我们依旧难以进行合理的进度安排 l 项目落后时，只能被动的延长工作时间或者增加人力 l 大量的BUG反复出现 l 开发的软件不能使用户满意，甚至用户仅仅使用软件的极少量功能 l 大量的软件项目以失败告终 这些《人月神话》中描述的现象，经历了几十年仍然存在，并且大量存在。这是软件工程这几十年没有发展吗？还是软件工程的根本问题还是没有得到较好的解决呢？ 阅读《人月神话》后我有两点最大的收获： 不用妄自菲薄，这些软件项目的问题是普遍存在的，不要对自己的能力产生怀疑； 众多前辈已经总结了大量软件项目的问题和解决方案，并且经历了时间的考验。我们应该坚定的学习掌握，同时在实际工作中运用、改善，从而形成行业规则，达成行业共识。这样才能推动软件行业不断发展。 二 可怕的场景 《人月神话》开篇描述了一副可怕的场景：“上帝见证着恐龙、猛犸象、剑齿虎在焦油中挣扎。他们挣扎得越猛烈，焦游纠缠得就越紧，没有哪种猛兽足够强壮或具有足够的技巧，能够挣脱束缚，它们最后都沉到了坑底”。 联想到我参与过的软件项目，这样的描述简直是身临其性、感同身受。很多时候，不管项目团队如何挣扎，还是眼睁睁地看着项目一点一点的拖延至失败，大家却毫无办法。 软件工程存在的意义是尽量避免软件项目陷入这个危险，而不是已经陷入危险之后的解决方法。我甚至怀疑书中描述这个场景的潜台词是：“如果已经陷入焦油坑，不管你有多大的本领，最终都会死在里面”。 三 软件的特性 软件系统有很多特性，这些特性是这个领域与生俱来的，是不会改变也不会消失的。 软件的复杂性： 首先，从代码层面来讲，没有任何两个部分是相同的。因为相同的代码应该形成公用的独立构件供多个地方引用。如果相同的代码出现在多个地方，并不采用组件重用的方式，带来的后果会更严重。 其次，计算机和软件程序存在很多状态。这些状态是动态的，是时刻会发生变化的，所以我们无法用一种静态的方式去描述软件系统。即使软件工程采用各种图：用例图、类图、流程图、时序图、物理模型图、网络部署图等等通过不同的维度去描述同一个软件系统，也不能描述完全软件系统的全部信息。 最后，软件系统在不断扩展。我们可以简单的划分为功能的扩展和数据量的扩展。这两个方向的扩展都不是简单的叠加，都会导致复杂度非线性的增长。二者同时扩展，复杂度会以指数级上升。 软件的一致性： 软件的一致性又可以称为兼容性。我将它分成时间上的兼容性和空间上的兼容性。在软件发布一个版本之后，如果软件能够取得成功，随之而来的就是不停的发布新版本。这时候，向前兼容性就是一个非常强制且重要的原则，为了确保软件的平滑升级，为了确保用户操作的习惯性，这些都需要软件尽量保持向前兼容性；另一方面，从软件设计的角度来讲，为了方便软件扩展，出现的各种软件设计模式，其实也是为了实现软件的向后兼容性。这两方面都属于时间上的兼容性。 空间上的兼容性体现在一款软件需要尽量在各种运行环境下：不同的硬件规格、不同的运行环境、不同的操作系统、不同的终端、不同的浏览器等等，保持相同的效果。 软件的可变性： 软件编程过程很大程度上纯粹是思维活动的过程，这种本质导致软件的变化看起来很容易（但是软件变化的成本并不低），于是，各种各样的原因都会导致软件经常会发生变化。虽然这一句话很简短，但是软件的可变性几乎是一切软件工程问题的根源。 软件的不可见性： 软件是抽象的，软件的定义很难以直观、可视化的形式体现出来，软件的运行过程也很难以可视化的形式体现出来，只有软件运行的结果是可视化的。 四 复杂与简单 编程就是建设软件系统的过程，由于软件系统存在的这些种种特性，也决定了编程过程是非常复杂的。 在《人月神话》中，作者将编程活动的根本任务定义为“打造构成抽象软件实体的复杂概念结构”；次要问题为“用编程语言表达这些抽象实体”。这两句话读起来很拗口，我们可以仔细的理解一下： 除了游戏等极少量行业软件之外，每个软件程序在现实世界中还是存在可以对应上的实体物体的。比如说：各种文件、各种人、实物信息、时间、位置、各种传感器、机械装置等等。软件程序在某种程度上可以简单的认为是一部分现实世界的虚拟化映射，我们使用软件程序是为了节约实物资源，提高信息转移效率。现实中的各种行为规则也会体现到软件程序中的代码逻辑。 若想要在纯粹虚拟的环境中模拟现实世界的事物是根本不可能的事情。任何一个软件系统实际上是在很多的约束和限制条件下，模拟一小部分现实事物和规则。这就需要软件人员充分去了解现实物体的每一项特性，然后形成一个虚拟软件概念；还需要梳理多个现实物体之间的影响规则，然后形成虚拟软件中的关系；最后还要将能够预料到的、无法模拟的事物形成约束条件。软件中包含了很多概念，这些概念以及概念之间的关系、规则和约束形成了“复杂概念结构”，而软件是虚拟的、抽象的，是由这些复杂概念结构组成的。在原书描述的软件活动的根本任务就是凭空去设计、实现这些概念结构，能够满足模拟现实事物和规律的目的，而这整个过程是抽象的、不可见的。在原书中还多次提到“概念结构的完整性和一致性”，这也是软件系统是否能够成功的非常重要的因素。我觉得，UML过程也是为了完成这个软件的根本任务而出现的。 相对来说，编程活动的次要问题就简单一些。软件领域的发展，高级语言的出现，各种更方便的IDE，都能够在很大程度上帮助开发人员去实现程序。 简单的来说，思考是根本问题，动手是次要问题。 五 乐趣和苦恼 程序开发是将一个人对事情的认知进行具化的过程，通过写代码的手段将程序员对事情的理解表现出来，这是一种从零创造世界的过程，这种创造事物的快乐是大多数职业很难体会到的。在这个过程中，开发人员就像造物主，又像是搭建乐高积木一样，最后整体目标搭建完成之后，这种组装成功的快乐也是非常巨大的，同时，这个完成的结果还能对其他人有用，开发人员的个人价值得到认可，而且，组装的零部件不尽相同，组装规则也需要经常学习摸索，组装的目标也是崭新的。这些都是编程行业所独有的乐趣。 在学生时代，这些乐趣和特性吸引着我们学习编程，体验编程，享受编程，选择编程作为我们的职业。然后，苦恼出现了。 计算机是非常死板的，它只会忠实的执行开发人员编写的语句，但凡语句中有任何一点点错误，计算机都不能理解，它不会自动修改，只会直接报错。这就要求开发人员要追求完美，考虑各种影响因素才尽可能的让程序不出错，这个过程是非常痛苦的。在编程的乐趣中提到的创造世界的过程，在实际工作中，这个世界目标是由他人制定的，程序员本身基本没有话语权，更多的时候，制定目标的人还不被程序员认可，这就不是享受创造的快乐了，而变成了应付别人的目标。而且这还是一种较好的情况，更多的情况不是创造，而是日复一日的枯燥重复或者解决繁琐的BUG。 乐趣与困恼共存，当然这是任何行业和领域都有的共性，作为软件工程管理人员，如何提供一个乐趣大于苦恼的环境，提升程序员的职业幸福感和成就感，提升程序员的积极主动性，也是很值得思考的一个方向。 六 人与月 40人/月 = 4个人工作10个月=10个人工作4个月？？？ 但凡有点常识的人都知道这个等式是不成立的，但是在实际工作中，每个人在估算计划与申请资源的时候，都会或多或少受到这里的影响。 在软件项目前期，管理人员需要对项目的工作量进行预估，然后根据已有的资源（人、资金、设备等）进行安排或者申请扩充，最终形成一份项目进度安排计划。 在原书中提到：“缺乏合理的进度安排是造成项目滞后的最主要原因”，在我的经验中，一份合理的进度安排是很难的、或者就是不可能的。具体的原因作者也做出了总结： 【 “在事先，我们都会乐观的认为“一切都将运作良好”，然而在事中，这就是不可能的，肯定会有各种意外情况发生，然后导致项目的各个部分都可能发生问题。” ”在估算进度安排的时候，很多时候，项目经理其实","date":"2022-01-12","objectID":"/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0--%E4%BA%BA%E6%9C%88%E7%A5%9E%E8%AF%9D--2/:0:0","tags":["读书笔记"],"title":"读书笔记--《人月神话》-- 2","uri":"/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0--%E4%BA%BA%E6%9C%88%E7%A5%9E%E8%AF%9D--2/"},{"categories":["读书笔记"],"content":"《浪潮之巅》","date":"2021-12-11","objectID":"/%E4%B8%87%E5%8E%86%E5%8D%81%E4%BA%94%E5%B9%B4/","tags":["读书笔记"],"title":"读书笔记--《万历十五年》","uri":"/%E4%B8%87%E5%8E%86%E5%8D%81%E4%BA%94%E5%B9%B4/"},{"categories":["读书笔记"],"content":"人生而自由，却无往不在枷锁之中 一个人真正的成功，是以自己想要的方式去度过一生 以下引自豆瓣 当一个人口众多的国家，各人行动全凭儒家简单粗浅而又无法固定的原则所限制，而法律又缺乏创造性，则其社会发展的程度，必然受到限制 道德代替不了法律和技术，个人的贤愚得失改变不了大历史的走向。明朝这个摇摇欲坠的戏台上一些人努力着把戏唱下去，张居正、戚继光走乾道，以个人力量建立的体系在政军两处弥补大体制的积弊；申时行走坤道，在已成的矛盾中调和博弈；海瑞走人道，把自身活成道德律法的矛盾体本身；谁也没能得到完满的谢幕，挽救不了这继续垮塌的戏台。万历皇帝从明君理想的破灭到个人欲求的失落，褪色成为庙堂里的一个牌位，李贽哲学精神上的叛逆、矛盾、走投无路，都是这个大国困境形而上的演绎。 因个人意愿和作为制度产物的身份相冲突而选择消极怠工的皇帝，胆大如天手腕强硬却死后被清算的前首辅和处事温和以和为贵的现首辅，清正廉洁但与现实脱节的官吏，军事才能出众却敌不过重文轻武现状的总兵，自封异端自相矛盾的大哲学家，是这历史失败总记录年鉴的主角们，技术不能展开，财政乱作一团，军备只按最低标准，以道德支撑半瘫痪的法律系统，大明帝国的覆灭实为必然。然而跳出1587来看，似乎年年都可称得上大失败。 自由之说，于人而言确为奢谈；命运之枷，帝王 能臣 名将 宿儒皆是囚徒。 当虚伪的道德完全凌驾于法律之上，当体制的惰性阻止了一切可能的变革，每个人都成为了镶嵌在体制之中的一个个螺丝钉，无力动弹，无论你是皇帝、大臣还是平民，这一点放之如今看起来仍精准异常。 ","date":"2021-12-11","objectID":"/%E4%B8%87%E5%8E%86%E5%8D%81%E4%BA%94%E5%B9%B4/:0:0","tags":["读书笔记"],"title":"读书笔记--《万历十五年》","uri":"/%E4%B8%87%E5%8E%86%E5%8D%81%E4%BA%94%E5%B9%B4/"},{"categories":["运维"],"content":"一 Ubuntu1804-Dokcer Author: JDZT.lln CreateDate: 2020-12-09 UpdateDate: 2021-10-17 说明:Ubuntu版本:18.04.5 LTS ","date":"2021-11-29","objectID":"/docker-%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/:0:0","tags":["运维"],"title":"Dokcer研发环境搭建记录","uri":"/docker-%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"},{"categories":["运维"],"content":"1.1 安装及配置 ","date":"2021-11-29","objectID":"/docker-%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/:1:0","tags":["运维"],"title":"Dokcer研发环境搭建记录","uri":"/docker-%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"},{"categories":["运维"],"content":"1.1.1 安装docker和docker-compose #安装docker sudo curl -fsSL https://get.docker.com | bash -s docker --mirror Aliyun #安装docker-compose sudo curl -L https://get.daocloud.io/docker/compose/releases/download/1.22.0/docker-compose- `uname -s`-`uname -m` -o /usr/local/bin/docker-compose sudo curl -L https://github.com/docker/compose/releases/download/v2.18.1/docker-compose-linux-x86_64-$(uname -s)-$(uname -m) -o ./docker-compose-linux-x86_64 #授权docker-compose sudo chmod +x /usr/local/bin/docker-compose ","date":"2021-11-29","objectID":"/docker-%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/:1:1","tags":["运维"],"title":"Dokcer研发环境搭建记录","uri":"/docker-%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"},{"categories":["运维"],"content":"1.1.2：配置docker镜像加速 编辑docker配置文件，若没有该文件则新建 参考文档 https://help.aliyun.com/document_detail/60750.html?spm=a2c4g.11186623.6.545.OY7haW 新建文件 cd /etc/docker touch daemon.json 编辑文件 vim /etc/docker/daemon.json 加入配置信息，不同的云端(阿里|腾讯)配置不同的镜像，可配置多个镜像 { \"registry-mirrors\": [\"https://docker.mirrors.ustc.edu.cn\",\"https://mirror.ccs.tencentyun.com\"] } { \"log-driver\":\"json-file\", \"log-opts\": {\"max-size\":\"500m\", \"max-file\":\"3\"} } 使配置生效 systemctl daemon-reload systemctl restart docker ","date":"2021-11-29","objectID":"/docker-%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/:1:2","tags":["运维"],"title":"Dokcer研发环境搭建记录","uri":"/docker-%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"},{"categories":["运维"],"content":"1.1.3：打包项目并在Docker中运行 流程：打包项目jar包，编写Dockerfile文件，放入到同一个文件夹中，使用docker命令打包，运行，就可以外部访问 Dockerfile 编写说明 # 基础镜像使用java FROM java:8 # 作者 MAINTAINER jd-lln # 定义卷 VOLUME /tmp # 将jar包添加到容器中并更名为test1.jar ADD easysite-exploration.jar easysite-exploration.jar # 指定容器内要暴露的端口 EXPOSE 8013 RUN echo \"Asia/Shanghai\" \u003e /etc/timezone ENTRYPOINT [ \"sh\", \"-c\", \"java -jar easysite-exploration.jar\" ] docker打包命令 在放置jar包和Dockerfile的目录下，使用命令打包为镜像（注意命令后面有个 '.',xxx/xxx为镜像名称，v1为版本号） docker build -t xxx/xxx:v1 . 1.2：在Docker中安装ubuntu[~v.v~] 拉取 Ubuntu 镜像 拉取最新镜像 docker pull ubuntu:latest 拉取指定镜像 docker pull ubuntu:18.04 在docker的ubuntu中安装jdk 复制宿主机中的/java/jdk8.tar.gz 文件至 docker中ubuntu中的/java 文件夹中，ea49f55dde3d为镜像id docker cp /java/jdk8.tar.gz ea49f55dde3d:/java/ 删除原装的openjdk sudo apt-get purge openjdk* 解压文件、配置环境变量略 ！！！特别注意！！！ 一定要提交对原镜像的修改，打包成新的镜像（否则在重启原镜像后，无法保留在原镜像上的所有修改，包含各种配置和安装的资源） docker commit -a=\"xxx\" -m=\"test\" c8314e7588ad xxx/test:0.1 打包命令 作者 描述信息 原镜像id 新的名字 版本号 二 Centos7-Docker ","date":"2021-11-29","objectID":"/docker-%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/:1:3","tags":["运维"],"title":"Dokcer研发环境搭建记录","uri":"/docker-%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"},{"categories":["运维"],"content":"1 安装docker 参考 https://blog.csdn.net/qq_26400011/article/details/113856681 1、安装之前现卸载系统上原有的Docker yum remove docker \\ docker-client \\ docker-client-latest \\ docker-common \\ docker-latest \\ docker-latest-logrotate \\ docker-logrotate \\ docker-engine 2、安装需要的安装包yum-utils yum install -y yum-utils 3、设置镜像仓库地址 阿里云的镜像仓库地址 yum-config-manager \\ --add-repo \\ http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo 4、安装docker相关的引擎 yum makecache fase ","date":"2021-11-29","objectID":"/docker-%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/:2:0","tags":["运维"],"title":"Dokcer研发环境搭建记录","uri":"/docker-%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"},{"categories":["运维"],"content":"2 设置镜像仓库 vi /etc/docker/daemon.json 添加 镜像路径 xxx为镜像url { \"registry-mirrors\": [\"xxx\"] } { \"registry-mirrors\": [\"https://nmg8n4ak.mirror.aliyuncs.com\"] } # 中国科技大学 https://docker.mirrors.ustc.edu.cn # 网易 http://hub-mirror.c.163.com # 阿里云（需要注册账户来进行个人镜像路径获取） 三 docker软件安装 ","date":"2021-11-29","objectID":"/docker-%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/:3:0","tags":["运维"],"title":"Dokcer研发环境搭建记录","uri":"/docker-%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"},{"categories":["运维"],"content":"3 安装mysql 安装最新版本 docker pull mysql:8.0.27 启动容器，将3306端口映射至外部3306端口，设置进入密码123456 docker run \\ --privileged=true \\ --restart=always \\ --name mysql:8.0.27 -p 3306:3306 \\ -e MYSQL_ROOT_PASSWORD=123456 \\ -v /opt/mysql/data:/var/lib/mysql \\ -v /opt/mysql/conf.d:/etc/mysql/conf.d \\ -d mysql \\ --lower_case_table_names=1 参数说明 进入容器，配置mysql ***为容器id docker exec -it mysql /bin/bash 进入mysql，修改远程连接 mysql -uroot -p123456 更新root权限 update user set host='%' where user='root'; alter user 'root'@'%' identified by '123456' password expire never; alter user 'root'@'%' identified with mysql_native_password by '123456'; 刷新权限配置 flush privileges; 重启mysql后使用navicat工具测试连接 ","date":"2021-11-29","objectID":"/docker-%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/:4:0","tags":["运维"],"title":"Dokcer研发环境搭建记录","uri":"/docker-%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"},{"categories":["运维"],"content":"4 安装redis # 安装最新redis docker pull redis # 启动redis镜像 docker run -p 6379:6379 \\ --restart=always \\ --name redis \\ -v /opt/redis/conf/redis.conf:/etc/redis/redis.conf \\ -v /opt/redis/data:/data \\ -d redis redis-server /etc/redis/redis.conf \\ --appendonly yes # 启动参数说明 -p 6379:6379 端口映射：前表示主机部分，：后表示容器部分。 --name redis 指定该容器名称，查看和进行操作都比较方便。 -v 挂载目录，规则与端口映射相同。 -d redis 表示后台启动redis redis-server /etc/redis/redis.conf 以配置文件启动redis，加载容器内的conf文件（其实找到的是挂载的宿主机映射目录/opt/redis/redis.conf） appendonly yes 开启redis 持久化 # 设置自启动 docker update --restart=always 镜像启动id ","date":"2021-11-29","objectID":"/docker-%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/:5:0","tags":["运维"],"title":"Dokcer研发环境搭建记录","uri":"/docker-%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"},{"categories":["运维"],"content":"5 安装nginx # 下载最新nginx docker pull nginx # 将本地主配置文件、从配置文件、静态资源文件映射到容器内部，并启动容器 docker run --name nginx \\ -p 80:80 \\ -p 6001:6001 \\ -p 7001:7001 \\ -p 7070:7070 \\ -p 10011:10011 \\ --restart=always \\ --privileged=true \\ -v /opt/nginx/docker.nginx.conf:/etc/nginx/nginx.conf \\ -v /opt/nginx/docker-nginx-confs/:/opt/nginx/docker-nginx-confs/ \\ -v /www/wwwroot/dists/:/www/wwwroot/dists \\ -d nginx docker run -p 80:80 -p 6001:6001 -p6002:6002 -p 7001:7001 -p 7070:7070 -p 10011:10011 --name nginx --restart=always --privileged=true -v /opt/nginx/docker.nginx.conf:/etc/nginx/nginx.conf -v /opt/nginx/docker-nginx-confs/:/opt/nginx/docker-nginx-confs/ -v /www/wwwroot/dists/:/www/wwwroot/dists -d nginx ","date":"2021-11-29","objectID":"/docker-%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/:6:0","tags":["运维"],"title":"Dokcer研发环境搭建记录","uri":"/docker-%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"},{"categories":["运维"],"content":"6安装可视化界面 portainer #下载镜像 dk pull portainer/portainer #启动镜像 docker run -d -p 9000:9000 \\ --restart=always \\ -v /var/run/docker.sock:/var/run/docker.sock \\ --name prtainer \\ docker.io/portainer/portainer ","date":"2021-11-29","objectID":"/docker-%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/:7:0","tags":["运维"],"title":"Dokcer研发环境搭建记录","uri":"/docker-%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"},{"categories":["运维"],"content":"7安装elasticsearch #设置max_map_count的值 sysctl -w vm.max_map_count=262144 #拉取镜像 docker pull elasticsearch:7.7.0 #启动镜像 docker run --name els -d -e \\ ES_JAVA_OPTS=\"-Xms512m -Xmx512m\" -e \"discovery.type=single-node\" \\ -p 9200:9200 -p 9300:9300 elasticsearch:7.7.0 #访问 http://ip:9200/ 出现以下内容代表启动成功 { \"name\" : \"80e63ddf710f\", \"cluster_name\" : \"docker-cluster\", \"cluster_uuid\" : \"lEabtVF1Tfqgny2MCud7aA\", \"version\" : { \"number\" : \"7.7.0\", \"build_flavor\" : \"default\", \"build_type\" : \"docker\", \"build_hash\" : \"81a1e9eda8e6183f5237786246f6dced26a10eaf\", \"build_date\" : \"2020-05-12T02:01:37.602180Z\", \"build_snapshot\" : false, \"lucene_version\" : \"8.5.1\", \"minimum_wire_compatibility_version\" : \"6.8.0\", \"minimum_index_compatibility_version\" : \"6.0.0-beta1\" }, \"tagline\" : \"You Know, for Search\" } #安装elasticsearch-head 客户端可视化工具 docker pull mobz/elasticsearch-head:5-alpine docker run -d \\ --name=elasticsearch-head \\ --restart=always \\ -p 9100:9100 \\ docker.io/mobz/elasticsearch-head:5-alpine ","date":"2021-11-29","objectID":"/docker-%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/:8:0","tags":["运维"],"title":"Dokcer研发环境搭建记录","uri":"/docker-%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"},{"categories":["运维"],"content":"8搭建nexus私服 #参考博客 https://blog.csdn.net/u012943767/article/details/79475718 #拉取最新镜像 docker pull sonatype/nexus3 #运行镜像 挂载磁盘信息、端口8081 docker run -d -p 8081:8081 \\ --name nexus \\ --restart=always \\ -v /opt/nexus/data:/var/nexus-data \\ sonatype/nexus3 docker run -d --name nexus3 \\ --privileged=true \\ --restart=always \\ -p 8081:8081 \\ -p 10000:10000 \\ -p 10010:10010 \\ -p 10020:10020 \\ -v /opt/nexus3/nexus-data:/var/nexus-data \\ fe48ec3e44c6 dk exec -it nexus3 /bin/bash dk cp nexus3:/nexus-data/ /opt/nexus/nexus-data/ #登录 默认账号：admin 默认密码： 默认密码在容器内部的 /nexus-data/admin.password 文件中 进入容器获取复制密码 #建立仓库 #设置中文 8081端口是nexus3的服务端口 10000端口用于host镜像仓库的服务端口 10010端口用于group镜像仓库的服务端口 ","date":"2021-11-29","objectID":"/docker-%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/:9:0","tags":["运维"],"title":"Dokcer研发环境搭建记录","uri":"/docker-%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"},{"categories":["运维"],"content":"9搭建jenkins自动化部署工具 参考博客 https://blog.csdn.net/cristianoxm/article/details/125740894?ops_request_misc=\u0026request_id=\u0026biz_id=102\u0026utm_term=java.net.UnknownHostException:\u0026utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduweb~default-5-125740894.nonecase\u0026spm=1018.2226.3001.4187 #下载镜像 docker pull jenkins/jenkins #搭建目录 mkdir -p /data/jenkins chmod 777 /data/jenkins #启动镜像 docker run -d \\ -p 10240:8080 \\ -p 10241:50000 \\ -v /data/jenkins:/var/jenkins_home \\ -v /etc/localtime:/etc/localtime \\ --name jenkins jenkins/jenkins #获取密码 docker logs jenkins #修改镜像 vim /data/jenkins/hudson.model.UpdateCenter.xml #替换url https://mirrors.tuna.tsinghua.edu.cn/jenkins/updates/update-center.json #启动jenkins后，生成updates目录，进入目录 cd /data/jenkins/updates #替换源 sed -i 's/https:\\/\\/updates.jenkins.io\\/download/http:\\/\\/mirrors.tuna.tsinghua.edu.cn\\/jenkins/g' /data/jenkins/updates/default.json \u0026\u0026 sed -i 's/http:\\/\\/www.google.com/https:\\/\\/www.baidu.com/g' /data/jenkins/updates/default.json #正式使用 ","date":"2021-11-29","objectID":"/docker-%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/:10:0","tags":["运维"],"title":"Dokcer研发环境搭建记录","uri":"/docker-%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"},{"categories":["运维"],"content":"10搭建sonarqube代码检测工具 #拉取postgres数据库 docker pull postgres #拉取sonarqube docker pull sonarqube #启动数据库 docker run \\ --restart=always \\ --name postgres \\ -v /opt/postgres/data:/var/lib/postgresql/data \\ -e POSTGRES_PASSWORD=root \\ -p 5432:5432 \\ -d postgres #启动sonarqube docker run \\ --name sonar \\ --restart=always \\ --link postgres \\ --privileged=true \\ --restart=always \\ -e SONARQUBE_JDBC_URL=jdbc:postgresql://postgres:5432/sonar \\ -e SONARQUBE_JDBC_USERNAME=postgres \\ -e SONARQUBE_JDBC_PASSWORD=root \\ -v /opt/sonarqube/data:/var/lib/postgresql/data \\ -v /opt/sonarqube/extensions:/opt/sonarqube/extensions \\ -v /opt/sonarqube/logs:/opt/sonarqube/logs \\ -v /opt/sonarqube/conf:/opt/sonarqube/conf \\ -p 9003:9000 \\ -d sonarqube 注意事项和异常处理： 1.通过 -e 填入数据库账号密码 2.需要在postgres中提前创建数据库sonar 3.url \u003cpostgres:5432\u003e中的postgres为link的数据库镜像名称，不能为localhost或127.0.0.1 4.需要设置java环境 5.启动报错，logs日志中关键词： max virtual memory areas vm.max_map_count [65530] is too low, increase to at least [262144] 解决办法： 切换到root用户修改配置sysctl.conf vi /etc/sysctl.conf 添加下面配置 vm.max_map_count=655360 并执行命令 sysctl -p 汉化插件安装失败 从gitee上下载符合版本的汉化包（sonar-l10n-zh-plugin-10.0.jar），放入plugins目录中 检测报告pdf导出 从gitee上下载pdf插件（sonar-pdfreport-plugin-4.0.1.jar），放入plugins目录中 #使用代码检测 mvn compile sonar:sonar \\ -Dsonar.projectKey=plm \\ -Dsonar.host.url=http://10.10.10.8:9001 \\ -Dsonar.login=c531b16a1d0dbb369fa7dfb79890902264017ef6 ","date":"2021-11-29","objectID":"/docker-%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/:11:0","tags":["运维"],"title":"Dokcer研发环境搭建记录","uri":"/docker-%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"},{"categories":["运维"],"content":"11使用IDEA连接ubuntu中的docker容器 #参考链接 https://blog.csdn.net/qq_43107323/article/details/102854705 #编辑配置文件 sudo vim /lib/systemd/system/docker.service #添加开发2375端口 在[Service]标签中，ExecStart行，末尾sock后面, 添加 -H tcp://0.0.0.0:2375 #重新加载配置 systemctl daemon-reload #查看端口配置是否启动 netstat -tulp #安装idea的docker插件 #进入docker设置，选择tcp连接，输入 tcp://虚拟机ip:2375 #可以再idea的服务中看到已经连接的docker容器内容 ","date":"2021-11-29","objectID":"/docker-%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/:12:0","tags":["运维"],"title":"Dokcer研发环境搭建记录","uri":"/docker-%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"},{"categories":["运维"],"content":"12安装cnnal #拉取最新canal docker pull canal/canal-server:latest #运行canal容器（导出配置文件后关闭） docker run -p 11111:11111 --name canal -d canal/canal-server #复制容器中文件至指定目录 dk cp canal:/home/admin/canal-server /opt/canal/ #重新带配置映射启动 docker run \\ --name canal \\ -e canal.instance.master.address=127.0.0.1:3306 \\ -e canal.instance.dbUsername=canal \\ -e canal.instance.dbPassword=canal \\ -v /opt/canal/canal-server:/home/admin/canal-server \\ -p 11111:11111 \\ -d canal/canal-server ","date":"2021-11-29","objectID":"/docker-%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/:13:0","tags":["运维"],"title":"Dokcer研发环境搭建记录","uri":"/docker-%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"},{"categories":["运维"],"content":"13安装kkfile #拉取最新 docker pull keking/kkfileview:v4.0.0 #运行 docker run \\ --name=kkfile \\ --privileged=true \\ --restart=always \\ -v /opt/minio/data:/opt/minio/data \\ -v /tmp/:/tmp/ \\ -v /opt/kkfile/kkFileView-3.3.1:/opt/kkFileView-3.3.1 \\ -p 8012:8012 \\ -d keking/kkfileview:v3.3.1 docker run \\ --name=kkfile \\ --privileged=true \\ --restart=always \\ -v /opt/minio/data:/opt/minio/data \\ -v /tmp/:/tmp/ \\ -v /opt/kkfile/kkFileView-4.0.0:/opt/kkFileView-4.0.0 \\ -p 18012:8012 \\ -d keking/kkfileview:v4.0.0 dk exec -it kkfile /bin/bash kkFileView-4.0.0/ libreoffice7.1/ dk cp kkfile:/opt/kkFileView-4.0.0/ /opt/kkfile/ /opt/openoffice4/program/soffice -headless -accept=\"socket,host=127.0.0.1,port=8100;urp;\" -nofirststartwizard \u0026 ","date":"2021-11-29","objectID":"/docker-%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/:14:0","tags":["运维"],"title":"Dokcer研发环境搭建记录","uri":"/docker-%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"},{"categories":["运维"],"content":"14安装Gitea #拉取最新 docker pull gitea/gitea #运行 docker run -d \\ --privileged=true \\ --restart=always \\ --name=gitea \\ -p 10025:22 \\ -p 10026:3000 \\ -v /opt/gitea:/data \\ gitea/gitea:latest ","date":"2021-11-29","objectID":"/docker-%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/:15:0","tags":["运维"],"title":"Dokcer研发环境搭建记录","uri":"/docker-%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"},{"categories":["运维"],"content":"15安装tomcat docker pull tomcat docker run -d \\ --privileged=true \\ --restart=always \\ --name=tomcat \\ -p 12000:12000 \\ -v /opt/tomcat_map/:/usr/local/tomcat/ \\ -v /usr/share/fonts/:/usr/share/fonts/ \\ tomcat:latest ","date":"2021-11-29","objectID":"/docker-%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/:16:0","tags":["运维"],"title":"Dokcer研发环境搭建记录","uri":"/docker-%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"},{"categories":["运维"],"content":"16安装showdoc #拉取最新 docker pull registry.cn-shenzhen.aliyuncs.com/star7th/showdoc #改名tag docker tag registry.cn-shenzhen.aliyuncs.com/star7th/showdoc:latest lln/showdoc:latest #启动showdoc容器 docker run -d --name showdoc \\ --user=root \\ --privileged=true \\ --restart=always \\ -p 5000:80 \\ -v /opt/showdoc/html:/var/www/html/ lln/showdoc ","date":"2021-11-29","objectID":"/docker-%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/:17:0","tags":["运维"],"title":"Dokcer研发环境搭建记录","uri":"/docker-%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"},{"categories":["运维"],"content":"17 安装minio docker run -p 10123:9000 --name minio \\ -e \"MINIO_ACCESS_KEY=admin\" \\ -e \"MINIO_SECRET_KEY=12345678\" \\ -v /opt/minio/data:/data \\ -v /opt/minio/config:/root/.minio \\ -d \\ minio/minio:RELEASE.2021-06-14T01-29-23Z server /data ","date":"2021-11-29","objectID":"/docker-%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/:18:0","tags":["运维"],"title":"Dokcer研发环境搭建记录","uri":"/docker-%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"},{"categories":["运维"],"content":"18 安装clickhouse ","date":"2021-11-29","objectID":"/docker-%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/:19:0","tags":["运维"],"title":"Dokcer研发环境搭建记录","uri":"/docker-%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"},{"categories":["运维"],"content":"19 安装harbor ","date":"2021-11-29","objectID":"/docker-%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/:20:0","tags":["运维"],"title":"Dokcer研发环境搭建记录","uri":"/docker-%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"},{"categories":["运维"],"content":"20 安装rancher https://docs.rancher.cn/rancher2.5/ sudo docker run --privileged -d --restart=unless-stopped -p 80:80 -p 443:443 rancher/rancher:stable ","date":"2021-11-29","objectID":"/docker-%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/:21:0","tags":["运维"],"title":"Dokcer研发环境搭建记录","uri":"/docker-%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"},{"categories":["运维"],"content":"21 linux命令搜索 https://github.com/jaywcjlove/linux-command docker pull wcjiang/linux-command # Or docker pull ghcr.io/jaywcjlove/linux-command:latest docker run --name linux-command --rm -d -p 9665:3000 wcjiang/linux-command:latest # Or docker run --name linux-command -itd -p 9665:3000 wcjiang/linux-command:latest # Or docker run --name linux-command -itd -p 9665:3000 ghcr.io/jaywcjlove/linux-command:latest http://192.168.11.127:9665/ docker pull wcjiang/linux-command # Or docker pull ghcr.io/jaywcjlove/linux-command:latest docker run --name linux-command --rm -d -p 9665:3000 wcjiang/linux-command:latest # Or docker run --name linux-command -itd -p 9665:3000 wcjiang/linux-command:latest # Or docker run --name linux-command -itd -p 9665:3000 ghcr.io/jaywcjlove/linux-command:latest ","date":"2021-11-29","objectID":"/docker-%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/:22:0","tags":["运维"],"title":"Dokcer研发环境搭建记录","uri":"/docker-%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"},{"categories":["运维"],"content":"22 安装oracle19c # 下载镜像 docker pull registry.cn-hangzhou.aliyuncs.com/zhuyijun/oracle:19c mkdir -p /home/oracle/data chmod 777 /home/oracle/data/ docker run -d \\ -p 1524:1521 -p 5502:5500 \\ -e ORACLE_SID=ORCLCDB \\ -e ORACLE_PDB=ORCLPDB1 \\ -e ORACLE_PWD=supermap1234! \\ -e ORACLE_EDITION=standard \\ -e ORACLE_CHARACTERSET=AL32UTF8 \\ -v /home/oracle/data:/opt/oracle/oradata \\ --name orcl19c \\ registry.cn-hangzhou.aliyuncs.com/zhuyijun/oracle:19c 四 Docker常用命令 启动docker sudo service docker start 停止docker sudo service docker stop 批量停止docker容器 docker ps | grep sinfcloud | awk '{print $1}' | xargs docker stop 说明 批量停止包含 sinfcloud 关键字的镜像，并打印 容器 id 批量删除已停止的docker镜像（docker版本大于1.3使用） sudo docker container prune 批量删除包含某个关键字的镜像（） docker rmi $(docker images | grep 'sinfcloud') 说明 批量删除所有包含 sinfcloud 的镜像包 重启docker sudo service docker restart 列出机器上的容器 docker images 查看所有容器 docker ps -a 启动容器 docker run -itd 容器名称或镜像编号 启动容器并将容器内端口2222映射到外部宿主机端口1111 docker run -itd -p 1111:2222 进入容器 docker attach 容器编号（使用 attach 命令有一个问题。当多个窗口同时使用该命令进入该容器时，所有的窗口都会同步显示。如果有一个窗口阻塞了，那么其他窗口也无法再进行操作。） 关闭容器 docker stop 容器编号 在容器中开启一个交互模式的终端: xxx 为 镜像id docker exec -it xxx /bin/bash 删除容器 容器名称:标签 docker rmi REPOSITORY:TAG 常见错误: \"Error response from daemon: conflict: unable to delete a838c1b6a0e4 (cannot be forced) - image has dependent child images\" 或 \"Error response from daemon: conflict: unable to remove repository reference \"ubuntu-1215:V0.1\" (must force) - container 0257eaaf90a4 is using its referenced image a838c1b6a0e4\" 使用以下命令后，再次执行删除镜像命令 删除所有停止的容器 docker rm $(docker ps -a -q) 在docker反复build后，会存留很多none镜像，下面命令一键删除所有none镜像 docker rmi `docker images | grep '\u003cnone\u003e' | awk '{print $3}'` 提交修改后的镜像 docker commit -a=\"xxx\" -m=\"test\" c8314e7588ad xxx/test:0.1 打包命令 作者 描述信息 原镜像id 新的名字 版本号 docker commit -a=\"jdzt.lln\" -m=\"add:vim\" dc6133ec39d8 nginx:0.3 删除多余tag docker rmi 仓库名称:TAG 设置自启动 docker update --restart=always ID # 查看本机docker所有网络 docker network ls # 创建网络 --driver 是网络模式，--subnet是子网掩码，后面的/16表示可以生成6万多个ip， --gateway是网关地址 docker network create 网络名称 --driver bridge --subnet 192.168.0.1/16 --gateway 192.168.0.2 mynet # 将容器加入到当前网络 docker network connect 网络名称 容器名称 # 断开容器的网络 （容器必须是运行状态才能断开连接） docker network disconnect 网络名称 容器名称 # 查看网络的详细信息 docker network inspect 网络id/网络名称 #删除网络 docker network rm 网络id/网络名称 # 删除所有未使用的网络 docker network prune --f 五 Dockerfile # 基础镜像使用java FROM java:8 # 作者 MAINTAINER jd-lln # VOLUME：用于指定持久化目录 VOLUME /tmp # ADD：将本地文件添加到容器中，tar类型文件会自动解压(网络压缩资源不会被解压)，可以访问网络资源，类似wget ADD test.jar app.jar # EXPOSE：指定于外界交互的端口 EXPOSE 9999 # RUN：构建镜像时执行的命令 RUN echo \"Asia/Shanghai\" \u003e /etc/timezone # ENTRYPOINT：配置容器，使其可执行化。配合CMD可省去\"application\"，只使用参数。 ENTRYPOINT [\"java\",\"-Djava.security.egd=file:/dev/./urandom\",\"-jar\",\"app.jar\"] #构建镜像 docker build -t plm . #运行镜像 dk run --name=plm \\ -p 6003:6003 \\ --privileged=true \\ -d plm 六 常见问题 基础镜像没有常用命令 配置 镜像 vim /etc/apt/sources.list 复制阿里云镜像,替换原国外镜像 deb http://mirrors.aliyun.com/ubuntu/ trusty main restricted universe multiverse deb http://mirrors.aliyun.com/ubuntu/ trusty-security main restricted universe multiverse deb http://mirrors.aliyun.com/ubuntu/ trusty-updates main restricted universe multiverse deb http://mirrors.aliyun.com/ubuntu/ trusty-proposed main restricted universe multiverse deb http://mirrors.aliyun.com/ubuntu/ trusty-backports main restricted universe multiverse deb-src http://mirrors.aliyun.com/ubuntu/ trusty main restricted universe multiverse deb-src http://mirrors.aliyun.com/ubuntu/ trusty-security main restricted universe multiverse deb-src http://mirrors.aliyun.com/ubuntu/ trusty-updates main restricted universe multiverse deb-src http://mirrors.aliyun.com/ubuntu/ trusty-proposed main restricted universe multiverse deb-src http://mirrors.aliyun.com/ubuntu/ trusty-backports main restricted universe multiverse 常用命令缺失 安装vim apt-get update apt-get install vim 安装ping ifconfig apt-get update apt install iputils-ping # ping apt install net-tools # ifconfig 七 出现的异常及解决方案 ","date":"2021-11-29","objectID":"/docker-%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/:23:0","tags":["运维"],"title":"Dokcer研发环境搭建记录","uri":"/docker-%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"},{"categories":["运维"],"content":"1.docker 运行时No chain/target/match by that name 启动镜像出现iptables: No chain/target/match by that name 解决方案 service docker restart 或 systemctl restart docker ","date":"2021-11-29","objectID":"/docker-%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/:23:1","tags":["运维"],"title":"Dokcer研发环境搭建记录","uri":"/docker-%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"},{"categories":["运维"],"content":"2.安装sonar启动镜像报错 日志内容 max virtual memory areas vm.max_map_count [65530] is too low, increase to at least [262144] 解决办法： 切换到root用户修改配置sysctl.conf vi /etc/sysctl.conf 添加下面配置： vm.max_map_count=655360 并执行命令： sysctl -p ","date":"2021-11-29","objectID":"/docker-%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/:23:2","tags":["运维"],"title":"Dokcer研发环境搭建记录","uri":"/docker-%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"},{"categories":["运维"],"content":"3，容器内部时区错误 1.复制宿主机上的zoneinfo文件夹到容器下的/usr/share/ docker cp /usr/share/zoneinfo ef761110f5a2:/usr/share/ 2.执行 docker exec -it detectronwj /bin/bash 进入dokcer内后，执行以下操作： ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime echo \"Asia/Shanghai\" \u003e /etc/timezone 输入验证 date 2.compose脚本中指定时区（推荐） ","date":"2021-11-29","objectID":"/docker-%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/:23:3","tags":["运维"],"title":"Dokcer研发环境搭建记录","uri":"/docker-%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"},{"categories":["读书笔记"],"content":"《浪潮之巅》","date":"2021-11-29","objectID":"/%E6%B5%AA%E6%BD%AE%E4%B9%8B%E5%B7%85/","tags":["读书笔记"],"title":"读书笔记--《浪潮之巅》","uri":"/%E6%B5%AA%E6%BD%AE%E4%B9%8B%E5%B7%85/"},{"categories":["读书笔记"],"content":"读书笔记–《浪潮之巅》 《浪潮之巅》 读书感受 第一，这本书让我明白了一个科学技术只会被另一个更加强大的技术打败 从产业方面来讲，科技产业的发展是一个不断迭代的过程，一个一个新的技术会持续涌现。从计算机的诞生到互联网的普及，再到移动互联网的崛起，每一次技术革新都伴随着一批企业的崛起和衰落。正如书中所说：“科技产业的竞争是一场没有硝烟的战争胜利者将获得巨大的财富和荣誉，而失败者则可能一无所有。”这种竞争的残酷性让我深刻体会到了科技产业的无常，也让我明白了要想在这个领域取得成功，就必须不断地学习和创新。 第二，这本书让我认识到了环境、资金、人才三者缺一不可。 美国的硅谷恰恰都满足，所以百多年来高科技企业层出不穷。书中举了这个例子，书中特别提到了斯坦福大学，他是间民营大学，里面的大学教授的研究费用都要靠自己，所以教授的研究方向就很商业价值，也就很容易找到资本，或者教授自己就创业了，同时也就带动了学生的主观能动性。换句话说，里面的教授可以自己开公司，包括它的校长把公司开进上市公司，形成厂校结合的模式，同时，为硅谷提供了源源不断的创新型人才。 第三，一个公司持续保持创新精神的支撑真心不易。 从战略层面来讲，开公司如同一个国家，它的体制决定了它的发展。作者在阐述企业的这个“神经网络”时，洞察了企业长期健康生存动力，企业就是靠着创新和体制这两驾马车的拉动。 Google的崛起，苹果对移动通信行业的颠覆式创新，以及当下以Facebook和Twitter为代表的社交网络的流行，他们都高举着创新大旗。而创新背后的人才体制、分配体制、管理体制的精细治理，是创新能够成功，并且保证企业持续发展的推动力。钱不是万能的，技术不是万能的，如果没有良好的战略设计，和体制保障，赚钱的游戏真的很难做成，再好的技术也无法转化成生产力。 如 ","date":"2021-11-29","objectID":"/%E6%B5%AA%E6%BD%AE%E4%B9%8B%E5%B7%85/:0:0","tags":["读书笔记"],"title":"读书笔记--《浪潮之巅》","uri":"/%E6%B5%AA%E6%BD%AE%E4%B9%8B%E5%B7%85/"},{"categories":["读书笔记"],"content":"苹果公司 苹果公司依然是目前全球市值最高的公司之一，但是他不断推出新产品的黄金时期已经过去。虽在手机领域仍然占有大部分市场份额，但是在乔布斯去世后，尚未出现如当初ipthon4发布时那样令人震撼的跨时代产品，大多数产品经理之所以做不出改变世界的产品，是因为他们只看见了成功者背后的临门一脚，而忽视了别人的长期思考。 99%的汗水往往不值一提，但那在无数思索后突现的的一抹灵光，往往是一个伟大产品出现的必要条件。 ","date":"2021-11-29","objectID":"/%E6%B5%AA%E6%BD%AE%E4%B9%8B%E5%B7%85/:0:1","tags":["读书笔记"],"title":"读书笔记--《浪潮之巅》","uri":"/%E6%B5%AA%E6%BD%AE%E4%B9%8B%E5%B7%85/"},{"categories":["读书笔记"],"content":"AT\u0026T IBM 像AT\u0026T（美国电话电报公司），曾一度是语音电话行业的龙头，但因为企业高管，资本的贪婪，使得抗住了几轮美国司法部垄断打压的公司，因为要保证投资人的利益，最终做出了很多杀鸡取卵的事情，再加上互联网对话机及语音的冲击，最终公司一步步走向灭亡。 再看IBM，经历三次转型，目前依然还是IT服务行业的龙头。从最初的机械制表机，转型到计算机，再转型到服务，都做的非常成功，虽然没有抓住自动PC和互联网的浪潮，但是他一直专注于自己的核心领域不断的做保守的创新，并且守住自己的核心市场高地，政府，企业和军队。这使得他经历了大萧条和金融危机而不倒。 任何一个企业最终是否能够穿越历史的长河，都会面临着两种挑战，一种是基于企业本身的挑战，战略决策，机会的把握，组织架构的调整，技术创新等等。另一种是外部趋势，潮流的挑战。 IT行业的几大规律 ","date":"2021-11-29","objectID":"/%E6%B5%AA%E6%BD%AE%E4%B9%8B%E5%B7%85/:0:2","tags":["读书笔记"],"title":"读书笔记--《浪潮之巅》","uri":"/%E6%B5%AA%E6%BD%AE%E4%B9%8B%E5%B7%85/"},{"categories":["读书笔记"],"content":"摩尔定律 集成电路上可以容纳的晶体管数目在大约每经过18个月便会增加一倍。 归纳起来，“摩尔定律”主要有以下3种“版本”： 1、集成电路芯片上所集成的电路的数目，每隔18个月就翻一番； 2、微处理器的性能每隔18个月提高一倍，而价格下降一半； 3、用一美元所能买到的计算机性能，每隔18个月翻两番。 ","date":"2021-11-29","objectID":"/%E6%B5%AA%E6%BD%AE%E4%B9%8B%E5%B7%85/:0:3","tags":["读书笔记"],"title":"读书笔记--《浪潮之巅》","uri":"/%E6%B5%AA%E6%BD%AE%E4%B9%8B%E5%B7%85/"},{"categories":["读书笔记"],"content":"安迪-比尔定律 安迪-比尔定理是对IT产业中软件和硬件升级换代关系的一个概括。原话是 “Andy gives, Bill takes away.（安迪提供什么，比尔拿走什么。）” 安迪指英特尔前CEO，比尔指微软前任CEO比尔·盖茨，这句话的意思是，硬件提高的性能，很快被软件消耗掉了。 ","date":"2021-11-29","objectID":"/%E6%B5%AA%E6%BD%AE%E4%B9%8B%E5%B7%85/:0:4","tags":["读书笔记"],"title":"读书笔记--《浪潮之巅》","uri":"/%E6%B5%AA%E6%BD%AE%E4%B9%8B%E5%B7%85/"},{"categories":["读书笔记"],"content":"反摩尔定律 反摩尔定律是Google的前CEO埃里克·施密特提出的：如果你反过来看摩尔定律，一个IT公司如果今天和18个月前卖掉同样多的、同样的产品，它的营业额就要降一半。IT界把它称为反摩尔定律。 ","date":"2021-11-29","objectID":"/%E6%B5%AA%E6%BD%AE%E4%B9%8B%E5%B7%85/:0:5","tags":["读书笔记"],"title":"读书笔记--《浪潮之巅》","uri":"/%E6%B5%AA%E6%BD%AE%E4%B9%8B%E5%B7%85/"},{"categories":["读书笔记"],"content":"70-20-10律 由原苹果公司CEO斯卡利提出，并由本书的作者吴军扩展，具体内容为：在信息科技产业中，当某个领域发展成熟之后，一般在全球容不下三个以上的竞争者，最大的公司主导着这个领域的发展，一般占据着一半以上（60%或70%）的市场份额，而第二名的公司一般也有20%左右的稳定市场，其余的10%的市场由一群小公司瓜分。比如，在桌面处理器领域的英特尔和AMD公司，在国内电子商务领域的阿里巴巴，京东以及拼多多，苏宁，唯品会等等。 ","date":"2021-11-29","objectID":"/%E6%B5%AA%E6%BD%AE%E4%B9%8B%E5%B7%85/:0:6","tags":["读书笔记"],"title":"读书笔记--《浪潮之巅》","uri":"/%E6%B5%AA%E6%BD%AE%E4%B9%8B%E5%B7%85/"},{"categories":["读书笔记"],"content":"诺威格定律 由Google研究院主任、人工智能专家彼得·诺威格博士提出，当一家公司的市场占有率超过50%后，就无法再翻番了。这个定律相应的很好理解，当一家公司在某个特定的行业做大做强乃至到了垄断的地步时，它的发展就受制于整个宏观经济或者整个行业的科技进步和发展了 ","date":"2021-11-29","objectID":"/%E6%B5%AA%E6%BD%AE%E4%B9%8B%E5%B7%85/:0:7","tags":["读书笔记"],"title":"读书笔记--《浪潮之巅》","uri":"/%E6%B5%AA%E6%BD%AE%E4%B9%8B%E5%B7%85/"},{"categories":["其他"],"content":"Python加密及Java调用方案","date":"2021-11-05","objectID":"/python%E5%8A%A0%E5%AF%86%E5%8F%8Ajava%E8%B0%83%E7%94%A8%E6%96%B9%E6%A1%88/","tags":["其他"],"title":"Python加密及Java调用方案","uri":"/python%E5%8A%A0%E5%AF%86%E5%8F%8Ajava%E8%B0%83%E7%94%A8%E6%96%B9%E6%A1%88/"},{"categories":["其他"],"content":"Python加密及Java调用方案 createBy lln updateTime 2021-09-28 ","date":"2021-11-05","objectID":"/python%E5%8A%A0%E5%AF%86%E5%8F%8Ajava%E8%B0%83%E7%94%A8%E6%96%B9%E6%A1%88/:0:0","tags":["其他"],"title":"Python加密及Java调用方案","uri":"/python%E5%8A%A0%E5%AF%86%E5%8F%8Ajava%E8%B0%83%E7%94%A8%E6%96%B9%E6%A1%88/"},{"categories":["其他"],"content":"加密方案 官方网站 http://www.pyinstaller.org 官网文档 https://pyinstaller.readthedocs.io/en/stable/ 参考博客 https://www.cnblogs.com/weix-l/p/10881373.html https://zhuanlan.zhihu.com/p/85760495 https://blog.csdn.net/x_w_haohan/article/details/99233561 https://blog.csdn.net/Iv_zzy/article/details/107462210 https://blog.csdn.net/qq_16104903/article/details/90444269 https://blog.csdn.net/qq_41699621/article/details/103596742 ","date":"2021-11-05","objectID":"/python%E5%8A%A0%E5%AF%86%E5%8F%8Ajava%E8%B0%83%E7%94%A8%E6%96%B9%E6%A1%88/:1:0","tags":["其他"],"title":"Python加密及Java调用方案","uri":"/python%E5%8A%A0%E5%AF%86%E5%8F%8Ajava%E8%B0%83%E7%94%A8%E6%96%B9%E6%A1%88/"},{"categories":["其他"],"content":"Windows pyinstaller打包方法 #安装pyinstaller pip install pyinstaller PyInstaller提供了两种把.py文件包成.exe文件的方式： 第一种：把由.py文件打包而成的.exe文件及相关文件放在一个目录中。 语法：pyinstaller 应用程序 eg：pyinstaller Hello.py 第二种：加上 -F 参数后把制作出的.exe打包成一个独立的.exe格式的可执行文件。 语法：pyinstaller -F 应用程序 eg：pyinstaller -F Hello.py 虽然扩平台，但是pyinstaller也只能在当前操作系统中运行，比如你用mac只能打包出mac上的可执行脚本，要是你想打包出windwos电脑上的可执行程序，你就要用windows执行打包命令。 如果你的脚本文件中包含其他脚本，比如hello.py包含自定义脚本(world.py)或是系统脚本(sys.py)：则需要在打包的时候加上其他脚本的路径。通过-p指定第三方包的路径，一条路径对应一个-p eg：pyinstaller -F -p C:\\SystemLib\\site-packages -p C:\\MyLib Hello.py 执行一次打包命令通常会生成两个目录一个附件，分别是build、dist、和xx.spec。build是编译过程中的中间产物，dist是最终可执行程序目录，spec文件是类似缓存，如果你第二次打包，则需要先把spec删掉，否则第二次打包会受影响。 参数介绍 -a：不包含编码.在支持Unicode的python版本上默认包含所有的编码 -c：使用控制台子系统执行(默认)(只对Windows有效) -d：产生debug版本的可执行文件 -i ：指定打包程序使用的图标（icon）文件 -F：打包成可执行程序 -h：查看帮助 -p：添加使用的第三方库路径 -v：查看 PyInstaller 版本 -w：取消控制台显示（默认是显示控制台的） eg: pyinstaller -F -p C:\\SystemLib\\site-packages -p C:\\MyLib main.py -i C:\\image\\excel.ico 解释： 打包 main.py 脚本 main.py包含第三方脚本，一个是系统脚本，一个是自定义脚本 设置可执行程序的图标为excel.ico 测试python脚本 from tkinter import * def btnClick(): textLabel['text'] = '我点击了按钮' root = Tk(className=\"测试打包\"); textLabel = Label(root, text='提示显示', justify=LEFT, padx=10) textLabel.pack(side=TOP) btn = Button(root) btn['text'] = '点击测试' btn['command'] = btnClick btn.pack(side=BOTTOM) mainloop() ","date":"2021-11-05","objectID":"/python%E5%8A%A0%E5%AF%86%E5%8F%8Ajava%E8%B0%83%E7%94%A8%E6%96%B9%E6%A1%88/:1:1","tags":["其他"],"title":"Python加密及Java调用方案","uri":"/python%E5%8A%A0%E5%AF%86%E5%8F%8Ajava%E8%B0%83%E7%94%A8%E6%96%B9%E6%A1%88/"},{"categories":["其他"],"content":"Linux 将python编译成so文件进行调用 1.安装cython，gcc sudo apt install python3-dev gcc 2.安装cpython pip3 install cython 3.将需要转化的python源文件，代码调用python文件，打包加密文件放在同一个目录中 4.在当前目录中执行 python3 setup.py build_ext 5.生成文件 /build/lib.linux-x86_64-3.6/t1.cpython-36m-x86_64-linux-gnu.so* 6.复制 /build/lib.linux-x86_64-3.6/t1.cpython-36m-x86_64-linux-gnu.so* 与 t3 处于同一文件夹 7.删除 t1.py rm t1.py 8.调用t3.py python t3.py 9.正常输出t1.py 的内容 测试python脚本 脚本1 t1.py 说明：数据脚本，即需要被加密的源文件 import datetime class Today(): def get_time(self): print(datetime.datetime.now()) def say(self): print(\"hello from JC!\") 脚本2 t2.py 说明：加密脚本 from distutils.core import setup from Cython.Build import cythonize setup(ext_modules = cythonize([\"t1.py\"])) 脚本3 t3.py 说明： 进行了对脚本 t1 的调用 from mytest import Today t = Today() t.get_time() t.say() ","date":"2021-11-05","objectID":"/python%E5%8A%A0%E5%AF%86%E5%8F%8Ajava%E8%B0%83%E7%94%A8%E6%96%B9%E6%A1%88/:1:2","tags":["其他"],"title":"Python加密及Java调用方案","uri":"/python%E5%8A%A0%E5%AF%86%E5%8F%8Ajava%E8%B0%83%E7%94%A8%E6%96%B9%E6%A1%88/"},{"categories":["其他"],"content":"调用方案 数据对接思路 1.python方， 将核心代码加密为 .so 文件，通过外层函数处理和转换数据，转换后的数据，对加密脚本进行黑箱调用。 2.java方， 定义python脚本路径，定义JSON数据对象格式，转换JSON数据为数据流，调用python暴露的外层壳函数，使用如下代码进行调用 测试调用代码 Java @Component public class AlgorithmExecuteHelper { private static final Logger logger = LoggerFactory.getLogger(AlgorithmExecuteHelper.class); private final String pythonPath; private final ThreadPoolTaskExecutor taskExecutor; public AlgorithmExecuteHelper(@Value(\"${python-path}\") String pythonPath, ThreadPoolTaskExecutor taskExecutor) { this.pythonPath = pythonPath; this.taskExecutor = taskExecutor; } public ProcessResultDto execute( File directory, File enterFile, DataConsumer consumer){ Process process = null; try { process = new ProcessBuilder() .command(pythonPath, enterFile.getName()) .directory(directory) .start(); final BlockingQueue\u003cString\u003e inputQueue = new LinkedBlockingQueue\u003c\u003e(); final BlockingQueue\u003cString\u003e errorQueue = new LinkedBlockingQueue\u003c\u003e(); taskExecutor.execute(this.readStreamToQueue(new BufferedInputStream(process.getInputStream()), inputQueue)); taskExecutor.execute(this.readStreamToQueue(new BufferedInputStream(process.getErrorStream()), errorQueue)); try (final OutputStream outputStream = new BufferedOutputStream(new GZIPOutputStream(process.getOutputStream()))) { consumer.accept(outputStream); } return new ProcessResultDto(process.waitFor(), inputQueue, errorQueue); } catch (Exception e) { throw new RuntimeException(); } finally { if (Objects.nonNull(process)) { process.destroy(); } } } private Runnable readStreamToQueue( InputStream inputStream, BlockingQueue\u003cString\u003e queue) { return () -\u003e { String line; try (final BufferedReader reader = new BufferedReader(new InputStreamReader(inputStream))) { while ((line = reader.readLine()) != null) { queue.add(line); } } catch (Exception e) { logger.warn(e.getMessage(), e); } }; } @FunctionalInterface public interface DataConsumer { void accept(OutputStream out) throws Exception; } } 测试调用代码 Python import sys import gzip import json def getInputData(): gzipByteArray = sys.stdin.buffer.read() jsonStr = gzip.decompress(gzipByteArray).decode(\"utf-8\") return json.loads(jsonStr) ","date":"2021-11-05","objectID":"/python%E5%8A%A0%E5%AF%86%E5%8F%8Ajava%E8%B0%83%E7%94%A8%E6%96%B9%E6%A1%88/:2:0","tags":["其他"],"title":"Python加密及Java调用方案","uri":"/python%E5%8A%A0%E5%AF%86%E5%8F%8Ajava%E8%B0%83%E7%94%A8%E6%96%B9%E6%A1%88/"},{"categories":["运维"],"content":" Author:JDZT.LLN CreateDate:2020-12-05 UpdateDate:2021-03-21 一：服务器环境安装 系统环境:ubuntu-18.04.5-live-server-amd64 安装过程:参考链接：https://blog.csdn.net/github_38336924/article/details/82427252 Xshell连接设置:参考链接：https://blog.csdn.net/sunset108/article/details/40818815 ","date":"2021-11-01","objectID":"/ubuntu1804-%E5%9F%BA%E6%9C%AC%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/:0:0","tags":["运维"],"title":"Ubuntu1804研发环境搭建","uri":"/ubuntu1804-%E5%9F%BA%E6%9C%AC%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"},{"categories":["运维"],"content":"JDK安装 卸载服务器自带openJDK,安装当前项目开发使用版本，当前为 JDK1.8 通过xftp将下载的jdk文件(注意jdk版本要和系统位数一致，64位系统使用64位的包)，放入服务器中指定文件夹 如果上传失败，检查文件夹权限，并修改权限 上传成功后，进行文件解压缩 配置环境变量文件 进入配置文件:vim /etc/profile 文件尾部添加: export JAVA_HOME=/java/jdk8 (jdk安装路径) export CLASSPATH=.:$CLASSPATH:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar export PATH=$PATH:$JAVA_HOME/bin export JRE_HOME=$JAVA_HOME/jre 刷新文件: source /etc/profile 测试是否安装完成 java -version ","date":"2021-11-01","objectID":"/ubuntu1804-%E5%9F%BA%E6%9C%AC%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/:1:0","tags":["运维"],"title":"Ubuntu1804研发环境搭建","uri":"/ubuntu1804-%E5%9F%BA%E6%9C%AC%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"},{"categories":["运维"],"content":"安装mysql 血泪教训：ubuntu默认安装 mysql5 !!! 一定要注意版本 安装参考链接： https://blog.csdn.net/wm609972715/article/details/83759266 ubuntu安装-卸载mysql8 https://www.cnblogs.com/zhangxuel1ang/p/13456116.html https://www.cnblogs.com/yxym2016/p/12669532.html 修改可远程访问,允许mysql远程连接：参考链接： https://blog.csdn.net/winterking3/article/details/86080434 https://www.cnblogs.com/devjiajun/articles/9635464.html https://blog.csdn.net/weixx3/article/details/80782479 https://www.cnblogs.com/wzwyc/p/10121409.html 安装后操作 1.注释bind-address = 127.0.0.1。 代码如下: sudo vim /etc/mysql/mysql.conf.d/mysqld.cnf 将bind-address = 127.0.0.1注释掉（即在行首加#） 除了注视掉这句话之外，还可以把后面的IP地址修改成允许连接的IP地址。 但是，如果只是开发用的数据库，为了方便起见，还是推荐直接注释掉。 从上面的注释中，可以看出，旧版本的MySQL（从一些资料上显示是5.0及其以前的版本）上使用的是skip-networking。所以，善意提醒一下，使用旧版本的小伙伴请注意一下。 2.登录进数据库： mysql -u root -p 切换到数据库mysql。SQL如下： use mysql; 3.增加允许远程访问的用户或者允许现有用户的远程访问。 删除匿名用户后，给root授予在任意主机（%）访问任意数据库的所有权限。SQL语句如下： grant all privileges on *.* to 'root'@'%' identified by '@Lisijiang1994321ZaQ!' with grant option; grant all privileges on *.* to 'root'@'%' identified by '123456' with grant option; @Lisijiang1994321ZaQ! update user set host=% where user=root; flush privileges; 4.退出数据库 exit 5.重启数据库 sudo service mysql restart create user 'root'@'%' identified by '@Lisijiang1994321ZaQ!'; 卸载mysql 参考：https://www.cnblogs.com/pighui/p/10422927.html 1.卸载mysql 以下命令分开执行 sudo apt-get autoremove --purge mysql-server sudo apt-get autoremove --purge mysql-server-* sudo apt-get autoremove --purge mysql-client sudo apt-get autoremove --purge mysql-client-* sudo apt-get remove mysql-common 2.删除数据 dpkg -l |grep ^rc|awk '{print $2}' |sudo xargs dpkg -P 注意，清楚的过程中会弹出几个窗口，内容大概是问你是否需要清除用户数据之类的，要选择yes！ 3.删除目录 sudo rm -rf /etc/mysql sudo rm -rf /var/lib/mysql 4.清除残留 sudo apt autoremove sudo apt autoreclean ","date":"2021-11-01","objectID":"/ubuntu1804-%E5%9F%BA%E6%9C%AC%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/:2:0","tags":["运维"],"title":"Ubuntu1804研发环境搭建","uri":"/ubuntu1804-%E5%9F%BA%E6%9C%AC%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"},{"categories":["运维"],"content":"maven 下载maven最新jar.gz压缩包，解压到指定路径 分别在系统配置文件中进行环境变量的配置 vim /etc/profile vim ~/.bashrc 添加配置信息,MAVEN_HOME 为解压后的maven路径 MAVEN_HOME=/www/maven3.6.3 PATH=${MAVEN_HOME}/bin:${PATH} ","date":"2021-11-01","objectID":"/ubuntu1804-%E5%9F%BA%E6%9C%AC%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/:3:0","tags":["运维"],"title":"Ubuntu1804研发环境搭建","uri":"/ubuntu1804-%E5%9F%BA%E6%9C%AC%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"},{"categories":["运维"],"content":"jenkins 安装流程官方说明： https://pkg.jenkins.io/debian-stable/ # 安装命令 wget -q -O - https://pkg.jenkins.io/debian-stable/jenkins.io.key | sudo apt-key add - deb https://pkg.jenkins.io/debian-stable binary/ sudo apt-get update sudo apt-get install jenkins 启动 service jenkins start systemctl restart jenkins 重启 service jenkins restart 停止 service jenkins stop 安装后配置密码 sudo cat /var/lib/jenkins/secrets/initialAdminPassword 修改端口 vim /etc/sysconfig/jenkins 或vim /etc/default/jenkins 修改JENKINS_PORT=\"9090\" 查看日志 vim /var/log/jenkins/jenkins.log ","date":"2021-11-01","objectID":"/ubuntu1804-%E5%9F%BA%E6%9C%AC%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/:4:0","tags":["运维"],"title":"Ubuntu1804研发环境搭建","uri":"/ubuntu1804-%E5%9F%BA%E6%9C%AC%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"},{"categories":["运维"],"content":"Nginx： ps aux | grep nginx nginx -s stop 立即停止nginx nginx -s quit 这种方法较stop相比就比较温和一些了，需要进程完成当前工作后再停止 killall nginx 这种方法是比较野蛮的，在上面使用没有效果时，我们用这种方法还是比较好的 systemctl stop nginx.service systemctl restart nginx.service nginx -s reload 重新载入配置文件 ","date":"2021-11-01","objectID":"/ubuntu1804-%E5%9F%BA%E6%9C%AC%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/:5:0","tags":["运维"],"title":"Ubuntu1804研发环境搭建","uri":"/ubuntu1804-%E5%9F%BA%E6%9C%AC%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"},{"categories":["运维"],"content":"Redis 安装 sudo apt-get install redis-server 进入 cd /etc/init.d/ //直接启动 ./redis-server //后台配置文件启动 ./redis-server redis.conf 启动、停止redis /etc/init.d/redis-server stop /etc/init.d/redis-server start 卸载 sudo apt-get purge --auto-remove redis-server ","date":"2021-11-01","objectID":"/ubuntu1804-%E5%9F%BA%E6%9C%AC%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/:6:0","tags":["运维"],"title":"Ubuntu1804研发环境搭建","uri":"/ubuntu1804-%E5%9F%BA%E6%9C%AC%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"},{"categories":["运维"],"content":"安装禅道项目管理 参考官方文档 https://www.zentao.net/book/zentaopmshelp/40.html 下载官方linux一键安装包，解压至 /opt #修改默认端口，防止和已安装服务冲突 /opt/zbox/zbox -ap 10024 -mp 3307 #启动 sh /opt/zbox/zbox start #停止 sh /opt/zbox/zbox stop #配置自启动 https://blog.csdn.net/lizhe_dashuju/article/details/56484733 1. 在/etc/init.d目录下创建chandao文件 内容如下： #!/bin/bash /opt/zbox/zbox restart 然后增加全选 chmod 755 chandao 2. 运行runlevel命令，查看现在的run level是多少， Linux系统有7个运行级别(runlevel) 运行级别0：系统停机状态，系统默认运行级别不能设为0，否则不能正常启动 运行级别1：单用户工作状态，root权限，用于系统维护，禁止远程登陆 运行级别2：多用户状态(没有NFS) 运行级别3：完全的多用户状态(有NFS)，登陆后进入控制台命令行模式 运行级别4：系统未使用，保留 运行级别5：X11控制台，登陆后进入图形GUI模式 运行级别6：系统正常关闭并重启，默认运行级别不能设为6，否则不能正常启动 eg： 显示 N 5 3. 既然是5,就在/etc/rc5.d目录下，创建一个链接 ln -s /etc/init.d/chandao S99chandao 4. 重启服务器，检查禅到是否开启 检查浏览器地址是否能打开禅道 二：出现的异常及解决方案 ","date":"2021-11-01","objectID":"/ubuntu1804-%E5%9F%BA%E6%9C%AC%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/:7:0","tags":["运维"],"title":"Ubuntu1804研发环境搭建","uri":"/ubuntu1804-%E5%9F%BA%E6%9C%AC%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"},{"categories":["运维"],"content":"1.系统配置 1.1服务器ip冲突，centos7修改静态ip 修网络配置文件 vim /etc/sysconfig/network-scripts/ifcfg-ens33 BOOTPROTO=\"static\" # 使用静态IP地址，默认为dhcp IPADDR=\"19.37.33.66\" # 设置的静态IP地址 NETMASK=\"255.255.255.0\" # 子网掩码 GATEWAY=\"19.37.33.1\" # 网关地址 DNS1=\"192.168.241.2\" # DNS服务器（此设置没有用到，所以我的里面没有添加） ONBOOT=yes #设置网卡启动方式为 开机启动 并且可以通过系统服务管理器 systemctl 控制网卡 修改映射文件 NETWORKING=yes GATEWAY=19.37.33.1 # 网关地址 同上 重启网络服务 service network restart 1.2无法挂载外部硬盘 mount: unknown filesystem type ‘ntfs’ 这是由于CentOS release 5.5(Final)上无法识别NTFS格式的分区（就是用U盘或者移动硬盘挂载，系统无法识别） 解放方案： 安装ntfs-3g插件 使用插件命令 此时依然报错 Mount is denied because the NTFS volume is already exclusively opened. The volume may be already mounted, or another software may use it which could be identified for example by the help of the 'fuser' command. 大意为sdb1挂载的盘上有正在运行的任务，所以需要先停止再进行挂载操作 fuser -m -u /dev/sdb2 杀死查询出来的进程，再次执行挂载 mount -t ntfs-3g /dev/sdb2 /opt/ 1.3新装系统无法ssh访问，无法ping通内部网络 解放方法： 安装openssh-client工具和openssh-server工具,并在系统ssh配置中添加允许远程访问 参考方案： https://jingyan.baidu.com/article/60ccbceb1fae7f25cbb19767.html //无法连接ssh https://blog.csdn.net/qq_23730693/article/details/107732884 sudo apt-get install openssh-server #如果安装失败，先卸载openssh-client，再安装 sudo apt-get purge openssh-client ","date":"2021-11-01","objectID":"/ubuntu1804-%E5%9F%BA%E6%9C%AC%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/:8:0","tags":["运维"],"title":"Ubuntu1804研发环境搭建","uri":"/ubuntu1804-%E5%9F%BA%E6%9C%AC%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"},{"categories":["运维"],"content":"2.MySQl mysql8运行group by异常 （5升级8后 语法模式调整，需要手动改sqlmode） mysql8 无法使用group by 语句 异常信息：this is incompatible with sql_mode=only_full_group_by 修改 配置文件中的 sql_mode vim /etc/my.cnf [mysqld] sql_mode=STRICT_TRANS_TABLES,NO_ZERO_IN_DATE,NO_ZERO_DATE,ERROR_FOR_DIVISION_BY_ZERO,NO_ENGINE_SUBSTITUTION ubuntu启动mysql报错 Job for mysql.service failed because the control process exited with error code. See \"systemctl status mysql.service\" and \"journalctl -xe\" for details. mysql设置大小写忽略、设置端口 vim /etc/mysql/mysql.conf.d/mysqld.cnf 在[mysqld]标签下添加 #默认0 1代表忽略 lower_case_table_names=1 port = 11001 大小写忽略需要在数据库初始化时配置，如果在已经使用数据库后配置，将报错。 需要先备份数据库，然后清理 /var/lib/mysql/中的内容，重新设置数据库相关配置信息。 ","date":"2021-11-01","objectID":"/ubuntu1804-%E5%9F%BA%E6%9C%AC%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/:9:0","tags":["运维"],"title":"Ubuntu1804研发环境搭建","uri":"/ubuntu1804-%E5%9F%BA%E6%9C%AC%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"},{"categories":["运维"],"content":"3 挂载在snap的/dev/loop占用100% https://www.cnblogs.com/raina/p/12613164.html 运行 df 命令时添加选项，不显示它就好了： df -x squashfs -h 如果嫌弃每次输选项麻烦，可以在 \"~/.bashrc\" 文件里起别名： echo \"alias df='df -x squashfs -x tmpfs -x devtmpfs'\" \u003e\u003e ~/.bashrc source ~/.bashrc 三：命令 ","date":"2021-11-01","objectID":"/ubuntu1804-%E5%9F%BA%E6%9C%AC%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/:10:0","tags":["运维"],"title":"Ubuntu1804研发环境搭建","uri":"/ubuntu1804-%E5%9F%BA%E6%9C%AC%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"},{"categories":["运维"],"content":"查看已安装的jdk rpm -qa|grep jdk ","date":"2021-11-01","objectID":"/ubuntu1804-%E5%9F%BA%E6%9C%AC%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/:11:0","tags":["运维"],"title":"Ubuntu1804研发环境搭建","uri":"/ubuntu1804-%E5%9F%BA%E6%9C%AC%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"},{"categories":["运维"],"content":"安装rpm apt install rpm ","date":"2021-11-01","objectID":"/ubuntu1804-%E5%9F%BA%E6%9C%AC%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/:12:0","tags":["运维"],"title":"Ubuntu1804研发环境搭建","uri":"/ubuntu1804-%E5%9F%BA%E6%9C%AC%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"},{"categories":["运维"],"content":"重启jenkins systemctl restart jenkins ","date":"2021-11-01","objectID":"/ubuntu1804-%E5%9F%BA%E6%9C%AC%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/:13:0","tags":["运维"],"title":"Ubuntu1804研发环境搭建","uri":"/ubuntu1804-%E5%9F%BA%E6%9C%AC%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"},{"categories":["运维"],"content":"apt命令无效 apt-get update apt-get upgrade ","date":"2021-11-01","objectID":"/ubuntu1804-%E5%9F%BA%E6%9C%AC%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/:14:0","tags":["运维"],"title":"Ubuntu1804研发环境搭建","uri":"/ubuntu1804-%E5%9F%BA%E6%9C%AC%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"},{"categories":["运维"],"content":"查看文件大小 //数字为深度 du -h --max-depth=2 //当前路径下文件夹大小 du -s -h ./* ","date":"2021-11-01","objectID":"/ubuntu1804-%E5%9F%BA%E6%9C%AC%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/:15:0","tags":["运维"],"title":"Ubuntu1804研发环境搭建","uri":"/ubuntu1804-%E5%9F%BA%E6%9C%AC%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"},{"categories":["运维"],"content":"压缩 tar -cvf filename.tar dir #将目录dir中压缩到filename.tar中，保留原文件 tar -zxvf filename.tar.gz #解压到当前目录，保留原文件 tar -zxvf filename.tar.gz -C dir #解压到dir目录，保留原文件 解压zip文件 unzip 文件名 ","date":"2021-11-01","objectID":"/ubuntu1804-%E5%9F%BA%E6%9C%AC%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/:16:0","tags":["运维"],"title":"Ubuntu1804研发环境搭建","uri":"/ubuntu1804-%E5%9F%BA%E6%9C%AC%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"},{"categories":["运维"],"content":"文件操作 删除文件夹下某个文件之外（1.txt）的其他所有文件 ls | grep -v \"1.txt\" | xargs rm -rf 删除文件夹中的所有文件，不删除文件夹 ls | xargs rm -rf ","date":"2021-11-01","objectID":"/ubuntu1804-%E5%9F%BA%E6%9C%AC%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/:17:0","tags":["运维"],"title":"Ubuntu1804研发环境搭建","uri":"/ubuntu1804-%E5%9F%BA%E6%9C%AC%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"},{"categories":["运维"],"content":"端口 端口使用情况 netstat -ntap | grep 8899 端口是否开放 firewall-cmd --list-ports 开放tcp端口 firewall-cmd --permanent --zone=public --add-port=8899/tcp 停止指定端口的服务 sudo kill -9 \\$(netstat -nlp | grep :6003 | awk '{print \\$7}' | awk -F\"/\" '{ print \\$1 }') ","date":"2021-11-01","objectID":"/ubuntu1804-%E5%9F%BA%E6%9C%AC%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/:18:0","tags":["运维"],"title":"Ubuntu1804研发环境搭建","uri":"/ubuntu1804-%E5%9F%BA%E6%9C%AC%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"},{"categories":["运维"],"content":"防火墙 关闭防火墙： ufw disable 查看防火墙状态： ufw status 开启防火墙 ufw enable 开启端口 ufw allow 9000 ","date":"2021-11-01","objectID":"/ubuntu1804-%E5%9F%BA%E6%9C%AC%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/:19:0","tags":["运维"],"title":"Ubuntu1804研发环境搭建","uri":"/ubuntu1804-%E5%9F%BA%E6%9C%AC%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"},{"categories":["运维"],"content":"磁盘 parted -l fdisk -l 查看磁盘空间大小 df -h 查看当前文件夹所有文件大小 du -sh 查看指定文件夹大小 du -h /data 查看指定文件夹下所有文件的大小 du -h /data/ 查看指定文件大小 du -h data.log查看目录挂载点df /data加上-kh以g单位显示df /data -kh ","date":"2021-11-01","objectID":"/ubuntu1804-%E5%9F%BA%E6%9C%AC%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/:20:0","tags":["运维"],"title":"Ubuntu1804研发环境搭建","uri":"/ubuntu1804-%E5%9F%BA%E6%9C%AC%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"},{"categories":["运维"],"content":"Tomcat linux下启动tomcat服务 Linux下tomcat服务的启动、关闭与错误跟踪，使用PuTTy远程连接到服务器以后，通常通过以下几种方式启动关闭tomcat服务： 切换到tomcat主目录下的bin目录（cd usr/local/tomcat/bin） 1，启动tomcat服务 方式一：直接启动 ./startup.sh 方式二：作为服务启动 nohup ./startup.sh \u0026 方式三：控制台动态输出方式启动 ./catalina.sh run 动态地显示tomcat后台的控制台输出信息,Ctrl+C后退出并关闭服务 解释： 通过方式一、方式三启动的tomcat有个弊端，当客户端连接断开的时候，tomcat服务也会立即停止，通过方式二可以作为linux服务一直运行 通过方式一、方式二方式启动的tomcat，其日志会写到相应的日志文件中，而不能动态地查看tomcat控制台的输出信息与错误情况，通过方式三可以以控制台模式启动tomcat服务， 直接看到程序运行时后台的控制台输出信息，不必每次都要很麻烦的打开catalina.out日志文件进行查看，这样便于跟踪查阅后台输出信息。tomcat控制台信息包括log4j和System.out.println()等输出的信息。 2，关闭tomcat服务 ./shutdown.sh ","date":"2021-11-01","objectID":"/ubuntu1804-%E5%9F%BA%E6%9C%AC%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/:21:0","tags":["运维"],"title":"Ubuntu1804研发环境搭建","uri":"/ubuntu1804-%E5%9F%BA%E6%9C%AC%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"},{"categories":["运维"],"content":"Mysql 查看数据库运行状态 sudo service mysql status 启动数据库服务 sudo service mysql start 停止数据库服务 sudo service mysql stop 重启数据库服务 sudo service mysql restart 数据文件夹 cd /var/lib/mysql ","date":"2021-11-01","objectID":"/ubuntu1804-%E5%9F%BA%E6%9C%AC%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/:22:0","tags":["运维"],"title":"Ubuntu1804研发环境搭建","uri":"/ubuntu1804-%E5%9F%BA%E6%9C%AC%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"},{"categories":["运维"],"content":"系统时间 #设置时间同步网络 cd /usr/share/zoneinfo tzselect #选择时区，亚洲4，中国9，北京1 sudo timedatectl set-timezone Asia/Shanghai sudo ntpdate -u ntp.ntsc.ac.cn #没有ntpdate命令的话, 先安装一下, 执行 sudo apt install ntpdate date timedatectl status查看当前时间状态 sudo date -s MM/DD/YY //修改日期 sudo date -s hh:mm:ss //修改时间 sudo hwclock --systohc //修改生效 ","date":"2021-11-01","objectID":"/ubuntu1804-%E5%9F%BA%E6%9C%AC%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/:23:0","tags":["运维"],"title":"Ubuntu1804研发环境搭建","uri":"/ubuntu1804-%E5%9F%BA%E6%9C%AC%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"},{"categories":["运维"],"content":"SCP移动文件 scp /test.txt root@192.168.1.102:~/test.txt ","date":"2021-11-01","objectID":"/ubuntu1804-%E5%9F%BA%E6%9C%AC%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/:24:0","tags":["运维"],"title":"Ubuntu1804研发环境搭建","uri":"/ubuntu1804-%E5%9F%BA%E6%9C%AC%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"},{"categories":["运维"],"content":"FDisk 挂载硬盘 本操作以该场景为例：当云服务器挂载了一块新的数据盘时，使用fdisk分区工具将该数据盘设为主分区，分区形式默认设置为MBR，文件系统设为ext4格式，挂载在“/mnt/sdc”下，并设置开机启动自动挂载。 执行以下命令，查看新增数据盘。 fdisk -l 回显类似如下信息： [root@ecs-test-0001 ~]# fdisk -l Disk /dev/vda: 42.9 GB, 42949672960 bytes, 83886080 sectors Units = sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 512 bytes Disk label type: dos Disk identifier: 0x000bcb4e Device Boot Start End Blocks Id System /dev/vda1 * 2048 83886079 41942016 83 Linux Disk /dev/vdb: 107.4 GB, 107374182400 bytes, 209715200 sectors Units = sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 512 bytes 表示当前的云服务器有两块磁盘，**“/dev/vda”是系统盘，“/dev/vdb”**是新增数据盘。 执行以下命令，进入fdisk分区工具，开始对新增数据盘执行分区操作。 fdisk 新增数据盘 以新挂载的数据盘“/dev/vdb”为例： fdisk /dev/vdb 回显类似如下信息： [root@ecs-test-0001 ~]# fdisk /dev/vdb Welcome to fdisk (util-linux 2.23.2). Changes will remain in memory only, until you decide to write them. Be careful before using the write command. Device does not contain a recognized partition table Building a new DOS disklabel with disk identifier 0x38717fc1. Command (m for help): 输入“n”，按“Enter”，开始新建分区。 回显类似如下信息： Command (m for help): n Partition type: p primary (0 primary, 0 extended, 4 free) e extended 表示磁盘有两种分区类型： - “p”表示主分区。 - “e”表示扩展分区。 说明： 磁盘使用MBR分区形式，最多可以创建4个主分区，或者3个主分区加1个扩展分区，扩展分区不可以直接使用，需要划分成若干个逻辑分区才可以使用。 磁盘使用GPT分区形式时，没有主分区、扩展分区以及逻辑分区之分。 以创建一个主要分区为例，输入“p”，按“Enter”，开始创建一个主分区。 回显类似如下信息： Select (default p): p Partition number (1-4, default 1): **“Partition number”**表示主分区编号，可以选择1-4。 以分区编号选择“1”为例，输入主分区编号“1”，按“Enter”。 回显类似如下信息： Partition number (1-4, default 1): 1 First sector (2048-209715199, default 2048): **“First sector”**表示起始磁柱值，可以选择2048-209715199，默认为2048。 以选择默认起始磁柱值2048为例，按“Enter”。 系统会自动提示分区可用空间的起始磁柱值和截止磁柱值，可以在该区间内自定义，或者使用默认值。起始磁柱值必须小于分区的截止磁柱值。 回显类似如下信息： First sector (2048-209715199, default 2048): Using default value 2048 Last sector, +sectors or +size{K,M,G} (2048-209715199, default 209715199):+500G **“Last sector”**表示截止磁柱值，可以选择2048-209715199，默认为209715199。 选择增加500G的磁盘分区 ，输入+500G ，按“Enter”。 系统会自动提示分区可用空间的起始磁柱值和截止磁柱值，可以在该区间内自定义，或者使用默认值。起始磁柱值必须小于分区的截止磁柱值。 回显类似如下信息： Last sector, +sectors or +size{K,M,G} (2048-209715199, default 209715199): Using default value 209715199 Partition 1 of type Linux and of size 100 GiB is set Command (m for help): 表示分区完成，即为数据盘新建了1个分区。输入“p”，按“Enter”，查看新建分区的详细信息。 回显类似如下信息： Command (m for help): p Disk /dev/vdb: 107.4 GB, 107374182400 bytes, 209715200 sectors Units = sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 512 bytes Disk label type: dos Disk identifier: 0x38717fc1 Device Boot Start End Blocks Id System /dev/vdb1 2048 209715199 104856576 83 Linux Command (m for help): 表示新建分区**“/dev/vdb1”**的详细信息。输入“w”，按“Enter”，将分区结果写入分区表中。 回显类似如下信息： Command (m for help): w The partition table has been altered! Calling ioctl() to re-read partition table. Syncing disks. 表示分区创建完成。 说明： 如果之前分区操作有误，请输入“q”，则会退出fdisk分区工具，之前的分区结果将不会被保留。 执行以下命令，将新的分区表变更同步至操作系统。 partprobe 执行以下命令，将新建分区文件系统设为系统所需格式。 mkfs -t 文件系统格式 /dev/vdb1 以设置文件系统为“ext4”为例： mkfs -t ext4 /dev/vdb1 回显类似如下信息： [root@ecs-test-0001 ~]# mkfs -t ext4 /dev/vdb1 mke2fs 1.42.9 (28-Dec-2013) Filesystem label= OS type: Linux Block size=4096 (log=2) Fragment size=4096 (log=2) Stride=0 blocks, Stripe width=0 blocks 6553600 inodes, 26214144 blocks 1310707 blocks (5.00%) reserved for the super user First data block=0 Maximum filesystem blocks=2174746624 800 block groups 32768 blocks per group, 32768 fragments per group 8192 inodes per group Superblock backups stored on blocks: 32768, 98304, 163840, 229376, 294912, 819200, 884736, 1605632, 2654208, 4096000, 7962624, 11239424, 20480000, 23887872 Allocating group tables: done Writing inode tables: done Creating journal (32768 blocks): done Writing superblocks and filesystem accounting information: done 格式化需要等待一段时间，请观察系统运行状态，不要退出。 须知： 不同文件系统支持的分区大小不同，","date":"2021-11-01","objectID":"/ubuntu1804-%E5%9F%BA%E6%9C%AC%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/:25:0","tags":["运维"],"title":"Ubuntu1804研发环境搭建","uri":"/ubuntu1804-%E5%9F%BA%E6%9C%AC%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"},{"categories":["运维"],"content":" 四：运维方案 ","date":"2021-11-01","objectID":"/ubuntu1804-%E5%9F%BA%E6%9C%AC%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/:26:0","tags":["运维"],"title":"Ubuntu1804研发环境搭建","uri":"/ubuntu1804-%E5%9F%BA%E6%9C%AC%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"},{"categories":["运维"],"content":"定时任务 cron 目的：定时备份数据库binlog文件以及全量文件，定时删除15天前的备份文件 cron是被默认安装并启动的。而 ubuntu 下启动，停止与重启cron，均是通过调用/etc/init.d/中的脚本进行 service cron start /*启动服务*/ service cron stop /*关闭服务*/ service cron restart / *重启服务*/ service cron reload /*重新载入配置*/ pgrep cron /* 可以通过以下命令查看cron是否在运行（如果在运行，则会返回一个进程ID）*/ crontab 命令用于安装、删除或者列出用于驱动cron后台进程的表格。也就是说，用户把需要执行的命令序列放到crontab文件中以获得执行，每个用户都可以有自己的crontab文件。以下是这个命令的一些参数与说明： crontab -u /*设定某个用户的cron服务*/ crontab -l /*列出某个用户cron服务的详细内容*/ crontab -r /*删除某个用户的cron服务*/ crontab -e /*编辑某个用户的cron服务*/ ","date":"2021-11-01","objectID":"/ubuntu1804-%E5%9F%BA%E6%9C%AC%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/:27:0","tags":["运维"],"title":"Ubuntu1804研发环境搭建","uri":"/ubuntu1804-%E5%9F%BA%E6%9C%AC%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"},{"categories":["运维"],"content":"mysql自动备份 /usr/bin/mysqldump -u root -p123456 -B -F -R -x easysitedb | gzip \u003e /mysql_backup/easysitedb_$(date +%Y%m%d).tar.gz mysql -uroot -p@Lisijiang1994321ZaQ! -e\"flush logs\" chmod 777 /var/lib/mysql/binlog.* docker exec -it /usr/bin/mysqldump -u root -p数据库密码 -B -F -R -x plm | gzip \u003e /opt/mysql/mysql_backup/plm$(date +%Y%m%d).tar.gz docker exec -it mysql mysql -u root -p@Lisijiang1994321ZaQ! -e\"flush logs\" 0 3 * * 6 /etc/cron/mysql_backup/mysqlautoback.sh 0 23 * * * /etc/cron/mysqlbinlogautoback.sh ","date":"2021-11-01","objectID":"/ubuntu1804-%E5%9F%BA%E6%9C%AC%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/:28:0","tags":["运维"],"title":"Ubuntu1804研发环境搭建","uri":"/ubuntu1804-%E5%9F%BA%E6%9C%AC%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"},{"categories":["运维"],"content":"系统日志发送-邮件服务搭建 目的：定时扫描系统日志，将日志文件发送至邮箱 思路 1.配置邮件服务器 2.配置扫描服务器状态脚本，并发送邮件，添加为定时任务计划 邮件服务搭建参考博客 https://blog.csdn.net/mdx20072419/article/details/103901254 https://blog.csdn.net/weixin_39278265/article/details/98593267 搭建邮件服务 编辑源 sudo vi /etc/apt/sources.list 添加deb信息 deb http://cz.archive.ubuntu.com/ubuntu xenial main universe 更新源 sudo apt-get update 安装heirloom-mailx sudo apt install heirloom-mailx 配置外部SMTP vim /etc/s-nail.rc 添加内容： set from=\"623872553@qq.com\" //修改为自己的邮箱 set smtp=\"smtps://smtp.qq.com:465\" //默认smtp服务地址 set smtp-auth-user=\"623872553@qq.com\" 修改为自己的邮箱 set smtp-auth-password=\"aaaaaaaaaa\" //qq邮箱授权码,邮箱设置里需要手动开启，然后发短信确认 set smtp-auth=login 测试发送 发送文字 echo \"邮件内容\" | s-nail -s \"邮件主题\" 623872553@qq.com 发送文件，会变成bin结尾的文件，接收下载之后修改文件后缀名可以恢复使用 s-nail -s \"邮件主题\" 623872553@qq.com \u003c /www/test.jar #Author: jdzt.lln #Date: 2021-04-02 #FileName: systeminfo.sh #--------------------------------------- export Start_Color=\"\\e[1;32m\" export End_Color=\"\\e[0m\" Ipaddr=`ifconfig | grep -Eo --color=auto \"(\\\u003c([1-9]|[1-9][0-9]|[1-9][0-9]{2}|2[0-4][0-9]|25[0-5])\\\u003e\\.){3}\\\u003c([1-9]|[1-9][0-9]|[1-9][0-9]{2}|2[0-4][0-9]|25[0-5])\\\u003e\"| head -1` KerneVer=`uname -r` Cpu_Info=`lscpu | grep \"Model name:\"|tr -s \" \" |cut -d: -f2` Mem_Info=`free -mh|tr -s \" \"|cut -d\" \" -f2 |head -2| tail -1` HD_Info=`lsblk | grep \"^sd\\{1,\\}\"| tr -s \" \"|cut -d\" \" -f1,4` echo -e \"The System Hostname is : $Start_Color `hostname` $End_Color\" echo -e \"The System IP ADDER is : $Start_Color $Ipaddr $End_Color\" echo -e \"The System kerneVer is : $Start_Color $KerneVer $End_Color\" echo -e \"The System Cpu_Info is :$Start_Color $Cpu_Info $End_Color\" echo -e \"The System Mem_Info is : $Start_Color $Mem_Info $End_Color\" echo -e \"The System HD_Info is : $Start_Color \\n$HD_Info $End_Color\" disk.sh unset Start_Color unset End_Color unset Ipaddr unset KerneVer unset Cpu_Info unset Mem_Info unset HD_Info ","date":"2021-11-01","objectID":"/ubuntu1804-%E5%9F%BA%E6%9C%AC%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/:29:0","tags":["运维"],"title":"Ubuntu1804研发环境搭建","uri":"/ubuntu1804-%E5%9F%BA%E6%9C%AC%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"},{"categories":["运维"],"content":"#Ubuntu内核升级 参考链接 https://linux.cn/article-12125-1.html 这个指南里介绍了 7 种为 Ubuntu 升级 Linux 内核的不同方法。这 7 种方法里，有 5 种需要重启系统来使新内核生效，其他两种则不用。升级之前，强烈建议你将重要数据进行备份! 这里提到的所有方法只在 Ubuntu 中测试过。我们并不确定这些方法是不是也能适用于其他 Ubuntu 的特色发行版（如： Xubuntu）和衍生发行版（如：Linux Mint）。 ","date":"2021-07-29","objectID":"/ubuntu%E5%86%85%E6%A0%B8%E5%8D%87%E7%BA%A7/:0:0","tags":["运维"],"title":"Ubuntu内核升级","uri":"/ubuntu%E5%86%85%E6%A0%B8%E5%8D%87%E7%BA%A7/"},{"categories":["运维"],"content":"第一部分：需要重启的内核升级 以下方法需要你重启系统以便新的内核生效。以下所有方法都建议在个人系统或测试系统中进行。重要的事儿再说一遍，请备份好你 Ubuntu 中的重要数据、配置文件和其他重要的东西。 ","date":"2021-07-29","objectID":"/ubuntu%E5%86%85%E6%A0%B8%E5%8D%87%E7%BA%A7/:1:0","tags":["运维"],"title":"Ubuntu内核升级","uri":"/ubuntu%E5%86%85%E6%A0%B8%E5%8D%87%E7%BA%A7/"},{"categories":["运维"],"content":"方法 １ － 使用 dpkg 升级 Linux 内核（手动方式） 这个方法可以帮助你从 kernel.ubuntu.com 网站手动下载可用的最新 Linux 内核。如果你打算安装最新版（而不是稳定版或者正式发布版），那这种方法对你会很有用。从以上链接下载 Linux 内核版本。编写这个指南的时候，最新的可用版本是 5.0-rc1，最新的稳定版是 v4.20。 点击你所选择的 Linux 内核版本链接，找到你对应的架构（“Build for XXX”）的那部分。然后下载符合以下格式的两个文件（其中 X.Y.Z 是最高版本号）： linux-image-X.Y.Z-generic-*.deb linux-modules-X.Y.Z-generic-.deb 在终端中改变到文件所在的目录，然后执行此命令手动安装内核： sudo dpkg --install *.deb 重启系统，使用新内核： sudo reboot 检查是否如你所愿： uname -r 对于分步的说明，请查看下列链接中对应的部分。 在基于 RPM 和 DEB 的系统中安装 Linux 内核 4.15 以上的指南是针对的是 4.15 版本，不过安装最新版本的所有的步骤都是一样的。 优势： 不必联网（你可以从任何系统中下载 Linux 内核来使用） 缺点： 手动更新，需要重启系统。 ","date":"2021-07-29","objectID":"/ubuntu%E5%86%85%E6%A0%B8%E5%8D%87%E7%BA%A7/:1:1","tags":["运维"],"title":"Ubuntu内核升级","uri":"/ubuntu%E5%86%85%E6%A0%B8%E5%8D%87%E7%BA%A7/"},{"categories":["运维"],"content":"方法 2 - 用 apt-get 来升级 Linux 内核（推荐方法） 这是在类 Ubuntu 系统中升级 Linux 内核的推荐方法。不同于上一个方法，这种方法会从 Ubuntu 官方仓库下载、安装内核版本，而不是从 kernel.ubuntu.com网站。 要升级包括内核的整个系统，只需要执行： sudo apt-get update sudo apt-get upgrade 如果只希望升级内核，运行： sudo apt-get upgrade linux-image-generic 优势： 简单。推荐方法。 缺点： 需要联网，需要重启。 从官方库中升级内核是最接近开箱即用的方法，并且不会出什么问题。如果是生产环境的系统，这是最为推荐的升级 Linux 内核的方法。 方法 1 和方法 2 都需要用户去介入到升级 Linux 内核的过程中。而下边的方法（3、 4、 5）则几乎是全自动的。 ","date":"2021-07-29","objectID":"/ubuntu%E5%86%85%E6%A0%B8%E5%8D%87%E7%BA%A7/:1:2","tags":["运维"],"title":"Ubuntu内核升级","uri":"/ubuntu%E5%86%85%E6%A0%B8%E5%8D%87%E7%BA%A7/"},{"categories":["运维"],"content":"方法 3 - 使用 Ukuu 升级 Linux 内核 Ukuu是一个 Gtk GUI 和命令行工具，它可以从 kernel.ubuntu.com 下载最新的 Linux 主线内核，并自动安装到你的 Ubuntu 桌面版和服务器版中。Ukku 不仅简化了手动下载和安装新内核的过程，同时也会帮助你安全地移除旧的和不再需要的内核。更多细节可以参照以下指南。 Ukuu：在 Ubuntu 系统中安装和升级 Linux 内核的简单方法 优势： 易于安装使用。自动安装主线内核。 缺点： 需要联网，需要重启。 ","date":"2021-07-29","objectID":"/ubuntu%E5%86%85%E6%A0%B8%E5%8D%87%E7%BA%A7/:1:3","tags":["运维"],"title":"Ubuntu内核升级","uri":"/ubuntu%E5%86%85%E6%A0%B8%E5%8D%87%E7%BA%A7/"},{"categories":["运维"],"content":"方法 4 - 使用 UKTools 升级 Linux 内核 跟 Ukuu 差不多，UKTools 也会从 kernel.ubuntu.com 网站获取最新的稳定内核并且自动安装到 Ubuntu 以及类似于 Linux Mint 的延伸发行版中。关于UKTools的更多详情，请参见下面的链接。 UKTools：升级Ubuntu及其衍生产品中的最新Linux内核 优势： 简单，自动。 缺点： 需要联网，需要重启。 ","date":"2021-07-29","objectID":"/ubuntu%E5%86%85%E6%A0%B8%E5%8D%87%E7%BA%A7/:1:4","tags":["运维"],"title":"Ubuntu内核升级","uri":"/ubuntu%E5%86%85%E6%A0%B8%E5%8D%87%E7%BA%A7/"},{"categories":["运维"],"content":"方法 5 - 使用 Linux 内核实用程序更新 Linux 内核 Linux 内核实用程序是目前另一个用于升级类 Ubuntu 系统 Linux 内核的程序。实质上，它是一个由一系列 Bash 脚本构成的合集，用于编译并且可以选择性地为 Debian（LCTT 译注：Ubuntu 的上游发行版）及其衍生发行版升级内核。它包含三个实用程序，一个用于手动编译、安装来自于 http://www.kernel.org 网站的源码内核，另一个用于安装来自 https://kernel.ubuntu.com 网站的预编译的内核，第三个脚本用于移除旧内核。更多细节请浏览以下链接。 Linux 内核实用程序：编译和更新最新的 Linux 内核的脚本，适用于 Debian 及其衍生产品 优势： 简单，自动。 缺点： 需要联网，需要重启。 ","date":"2021-07-29","objectID":"/ubuntu%E5%86%85%E6%A0%B8%E5%8D%87%E7%BA%A7/:1:5","tags":["运维"],"title":"Ubuntu内核升级","uri":"/ubuntu%E5%86%85%E6%A0%B8%E5%8D%87%E7%BA%A7/"},{"categories":["运维"],"content":"第二部分：无需重启的内核升级 我之前说过，上边所有的方法都需要你重启服务器（LCTT 译注：也可以是桌面版）来启用新内核。如果是个人系统或者测试系统，可以这么办。但对于无法停机的生产环境系统该怎么办呢？一点问题没有，这时候实时补丁livepatching就派上用场了。 实时补丁（或者叫热补丁）允许你在不重启的情况下安装 Linux 更新或补丁，使你的服务器处于最新的安全级别。这对 web 主机、游戏服务器这类需要不间断在线的服务器来说是很有价值的。事实上，任何情况下，服务器都应该保持在不间断运行的状态下。由于 Linux 供应商只会在出于修复安全漏洞的目的下维护补丁，所以如果安全性是你最关注的问题时，这种方式再适合不过了。 以下两种方法不需要重启，对于生产环境和执行关键任务的 Ubuntu 服务器的 Linux 内核更新非常有用。 ","date":"2021-07-29","objectID":"/ubuntu%E5%86%85%E6%A0%B8%E5%8D%87%E7%BA%A7/:2:0","tags":["运维"],"title":"Ubuntu内核升级","uri":"/ubuntu%E5%86%85%E6%A0%B8%E5%8D%87%E7%BA%A7/"},{"categories":["运维"],"content":"方法 6 – 使用 Canonical 实时补丁服务来更新 Linux 内核 Canonical 实时补丁服务可以在不需要重启 Ubuntu 系统的情况下自动应用内核更新、补丁和安全补丁。它可以减少Ubuntu系统的停机时间，并保证系统的安全。Canonical 实时补丁服务可以在安装过程当中或安装之后进行设置。如果你使用的是 Ubuntu 桌面版，软件更新器会自动检查内核补丁的更新，并通知你。在基于控制台的系统中，则需要你定期运行 apt-get update 命令来进行升级。由于需要你手动运行 apt-get upgrade 命令它才会安装内核的安全补丁，所以算是半自动的。 实时补丁对三个及以下系统免费，如果多于三个，你需要升级成名为 Ubuntu Advantage 的企业支持方案套件。这个套件包括 Kernel 实时补丁及以下服务： 扩展安全维护 – Ubuntu 生命周期后的重要安全更新 Landscape – 针对大规模使用 Ubuntu 的系统管理工具 知识库 – 由 Ubuntu 专家撰写的私人文章和教程 电话和网站支持 价格 Ubuntu Advantage 包含三种付费计划，即基本计划、标准计划和高级计划。最基础的计划（基本计划）从 单物理节点 225 美元/年和单VPS 75美元/年开始计价。对于 Ubuntu 服务器版和桌面版看上去没有按月订阅。你可以在此处浏览所有计划的细节信息。 优势： 简单。半自动化。无需重启。支持三个免费系统。 缺点： ４ 个以上主机的话非常昂贵。没有补丁回滚。 开启 Canonical 实时补丁 如果你想在安装后设置实时补丁服务，依照以下方法逐步执行： 从 https://auth.livepatch.canonical.com/　获取一个密钥。 sudo snap install canonical-livepatch sudo canonical-livepatch enable your-key ","date":"2021-07-29","objectID":"/ubuntu%E5%86%85%E6%A0%B8%E5%8D%87%E7%BA%A7/:2:1","tags":["运维"],"title":"Ubuntu内核升级","uri":"/ubuntu%E5%86%85%E6%A0%B8%E5%8D%87%E7%BA%A7/"},{"categories":["运维"],"content":"方法 ７ －　使用 KernelCare 升级 Linux 内核 KernelCare 是最新的实时补丁方案。它是 CloudLinux 推出的产品。KernelCare 可以运行在 Ubuntu 和其他的 Linux 发行版中。它每四个小时检查一遍补丁的发布，并在无需确认的情况下安装它们。如果更新后存在问题，可以将补丁进行回滚。 价格 费用，每台服务器：4 美元/月，45 美元/年。 跟 Ubuntu 实时补丁相比，KernelCare 看起来非常便宜、实惠。好的方面在于也可以按月订阅。另一个前者不具备的功能是支持其他 Linux 发行版，如 Red Hat、CentOS、Debian、Oracle Linux、Amazon Linux 以及 OpenVZ、Proxmox 等虚拟化平台。 你可以在此处了解 KernelCare 的所有特性和简介，以及所有的付费计划的细节。 优势： 简单。全自动化。覆盖范围更广的操作系统。补丁回滚。无需重启。对非营利组织提供免费许可。价格低廉。 缺点： 不是免费的（除了30天的试用期）。 开启 KernelCare 服务 在 https://cloudlinux.com/kernelcare-free-trial5　获取一个 30 天免费试用密钥。 执行以下命令开启 KernelCare 并注册秘钥。 sudo wget -qq -O - https://repo.cloudlinux.com/kernelcare/kernelcare_install.sh | bash sudo /usr/bin/kcarectl --register KEY 如果你正在寻找一种经济实惠且可靠的商业服务来保持 Linux 服务器上的 Linux 内核更新，那么 KernelCare 是个不错的选择。 ","date":"2021-07-29","objectID":"/ubuntu%E5%86%85%E6%A0%B8%E5%8D%87%E7%BA%A7/:2:2","tags":["运维"],"title":"Ubuntu内核升级","uri":"/ubuntu%E5%86%85%E6%A0%B8%E5%8D%87%E7%BA%A7/"},{"categories":["分布式"],"content":"Sentinel 熔断限流学习","date":"2021-06-15","objectID":"/sentinel-%E7%86%94%E6%96%AD%E9%99%90%E6%B5%81/","tags":["分布式"],"title":"Sentinel 熔断限流学习","uri":"/sentinel-%E7%86%94%E6%96%AD%E9%99%90%E6%B5%81/"},{"categories":["分布式"],"content":"Sentinel 熔断限流学习 Sentinel版本 控制台 1.8.2 客户端 2.2.7.RELEASE 参考信息 控制台 https://github.com/alibaba/Sentinel/wiki/%E6%8E%A7%E5%88%B6%E5%8F%B0 官方文档 https://github.com/alibaba/spring-cloud-alibaba/wiki/Sentinel 博客 https://www.cnblogs.com/crazymakercircle/p/14285001.html ","date":"2021-06-15","objectID":"/sentinel-%E7%86%94%E6%96%AD%E9%99%90%E6%B5%81/:0:0","tags":["分布式"],"title":"Sentinel 熔断限流学习","uri":"/sentinel-%E7%86%94%E6%96%AD%E9%99%90%E6%B5%81/"},{"categories":["分布式"],"content":"1 控制台搭建 # 官网下载控制台Jar文件 https://github.com/alibaba/Sentinel/releases # 运行并启动控制台jar文件 java -Dserver.port=8080 -Dcsp.sentinel.dashboard.server=localhost:8080 -Dproject.name=sentinel -jar sentinel-dashboard-1.8.2.jar windows bat一键启动脚本（替换jar包路径） @echo off start cmd /k \"cd /d D:\\work\\springclude\\sentinel \u0026\u0026 java -Dserver.port=8080 -Dcsp.sentinel.dashboard.server=localhost:8080 -Dproject.name=sentinel -jar sentinel-dashboard-1.8.2.jar\" exit #参数解释 用于指定 Sentinel 控制台端口为 8080 -Dserver.port=8080 用于控制台对外暴露的服务地址 -Dcsp.sentinel.dashboard.server 用于指定项目名称 -Dproject.name=sentinel 用于指定控制台的登录用户名为 sentinel -Dsentinel.dashboard.auth.username=sentinel 用于指定控制台的登录密码为 123456；如果省略这两个参数，默认用户和密码均为 sentinel -Dsentinel.dashboard.auth.password=123456 用于指定 Spring Boot 服务端 session 的过期时间，如 7200 表示 7200 秒；60m 表示 60 分钟，默认为 30 分钟 -Dserver.servlet.session.timeout=7200 # 访问Sentinel 控制台界面 localhost:8080 ","date":"2021-06-15","objectID":"/sentinel-%E7%86%94%E6%96%AD%E9%99%90%E6%B5%81/:1:0","tags":["分布式"],"title":"Sentinel 熔断限流学习","uri":"/sentinel-%E7%86%94%E6%96%AD%E9%99%90%E6%B5%81/"},{"categories":["分布式"],"content":"2 环境搭建 ","date":"2021-06-15","objectID":"/sentinel-%E7%86%94%E6%96%AD%E9%99%90%E6%B5%81/:2:0","tags":["分布式"],"title":"Sentinel 熔断限流学习","uri":"/sentinel-%E7%86%94%E6%96%AD%E9%99%90%E6%B5%81/"},{"categories":["分布式"],"content":"2.1 引入依赖 \u003c!-- 熔断限流 https://mvnrepository.com/artifact/com.alibaba.cloud/spring-cloud-starter-alibaba-sentinel --\u003e \u003cdependency\u003e \u003cgroupId\u003ecom.alibaba.cloud\u003c/groupId\u003e \u003cartifactId\u003espring-cloud-starter-alibaba-sentinel\u003c/artifactId\u003e \u003cversion\u003e2.2.7.RELEASE\u003c/version\u003e \u003c/dependency\u003e ","date":"2021-06-15","objectID":"/sentinel-%E7%86%94%E6%96%AD%E9%99%90%E6%B5%81/:2:1","tags":["分布式"],"title":"Sentinel 熔断限流学习","uri":"/sentinel-%E7%86%94%E6%96%AD%E9%99%90%E6%B5%81/"},{"categories":["分布式"],"content":"2.2 配置文件 spring: # 熔断限流 cloud: sentinel: transport: # sentinel控制台地址 dashboard: localhost:8080 # 应用与Sentinel控制台交互的端口，应用本地会起一个该端口占用的HttpServer port: 8081 # 是否提前触发 Sentinel 初始化 eager: true ","date":"2021-06-15","objectID":"/sentinel-%E7%86%94%E6%96%AD%E9%99%90%E6%B5%81/:2:2","tags":["分布式"],"title":"Sentinel 熔断限流学习","uri":"/sentinel-%E7%86%94%E6%96%AD%E9%99%90%E6%B5%81/"},{"categories":["分布式"],"content":"2.3 持久化配置至nacos（TODO） Sentinel Dashboard中添加的规则是存储在内存中的，只要项目一重启规则就丢失了，需要规则持久化到nacos中 参考博客 https://blog.csdn.net/h273979586/article/details/115596602?spm=1001.2101.3001.6650.1\u0026utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7Edefault-1.nonecase\u0026depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7Edefault-1.nonecase ","date":"2021-06-15","objectID":"/sentinel-%E7%86%94%E6%96%AD%E9%99%90%E6%B5%81/:2:3","tags":["分布式"],"title":"Sentinel 熔断限流学习","uri":"/sentinel-%E7%86%94%E6%96%AD%E9%99%90%E6%B5%81/"},{"categories":["分布式"],"content":"3 常用规则配置说明 Spring Cloud Alibaba Sentinel 提供了这些配置选项: 配置项 含义 默认值 spring.application.name or project.name Sentinel项目名 spring.cloud.sentinel.enabled Sentinel自动化配置是否生效 true spring.cloud.sentinel.eager 是否提前触发 Sentinel 初始化 false spring.cloud.sentinel.transport.port 应用与Sentinel控制台交互的端口，应用本地会起一个该端口占用的HttpServer 8719 spring.cloud.sentinel.transport.dashboard Sentinel 控制台地址 spring.cloud.sentinel.transport.heartbeat-interval-ms 应用与Sentinel控制台的心跳间隔时间 spring.cloud.sentinel.transport.client-ip 此配置的客户端IP将被注册到 Sentinel Server 端 spring.cloud.sentinel.filter.order Servlet Filter的加载顺序。Starter内部会构造这个filter Integer.MIN_VALUE spring.cloud.sentinel.filter.url-patterns 数据类型是数组。表示Servlet Filter的url pattern集合 /* spring.cloud.sentinel.filter.enabled Enable to instance CommonFilter true spring.cloud.sentinel.metric.charset metric文件字符集 UTF-8 spring.cloud.sentinel.metric.file-single-size Sentinel metric 单个文件的大小 spring.cloud.sentinel.metric.file-total-count Sentinel metric 总文件数量 spring.cloud.sentinel.log.dir Sentinel 日志文件所在的目录 spring.cloud.sentinel.log.switch-pid Sentinel 日志文件名是否需要带上 pid false spring.cloud.sentinel.servlet.block-page 自定义的跳转 URL，当请求被限流时会自动跳转至设定好的 URL spring.cloud.sentinel.flow.cold-factor WarmUp 模式中的 冷启动因子 3 spring.cloud.sentinel.zuul.order.pre SentinelZuulPreFilter 的 order 10000 spring.cloud.sentinel.zuul.order.post SentinelZuulPostFilter 的 order 1000 spring.cloud.sentinel.zuul.order.error SentinelZuulErrorFilter 的 order -1 spring.cloud.sentinel.scg.fallback.mode Spring Cloud Gateway 流控处理逻辑 (选择 redirect or response) spring.cloud.sentinel.scg.fallback.redirect Spring Cloud Gateway 响应模式为 ‘redirect’ 模式对应的重定向 URL spring.cloud.sentinel.scg.fallback.response-body Spring Cloud Gateway 响应模式为 ‘response’ 模式对应的响应内容 spring.cloud.sentinel.scg.fallback.response-status Spring Cloud Gateway 响应模式为 ‘response’ 模式对应的响应码 429 spring.cloud.sentinel.scg.fallback.content-type Spring Cloud Gateway 响应模式为 ‘response’ 模式对应的 content-type application/json 请注意。这些配置只有在 Servlet 环境下才会生效，RestTemplate 和 Feign 针对这些配置都无法生效 ","date":"2021-06-15","objectID":"/sentinel-%E7%86%94%E6%96%AD%E9%99%90%E6%B5%81/:3:0","tags":["分布式"],"title":"Sentinel 熔断限流学习","uri":"/sentinel-%E7%86%94%E6%96%AD%E9%99%90%E6%B5%81/"},{"categories":["分布式"],"content":"4 核心概念 使用 Sentinel 来进行熔断保护，主要分为两个步骤：定义资源和定义规则。 ","date":"2021-06-15","objectID":"/sentinel-%E7%86%94%E6%96%AD%E9%99%90%E6%B5%81/:4:0","tags":["分布式"],"title":"Sentinel 熔断限流学习","uri":"/sentinel-%E7%86%94%E6%96%AD%E9%99%90%E6%B5%81/"},{"categories":["分布式"],"content":"4.1.定义资源 资源：可以是任何东西，一个服务，服务里的方法，甚至是一段代码。 资源是 Sentinel 的关键概念。它可以是 Java 应用程序中的任何内容，例如，由应用程序提供的服务，或由应用程序调用的其它应用提供的服务，RPC接口方法，甚至可以是一段代码。 只要通过 Sentinel API 定义的代码，就是资源，能够被 Sentinel 保护起来。大部分情况下，可以使用方法签名，URL，甚至服务名称作为资源名来标示资源。 把需要控制流量的代码用 Sentinel的关键代码 SphU.entry(\"资源名\") 和 entry.exit() 包围起来即可。 示例代码1 Entry entry = null; try { // 定义一个sentinel保护的资源，名称为test-sentinel-api entry = SphU.entry(resourceName); // 模拟执行被保护的业务逻辑耗时 Thread.sleep(100); return a; } catch (BlockException e) { // 如果被保护的资源被限流或者降级了，就会抛出BlockException log.warn(\"资源被限流或降级了\", e); return \"资源被限流或降级了\"; } catch (InterruptedException e) { return \"发生InterruptedException\"; } finally { if (entry != null) { entry.exit(); } ContextUtil.exit(); } } 示例代码2 public static void main(String[] args) { // 配置规则. initFlowRules(); while (true) { // 1.5.0 版本开始可以直接利用 try-with-resources 特性 try (Entry entry = SphU.entry(\"HelloWorld\")) { // 被保护的逻辑 System.out.println(\"hello world\"); } catch (BlockException ex) { // 处理被流控的逻辑 System.out.println(\"blocked!\"); } } } 示例代码3 （推荐使用）（注意：注解方式埋点不支持 private 方法。） @SentinelResource(\"HelloWorld\") public void helloWorld() { // 资源中的逻辑 System.out.println(\"hello world\"); } @SentinelResource 用于定义资源，并提供可选的异常处理和 fallback 配置项 使用说明见官方文档 https://github.com/alibaba/Sentinel/wiki/%E6%B3%A8%E8%A7%A3%E6%94%AF%E6%8C%81 （以下说明为复制） value：资源名称，必需项（不能为空） entryType：entry 类型，可选项（默认为 EntryType.OUT） blockHandler / blockHandlerClass: blockHandler 对应处理 BlockException 的函数名称，可选项。blockHandler 函数访问范围需要是 public，返回类型需要与原方法相匹配，参数类型需要和原方法相匹配并且最后加一个额外的参数，类型为 BlockException。blockHandler 函数默认需要和原方法在同一个类中。若希望使用其他类的函数，则可以指定 blockHandlerClass 为对应的类的 Class 对象，注意对应的函数必需为 static 函数，否则无法解析。 fallback / fallbackClass：fallback 函数名称，可选项，用于在抛出异常的时候提供 fallback 处理逻辑。fallback 函数可以针对所有类型的异常（除了 exceptionsToIgnore 里面排除掉的异常类型）进行处理。fallback 函数签名和位置要求： 返回值类型必须与原函数返回值类型一致； 方法参数列表需要和原函数一致，或者可以额外多一个 Throwable 类型的参数用于接收对应的异常。 fallback 函数默认需要和原方法在同一个类中。若希望使用其他类的函数，则可以指定 fallbackClass 为对应的类的 Class 对象，注意对应的函数必需为 static 函数，否则无法解析。 defaultFallback（since 1.6.0）：默认的 fallback 函数名称，可选项，通常用于通用的 fallback 逻辑（即可以用于很多服务或方法）。默认 fallback 函数可以针对所有类型的异常（除了 exceptionsToIgnore 里面排除掉的异常类型）进行处理。若同时配置了 fallback 和 defaultFallback，则只有 fallback 会生效。defaultFallback 函数签名要求： 返回值类型必须与原函数返回值类型一致； 方法参数列表需要为空，或者可以额外多一个 Throwable 类型的参数用于接收对应的异常。 defaultFallback 函数默认需要和原方法在同一个类中。若希望使用其他类的函数，则可以指定 fallbackClass 为对应的类的 Class 对象，注意对应的函数必需为 static 函数，否则无法解析。 exceptionsToIgnore（since 1.6.0）：用于指定哪些异常被排除掉，不会计入异常统计中，也不会进入 fallback 逻辑中，而是会原样抛出。 1.8.0 版本开始，defaultFallback 支持在类级别进行配置。 注：1.6.0 之前的版本 fallback 函数只针对降级异常（DegradeException）进行处理，不能针对业务异常进行处理。 特别地，若 blockHandler 和 fallback 都进行了配置，则被限流降级而抛出 BlockException 时只会进入 blockHandler 处理逻辑。若未配置 blockHandler、fallback 和 defaultFallback，则被限流降级时会将 BlockException 直接抛出（若方法本身未定义 throws BlockException 则会被 JVM 包装一层 UndeclaredThrowableException）。 ","date":"2021-06-15","objectID":"/sentinel-%E7%86%94%E6%96%AD%E9%99%90%E6%B5%81/:4:1","tags":["分布式"],"title":"Sentinel 熔断限流学习","uri":"/sentinel-%E7%86%94%E6%96%AD%E9%99%90%E6%B5%81/"},{"categories":["分布式"],"content":"4.2.定义规则 Sentinel 支持以下几种规则：流量控制规则、熔断降级规则、系统保护规则、来源访问控制规则、热点参数规则 4.2.1 熔断降级 熔断降级对调用链路中不稳定的资源进行熔断降级是保障高可用的重要措施之一。 由于调用关系的复杂性，如果调用链路中的某个资源不稳定，最终会导致请求发生堆积。Sentinel 熔断降级会在调用链路中某个资源出现不稳定状态时（例如调用超时或异常比例升高），对这个资源的调用进行限制，让请求快速失败，避免影响到其它的资源而导致级联错误。当资源被降级后，在接下来的降级时间窗口之内，对该资源的调用都自动熔断（默认行为是抛出 DegradeException） Field 说明 默认值 resource 资源名，即规则的作用对象 grade 熔断策略，支持慢调用比例/异常比例/异常数策略 慢调用比例 count 慢调用比例模式下为慢调用临界 RT（超出该值计为慢调用）；异常比例/异常数模式下为对应的阈值 timeWindow 熔断时长，单位为 s minRequestAmount 熔断触发的最小请求数，请求数小于该值时即使异常比率超出阈值也不会熔断（1.7.0 引入） 5 statIntervalMs 统计时长（单位为 ms），如 60*1000 代表分钟级（1.8.0 引入） 1000 ms slowRatioThreshold 慢调用比例阈值，仅慢调用比例模式有效（1.8.0 引入） 通常用以下几种降级策略： 平均响应时间 (DEGRADE_GRADE_RT)： 当资源的平均响应时间超过阈值（DegradeRule 中的 count，以 ms 为单位）之后，资源进入准降级状态。如果接下来 1s 内持续进入 5 个请求（即 QPS \u003e= 5），它们的 RT 都持续超过这个阈值，那么在接下的时间窗口（DegradeRule 中的 timeWindow，以 s 为单位）之内，对这个方法的调用都会自动地熔断（抛出 DegradeException）。 注意 Sentinel 默认统计的 RT 上限是 4900 ms，超出此阈值的都会算作 4900 ms，若需要变更此上限可以通过启动配置项 -Dcsp.sentinel.statistic.max.rt=xxx 来配置。、 异常比例 (DEGRADE_GRADE_EXCEPTION_RATIO)： 当资源的每秒异常总数占通过量的比值超过阈值（DegradeRule 中的 count）之后，资源进入降级状态，即在接下的时间窗口（DegradeRule 中的 timeWindow，以 s 为单位）之内，对这个方法的调用都会自动地返回。 异常比率的阈值范围是 [0.0, 1.0]，代表 0% - 100%。 异常数 (DEGRADE_GRADE_EXCEPTION_COUNT)： 当资源近 1 分钟的异常数目超过阈值之后会进行熔断。 注意由于统计时间窗口是分钟级别的，若 timeWindow 小于 60s，则结束熔断状态后仍可能再进入熔断状态。 4.2.2 限流 流量控制(Flow Control)，原理是监控应用流量的QPS或并发线程数等指标，当达到指定阈值时对流量进行控制，避免系统被瞬时的流量高峰冲垮，保障应用高可用性。 一条限流规则主要由下面几个因素组成，我们可以组合这些元素来实现不同的限流效果： Field 说明 默认值 resource 资源名，资源名是限流规则的作用对象 count 限流阈值 grade 限流阈值类型，QPS 或线程数模式 QPS 模式 limitApp 流控针对的调用来源 default，代表不区分调用来源 strategy 判断的根据是资源自身，还是根据其它关联资源 (refResource)，还是根据链路入口 根据资源本身 controlBehavior 流控效果（直接拒绝 / 排队等待 / 慢启动模式） 直接拒绝 资源名：唯一名称，默认请求路径 针对来源：Sentinel可以针对调用者进行限流，填写微服务名，默认为default(不区分来源) 阈值类型/单机阈值： 1.QPS：每秒请求数，当前调用该api的QPS到达阈值的时候进行限流 2.线程数：当调用该api的线程数到达阈值的时候，进行限流 是否集群：是否为集群 流控的三种模式 1.直接：当api大达到限流条件时，直接限流 2.关联：当关联的资源到达阈值，就限流自己 3.链路：只记录指定路上的流量，指定资源从入口资源进来的流量，如果达到阈值，就进行限流，api级别的限流 4.2.3 热点限流 Field 说明 默认值 resource 资源名，必填 count 限流阈值，必填 grade 限流模式 QPS 模式 durationInSec 统计窗口时间长度（单位为秒），1.6.0 版本开始支持 1s controlBehavior 流控效果（支持快速失败和匀速排队模式），1.6.0 版本开始支持 快速失败 maxQueueingTimeMs 最大排队等待时长（仅在匀速排队模式生效），1.6.0 版本开始支持 0ms paramIdx 热点参数的索引，必填，对应 SphU.entry(xxx, args) 中的参数索引位置 paramFlowItemList 参数例外项，可以针对指定的参数值单独设置限流阈值，不受前面 count 阈值的限制。仅支持基本类型和字符串类型 clusterMode 是否是集群参数流控规则 false clusterConfig 集群流控相关配置 4.2.4 系统保护 系统规则支持以下的模式： Load 自适应（仅对 Linux/Unix-like 机器生效）：系统的 load1 作为启发指标，进行自适应系统保护。当系统 load1 超过设定的启发值，且系统当前的并发线程数超过估算的系统容量时才会触发系统保护（BBR 阶段）。系统容量由系统的 maxQps * minRt 估算得出。设定参考值一般是 CPU cores * 2.5。 CPU usage（1.5.0+ 版本）：当系统 CPU 使用率超过阈值即触发系统保护（取值范围 0.0-1.0），比较灵敏。 平均 RT：当单台机器上所有入口流量的平均 RT 达到阈值即触发系统保护，单位是毫秒。 并发线程数：当单台机器上所有入口流量的并发线程数达到阈值即触发系统保护。 入口 QPS：当单台机器上所有入口流量的 QPS 达到阈值即触发系统保护。 4.2.5 黑白名单 授权规则，即黑白名单规则（AuthorityRule）非常简单，主要有以下配置项： resource：资源名，即限流规则的作用对象 limitApp：对应的黑名单/白名单，不同 origin 用 , 分隔，如 appA,appB strategy：限制模式，AUTHORITY_WHITE 为白名单模式，AUTHORITY_BLACK 为黑名单模式，默认为白名单模式 ","date":"2021-06-15","objectID":"/sentinel-%E7%86%94%E6%96%AD%E9%99%90%E6%B5%81/:4:2","tags":["分布式"],"title":"Sentinel 熔断限流学习","uri":"/sentinel-%E7%86%94%E6%96%AD%E9%99%90%E6%B5%81/"},{"categories":["分布式"],"content":"采坑记录 1.控制台配置规则后，无法生效，也不显示配置记录 本地项目fastjson版本过低，为1.1.7,升级为1.2.75,问题解决 \u003cproperties\u003e \u003cfastjson.version\u003e1.2.75\u003c/fastjson.version\u003e \u003c/properties\u003e \u003c!-- fastjson https://mvnrepository.com/artifact/com.alibaba/fastjson --\u003e \u003cdependency\u003e \u003cgroupId\u003ecom.alibaba\u003c/groupId\u003e \u003cartifactId\u003efastjson\u003c/artifactId\u003e \u003cversion\u003e${fastjson.version}\u003c/version\u003e \u003c/dependency\u003e ","date":"2021-06-15","objectID":"/sentinel-%E7%86%94%E6%96%AD%E9%99%90%E6%B5%81/:5:0","tags":["分布式"],"title":"Sentinel 熔断限流学习","uri":"/sentinel-%E7%86%94%E6%96%AD%E9%99%90%E6%B5%81/"},{"categories":["领域驱动设计"],"content":"领域驱动名词与术语","date":"2023-07-29","objectID":"/ddd%E7%9A%84%E5%90%8D%E8%AF%8D%E4%B8%8E%E6%9C%AF%E8%AF%AD/","tags":["领域驱动设计"],"title":"领域驱动名词与术语","uri":"/ddd%E7%9A%84%E5%90%8D%E8%AF%8D%E4%B8%8E%E6%9C%AF%E8%AF%AD/"},{"categories":["领域驱动设计"],"content":"领域驱动名词与术语 名词与术语 l Event Storming（事件风暴）：事件风暴是一项团队活动，旨在通过领域事件识别出聚合根，进而划分微服务的限界上下文。在活动中，团队先通过头脑风暴的形式罗列出领域中所有的领域事件，整合之后形成最终的领域事件集合，然后对于每一个事件，标注出导致该事件的命令（Command），再然后为每个事件标注出命令发起方的角色，命令可以是用户发起，也可以是第三方系统调用或者是定时器触发等。最后对事件进行分类整理出聚合根以及限界上下文。 l Entity（实体）：每个实体是唯一的，并且可以相当长的一段时间内持续地变化。我们可以对实体做多次修改，故一个实体对象可能和它先前的状态大不相同。但是，由于它们拥有相同的身份标识，他们依然是同一个实体。例如一件商品在电商商品上下文中是一个实体，通过商品中台唯一的商品id来标示这个实体。 l ValueObject（值对象）：值对象用于度量和描述事物，当你只关心某个对象的属性时，该对象便可作为一个值对象。实体与值对象的区别在于唯一的身份标识和可变性。当一个对象用于描述一个事物，但是又没有唯一标示，那么它就是一个值对象。例如商品中的商品类别，类别就没有一个唯一标识，通过图书、服装等这些值就能明确表示这个商品类别。 l Aggregate（聚合）：聚合是实体的升级，是由一组与生俱来就密切相关实体和值对象组合而成的，整个组合的最上层实体就是聚合。 l Bounded Context（限界上下文）：用来封装通用语言和领域对象，为领域提供上下文语境，保证在领域之内的一些术语、业务相关对象等（通用语言）有一个确切的含义，没有二义性。使团队所有成员能够明确地知道什么必须保持一致，什么必须独立开发。 l 云原生：一种基于容器、微服务和DevOps等现代技术的应用开发和部署方法，旨在实现高可靠性、弹性和可扩展性。 l 微服务：将系统拆分成多个小而自治的服务并独立部署、运行、维护的一种服务架构风格，能够提高灵活性、复用性和可测试性。 l 领域驱动设计（DDD）：一种软件开发方法论，它以业务领域为中心，强调深入理解领域知识，并采用建模的方式将领域知识转化为高质量和完备性的系统设计。 l 领域：领域表示一个现实世界中的业务活动范围。 l 子域：子域是大型领域中相对独立的子领域，通常专注于单一的业务问题，是领域内的更小粒度划分。 l 核心域：核心域指提供主要价值且区别于竞争对手的最重要领域。 l 通用域：通用域则是所有项目和组织都具备的基础、通用的功能部分。 l 支撑域：支撑域则是专注于支持核心业务以及支持日常运营和维护等内部需求和工具领域。 l 战略设计：确定整体战略，划分领域、子域、业务依赖等。 l 战术设计：针对每个子域进行更细粒度的设计。 l 限界上下文：用于区分不同的业务领域和子系统，明确各自的作用范围和交互方式。 l 领域模型：反映业务规则和相关行为的模型，通常由实体、值对象、服务、聚合等组成。 l 实体：代表需要跟踪和管理的业务对象，具有唯一标识符、属性和行为等。 l **值对象：只有属性没有唯一标识符和行为，**通常是不可变的对象类型。值对象在领域模型中很重要，它们通常是不可变的，并表示在业务流程中经常使用的值，如日期、时间、电话号码等。 l 聚合：将多个相关实体和值对象封装成单个操作及处理的事务单元。 l 聚合根：聚合中的一个实体或值对象，通过根来保证整个聚合的完整性及一致性。 l 领域事件：发生于领域模型中的代表业务动作的事件，可以用于解耦设计和建立异步处理机制。 l 领域服务：协调多个实体和聚合之间交互和操作的业务逻辑过程。领域服务是处理跨多个实体和聚合的逻辑操作的一种方式。领域服务可以协调和执行不同的命令和查询，并将其组合成一个长时间运行的事务。 l 应用服务：负责应用程序的具体逻辑和处理，通常与用户界面进行交互。 l 命令：领域对象执行某个行为的请求，类似于面向对象编程中的方法调用。 l 工厂：创建领域对象的一种设计模式，它可以隐藏复杂的构造逻辑并提高代码的可测试性。 l 仓储：负责存储和查询领域对象的一类组件，通常是一种数据访问接口，它封装了与底层数据存储交互的全部细节。 l 界限映射(Bounded contexts mapping)：通过在不同领域上下文之间建立显式的联系来确保整个系统具有一致性。映射可以是直接映射，反映了两个上下文之间共享元素的关系。也可以是转译映射，在某些阶段为缓解代码集成而代表关节。 ","date":"2023-07-29","objectID":"/ddd%E7%9A%84%E5%90%8D%E8%AF%8D%E4%B8%8E%E6%9C%AF%E8%AF%AD/:0:0","tags":["领域驱动设计"],"title":"领域驱动名词与术语","uri":"/ddd%E7%9A%84%E5%90%8D%E8%AF%8D%E4%B8%8E%E6%9C%AF%E8%AF%AD/"},{"categories":null,"content":"About LoveIt","date":"2019-08-02","objectID":"/about/","tags":null,"title":"About LoveIt","uri":"/about/"},{"categories":null,"content":"  LoveIt is a clean, elegant but advanced blog theme for Hugo developed by Dillon . It is based on the original LeaveIt Theme and KeepIt Theme . Hugo Theme LoveIt ","date":"2019-08-02","objectID":"/about/:0:0","tags":null,"title":"About LoveIt","uri":"/about/"},{"categories":null,"content":"Features Performance and SEO  Optimized for performance: 99/100 on mobile and 100/100 on desktop in Google PageSpeed Insights  Optimized SEO performance with a correct SEO SCHEMA based on JSON-LD  Google Analytics supported  Fathom Analytics supported  Search engine verification supported (Google, Bind, Yandex and Baidu)  CDN for third-party libraries supported  Automatically converted images with Lazy Load by lazysizes Appearance and Layout  Desktop/Mobile responsive layout  Light/Dark mode  Globally consistent design language  Pagination supported  Easy-to-use and self-expanding table of contents  Multilanguage supported and i18n ready  Beautiful CSS animation Social and Comment Systems  Gravatar supported by Gravatar  Local Avatar supported  Up to 64 social links supported  Up to 24 share sites supported  Disqus comment system supported by Disqus  Gitalk comment system supported by Gitalk  Valine comment system supported by Valine  Facebook comments system supported by Facebook  Telegram comments system supported by Comments  Commento comment system supported by Commento  Utterances comment system supported by Utterances Extended Features  Search supported by Lunr.js or algolia  Twemoji supported  Automatically highlighting code  Copy code to clipboard with one click  Images gallery supported by lightGallery  Extended Markdown syntax for Font Awesome icons  Extended Markdown syntax for ruby annotation  Extended Markdown syntax for fraction  Mathematical formula supported by $\\KaTeX$  Diagrams shortcode supported by mermaid  Interactive data visualization shortcode supported by ECharts  Mapbox shortcode supported by Mapbox GL JS  Music player shortcode supported by APlayer and MetingJS  Bilibili player shortcode  Kinds of admonitions shortcode  Custom style shortcode  Custom script shortcode  Animated typing supported by TypeIt  Cookie consent banner supported by cookieconsent … ","date":"2019-08-02","objectID":"/about/:0:1","tags":null,"title":"About LoveIt","uri":"/about/"},{"categories":null,"content":"License LoveIt is licensed under the MIT license. Check the LICENSE file for details. ","date":"2019-08-02","objectID":"/about/:0:2","tags":null,"title":"About LoveIt","uri":"/about/"},{"categories":null,"content":"Special Thanks Thanks to the authors of following resources included in the theme: normalize.css Font Awesome Simple Icons Animate.css autocomplete Lunr.js algoliasearch lazysizes object-fit-images Twemoji emoji-data lightGallery clipboard.js Sharer.js TypeIt $\\KaTeX$ mermaid ECharts Mapbox GL JS APlayer MetingJS Gitalk Valine cookieconsent ","date":"2019-08-02","objectID":"/about/:0:3","tags":null,"title":"About LoveIt","uri":"/about/"}]